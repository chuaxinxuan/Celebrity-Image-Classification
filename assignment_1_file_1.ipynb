{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h1><center>DSA 4212: Year 2022</center></h1>\n",
    "<h3><center> Assignment 1 (Deadline: Sunday 27th March at 23:59) </center></h3>\n",
    "<h4><center> Group Number: 12 </center></h4>\n",
    "<h4><center> Filename: assignment_1_12.ipynb where XX is your group number</center></h4>\n",
    "<h4><center> Group Member 1: Chua Xin Xuan, A0205767X </center></h4>\n",
    "<h4><center> Group Member 2: Joey Tan Xin Yi, A0206334N </center></h4>\n",
    "<h4><center> Group Member 3: Quek Su Ning, A0205557A </center></h4>\n",
    "<h4><center> Group Member 4: Tan Jie Yi, A0206383H </center></h4>\n",
    "\n",
    "**Remark:** as described below, each group has to submit two documents on lumiNUS: \n",
    "1. a jupyter notebook with your code  \n",
    "2. a pdf report explaining your approaches and conclusions.\n",
    "3. you can have a look at `https://www.overleaf.com/read/xmvqgpsdqwyx` if you would like to use Overleaf and Latex to rapidly produce a neat report. You can use your NUS email to create an Overleaf account.\n",
    "\n",
    "**File naming convention:**\n",
    "1. the Jupyter notebook needs to be named `assignment_1_XX.ipynb`. For example, group number 3 needs to name its jupyter notebook as `assignment_1_03.ipynb`.\n",
    "1. the pdf report needs to be named `assignment_1_XX.pdf`. For example, group number 3 needs to name its pdf report as `assignment_1_03.pdf`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True) # for higher accuracy\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pylab as plt\n",
    "import imageio\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "# to install scikit-image: !pip install scikit-image\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Data Download\n",
    "1. Download the \"celeba_small.zip\" file available on lumiNUS.\n",
    "This is a 146Mo large zip-file containing 20K face images.\n",
    "2. Download the attribute file \"celeba.csv\" available on lumiNUS.\n",
    "3. Unzip the file \"celeba_small.zip\" in the directory of your choice. (Data = 175 Mo when uncompressed). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Brief Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "path_csv  = \"/Users/joeyt/Desktop/4212 lab/project\"\n",
    "attribute = pd.read_csv(os.path.join(path_csv, \"celeba.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"attribute\" is a dictionary containing several attributes for each image\n",
    "attribute.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 20000\n"
     ]
    }
   ],
   "source": [
    "#let us list all the files in the image directory\n",
    "path = \"/Users/joeyt/Desktop/4212 lab/project/img_celeba_small\"\n",
    "all_img = [f for f in os.listdir(path) \n",
    "                 if os.path.isfile(os.path.join(path, f)) \n",
    "                 and f.endswith(\".jpg\")]\n",
    "\n",
    "# sort the images by alphabetical order \n",
    "# !!!! VERY IMPORTANT in order to be consistent with the labels contained in celeba.csv !!!!\n",
    "all_img.sort()\n",
    "nb_img = len(all_img)\n",
    "print(\"Number of images:\", nb_img)\n",
    "\n",
    "#let us keep only the relevant attributes\n",
    "attribute = attribute[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let us display the first 20 images\n",
    "# !!! MAKE SURE THAT THE LABELS ARE CORRECT !!!\n",
    "plt.figure(figsize=(15,3))\n",
    "for k in range(20):\n",
    "    #load image\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    #resize to 100x100 for display (you do not have to do this in the assignment)\n",
    "    im = resize(im, (100,100) )\n",
    "    #scale pixel intensity to [0,1] by divising by 255 and display\n",
    "    plt.subplot(2,10,k+1)\n",
    "    plt.imshow(im/255.)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    is_male = attribute[\"Male\"][k]\n",
    "    if is_male == 1:\n",
    "        plt.title(\"Male\")\n",
    "    else:\n",
    "        plt.title(\"Female\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let us display the first 20 images in black and white\n",
    "plt.figure(figsize=(15,3))\n",
    "for k in range(20):\n",
    "    #load image\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    #resize to 100x100\n",
    "    im = resize(im, (100,100) )\n",
    "    #transform to black and white by averaging the 3 color channels\n",
    "    im = np.mean(im, axis=2)\n",
    "    #scale pixel intensity to [0,1] by divising by 255 and display\n",
    "    plt.subplot(2,10,k+1)\n",
    "    plt.imshow(im/255., cmap=\"gray\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#let us load the first 500 images\n",
    "n_img = 500\n",
    "img_array = np.zeros((n_img, 100,100))\n",
    "for k in range(n_img):\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    im = np.mean(im, axis=2) # average the last channel\n",
    "    img_array[k,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAABoCAYAAADrRhrhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAB1b0lEQVR4nO29ebTkW1bX+T0RcYeIG3fMly/zvZf13uNVFY+qUqFLypJets1qBKG1Rbtb1FZBpRCwaUDsdmhdAt2oOOBa2goOXVgNODeiojhLMah04QSUMhQUVfWGHG/mnceI+PUfv/ic+P72/d3MrFc3M+NXK/Zase6NiF/8hnPO3vu7v3ufc1JRFJrJTGYyk5nMZCYzaaK0nvQNzGQmM5nJTGYyk5m8UZkBmZnMZCYzmclMZtJYmQGZmcxkJjOZyUxm0liZAZmZzGQmM5nJTGbSWJkBmZnMZCYzmclMZtJYmQGZmcxkJjOZyUxm0liZGiCTUvq8lNLffdL3UScppSsppZ9MKS086XtpojyKvk0pfXZK6dWHPParU0rffJHX/2SWadbFB8kna1+/kT5JKe2llF56yGOLlNJb3tDNPZnzvi+l9E3nfPenU0pfcdHXfBTSBF1LKb047sfOIzj3+1NK7znnu7+TUvr8hznPGwYy4xu4d4HO/Y9K+uZUyg+mlP5wuN6XpJR+LqXUu6DrPbQURXFT0vdL+p2P+9pPQh5V39r5i5TSTVeMlFInpXQrpfQoFjb6S5J+S0rp6Udw7icuj6G/Ukrpq1JKP55SOkgp3Rhf8zdexMUu2NlNRV8/Jh2qtFlK6RtSSt/F+6Io+kVRfPiCrl8rKaVnUkrvTSldTyntppR+KqX0jSmlpUd53QfIn5T0B1NK8xd94ifRr49DUkqfmlL62ymlOyml7bGuf11Kqf2478XkmyX9kYc58A0BmZTSi5L+K0mFpF/zRs4RzvcuSatFUfxIUa7Q96WSvi6l9I7x95cl/SlJ7ymK4uATvd4blL8q6cuf0LUfmzzKvg1fbUn6Anv/30q694ler06KojiS9I8kffGjOP+TlMfUX39W0tdK+j2SLkl6TtIfkvRQ0dLjlGno68eoQ09UUkobkv6NpK6kzyqKYlnS50pak/TmJ3VfRVFcl/RTuoC2d/lk7deU0psl/X+SXpH0C4uiWJX06yV9pqTlJ3VfRVF8QNJKSukzH3TsG2VkvljSj0h6n6QvSSktpJS2Ukq/gANSSpdTSodERiml3ztG7a+nlN4TkOcXSPoBe4APqURi700ptVQa0u8uiuL7U0pfllL62ZTS3ZTS308pPTs+/xn6y2mrlNJvSyn9cErpT40R9c+nlL7Ajv2UMRO0m1L65ymlP+/RjcqOfiml9MIbbLOmyCPtW5PvVNXZfLGk7/ADUkq/PZUpvd2U0odTSucCyZTSsyml704p3R737VeHQ94v6Vc9VAs0Sx5pf6WUPlXS75L0G4ui+GdFURwWRTEsiuKHi6L4bXbcs2N9vDvWzy+z735JSunfjO/rekrpzxEtp5R+cHzYj6UyFfIbxp//6pTSfxz/5l+nlH5RuNY09/Xj0qH7ip8jpXQppfS9KaWdlNKPppS+KaX0w+EnvyKl9KGxffzzKaX0gEt8naRdSb+lKIqPSFJRFK8URfE1RVH8+MOcN6X0O8Y6fi+l9E/cvqaUPi2l9M/GY+qnU0pfdM5zLqeUvj+l9Gft3O/XxY+BJ9avKaXVlNJ3jMf8R1NKfyiVvlHj9794/P9vGV/j7eP370kPTl19o6R/XRTF141BoIqi+OmiKP6noii27LjfnFL6WCpZmz9o99ZKKf3+VGZMNlNKfyuVIJfvf+lYh7dSSj+WUvrsc57xmVQyQf+rffx+PUw/FkXxcb8k/axK4/aLJZ1KuiLp2yX9ETvmf5b0j8f/f76kG5LeIamn0okVkt4y/v5vS/rfwjXaKsHD35H0MZXI8L+RdEfSOyUtSPq/JP3g+PgXx+fs2Dner5LFkaTfNr7XLxuf+yslvS4pjb//NypZn3lJv0zSjqTvCvf045J+zRtps6a8HlPfFpJ+gaSbKqO3tfH/v6Ackvm4X6UyskuS/mtJB5LeOf7usyW9Ov6/JenfSfrD4/57SdKHJf1KO9c7Jd190u3btP6S9BWSPvIQ9/EDkr5V0qKkz5B0W9LnjL/7xZJ+qaTOWE9/UtLXhvHwltBXtyS9e6yrXyLpIyp1fur7+jHq0FvCZ98gs1nhHH9j/OpJervK6PuHw7H/QKUuPj/uv89/wHP+iKRvfMAx555X0q8dt9XbxmPjD6l0qJK0NL7H3z7+7p0qbf87xt+/T9I3qWQIPyDpm8J1/3tJ//6ToV/Hn3+HpL+n0g++KOlnJH2pffd7xv//JUk/J+kr7bvf/YDnuiHpt9/n+xfH9/WXVbJvny7pWNLbxt9/7XgsXFOpo39R0l8ff/ecpE2VjHtLJWO3Keny+Pv3S3qPPdPvDNf+Okl/54F98wY685eNO/Gp8fufkvS7Jf0KSR+24/6VpC8e///tkv6YffeW0KH/TNJX1FzrHePjvnD8/r2S/oR93x/fy4t6OCDzs/Zdb3z8VZUKNpDUs++/S2eBTH6mT8bX4+pbvpf0f6tM133FWEneIgMyNff3dyV9zfj/z9YEyLxb0sfCsX9A0l+x92+VNHzSbdy0/lLpXH4kXPdVlanBI0kvSHqTpKGkZTvmj0l63zn3/bWSvieOB3v/bZL+z/Cbn1YJZqe6rx+zDu2M+4HXkWqAjEoweCrpZfvum3QWyPwye/+3JP3+Bzzrh+J91Rxz7nlVpgC/1L5rqQxWXpD0GyT9UDjXX5T09eP/3zdutw8qgIHx95/r7d2wfo0Ata0SOLzdPvtySe8f//+lkv7++P+fVAkM/sb4/Uc1Dv7u82ynug9o1cS3XrPPPqCSpeWan2PfPTM+Z0fS75P0neF8/0TSl4z/f7+kP60yUPlNNdf+Mkn/8kH980aqkL9E0j8tiuLO+P1fG3/2TkndlNK7VSK8z5D0PeNjnpX0b+0cr4Rz3lNNLq4oiv80Zgr/k53n39v3eymlTZWo77WHuPcb9tuD8bn7kp5SGcF5/c0rKg20y7JKg/HJKo+tb8fyHSodXlI54CuSytTf10v6VJVGrifpJ2rO84KkZ1NKW/ZZW9IP2ftlSdvn3EdT5XH016ZKw5SlKIprqUzhnqrsu2dV6s+uHfZRlTl20lN/evy+p9LA/bv7PNcLKqn7/8U+mx9fZ6jp7uvHqUPvLIriZ3mTUvoGlc4yymWVbe7njdeQzD6qBBT9mmNczoyNc+S8874g6c+klL7Fvk8q7fkLkt4d+rmjktVAfpWkPUl/oeaaF22rH7dtdHlK5fj/qH32UZXtJJVs6J9KKV1VqQt/U9LXp7KmZ1XSf3zA+S+iH78npTSy74cqGasXJP36lNJ/Z9/NqZw8g/xmlWzX/1tzzYfqx48LyKSUupK+SFI7pcRDLaikDX+hSrT9m1SmCf6BGbbrKmknJAKEH1fprB4kr6tsGO5nSSW1+Jqk/fHHPZWRilSyLQ8j1yVtpJR6BmYq9zg23G+R9GMPec5GyRPq2x9SqUCFpB+WFQimclbAd6vMS/+9oihOx7neurz9K5J+viiKt97nEd+mT6K+e4z99S8l/bmU0mcWRfFvVS+vq9SfZbvO85oEF98m6T+ojLh2U0pfK+l/vM/jvaKSrj8zYyGl9Fma0r6eAvt4ntxWyThfU0nf113jjcg/l/TrUkrfWBTF6IFHnxX6+a/GL8a1Mj9QFMXn3uf3f1nSuqTvSyl9flEU+/bdhY2BKejXOyqDhhck/efxZ1m/iqL42ZTSgaSvVllqsTu+z9+pknV7UN/8c0n/g6S/8hD3UievSPodRVH8q/hFSukVlYzMl539WZZvUJmG+2sppd9YFMXQvnu4fvw46bXfJOmuyka8aq8flPQtKmnf6yrpvi+0333B+PO3qQQa36EqxfZOST9zzjX9uM9RqZSfoXIg/RlV6dFXVeYw25J+h8rO99TSD9/n3D8i6U+oRL6fpTKic5r2v5T0nz+e9mrS63H2bfj+HZrkvXNqSSUSH6pMJ6TxdQ40zoWrmlpqq4zwf5/KHG5bZb3Nu+yaf0nS733S7dzQ/vpWlRHT51r7/vLx714cH/NDkv6cyhqZX6TSqH/u+LsPqKxpSZI+TWWayPX2hqTPs/efqdI4vnv8myWV0ffyNPf1k9Ih++wbdH6NzN9UySL0xn3wMZ1NLXl6730KdSc1z7uhMiXwnZJeGH/2nEr27Rc96LySft24LdD/VUm/vpjo/0cl/VaVEfycpHdpUpfxPpXpsaQyRf39krp2nX8q6Ysa2q9vV6lHvNoqSx2+Z9wuL6hMbb3HfvfXVAbwv3X8/k+O359Ju9U835vHz/cnJV0df/aW8TXX9OCyjd89fs8YuKxJOcibVOr3rxw/x6JK233Nz6PS737f+Dladp2fkfRLHvgMH2eH/mNJ31Lz+ReNb7aj0uDdlTQfjvkD42NeV1loW0h6k33/o5LeXXPuqAhfobKY6a7KIjLP232BpJ9XSUV9i0rK7WGBzJtVGuNdSf9CpTF8rx375yV99UUoxjS+Hmffxj61zys1MioL526O+/M7VRYrngEy4/fPSvrr4/u4pxKY/orxd4sqQe6VJ93ODe2vpDLa+wlJhyqN8w+Mr9UaH3NtrI93x/rpdTa/XKXh3Rvr2P+hqhP9ivE5tzR2PiojtB8df3ZdZWHk8jT39ZPWId0fyFyW9A9VOrcflfTHJf2L886nhwAy1hffPr733XE/f73G9YYPOq9KoPIT4/t6RdK323cvj+/5tsr0x7+U9BnxPCrTzt+hErwsqmR5X41t3KB+ja/3qGSevmvcFq+oDAzc4X/5+NgXxu9/9fj9GZ96zjO+rFLHNlUG8T+mspatrQcDmZbKotyfHo+Bn5P0R+3Yd6u0F3fH9/8PJT1fc55FlezQ+8bnfJek//Aw98+MnccqKaW3qUSvC0VRDMaffZ6k31UUxa997DdUIymlvynpp4qi+PrxVLofkPRfFOU6FTM5R6axb8e1Fm8qiuL3PonrT7NMY399IvLJ0NePo09SSn9cZfT9JRdxvmmScc3NzxVF8a1P+l5cPtl07VFLSum7VZIJ3/fAYx8XkEkp/TqVSGxJ0v8jaTRNnZfKxYnuqmR0Pk/lDJnPKoriPzzJ+2qCTHvfzqQqs/6aPnnUfZJS+jSV9P1PqIx0v09lJPx3L+oaMzkrM117PPI491r6cpW00s+prH34ysd47YeRqypprj2VC/B95QzEPLRMe9/OpCqz/po+edR9sqxyTa59lcWp36JyXZL7SkrpL6RyocL4qpspNJOzMhW6llL6R+f04//+JO7nouWJpJZmMpOZzGQmM5nJTC5Cpmb365nMZCYzmclMZjKTj1dmQGYmM5nJTGYyk5k0Vu67IN63fuu3FqPRSK1WSyml/BqNRhoOyzVrWq0SC3U6HaWU1Gq18mcpJaZf5WlSo9HozGecE0m2VxnXlqThcJiP92P9fH683zPH+f1xL/5cCOfkOz4bjUb5d/6c73nPex60wdoTl6/6qq8q59La80jKz+1pxvn5ebXbbbXb7TP9xu99XNAu/jnSbrfVarXUbk92hB8Oh5W29PHEZ1yPdpYm4yz2sfcp93FycpLvxc+fUtJgMMjj+PT09MzY+bZv+7ap7s8v/MIvLEajkVJKOj091fHxsU5OTvJzSspjvd/vq9PpZP05Pj7WcDjM/XF6eqqDgwONRiN1Oh0NBgMdHByo1WppYWFBnU5pJo6Pj7W0tKR+v692u62FhQXNz89X7MFwOMy/9THg9zU/P6/5+fl8f7w6nY46nY6KotDR0ZGGw6EWFxcrfVYURb7ucDjUycmJTk5ONBgMND8/n8fSYDDI1/3e7/3eqe5LSXrve99bzmNttSr2jLbludDJTqeT24XfRNvo58H++XGuu65v0VYXRZF12G2kVOp2nQ3gWaSJjcaX8OJe+d159x7LH6bd1n7zN39zMRqNctvwvO43eFZ0i7aKfejibSKp4rPcHjI2GBfoHn0QhX5xYZxxjpRSfh5+w32cnp7m8/LcPCP9NxgM8jj2Mf41X/M1F9KX9wUy3gl+Uwid4wO27hz8pUHrjovAwZ1r7MD4F4kDxRs9AhJXLr+mK7jfWwRP5z1HE4Rnd0AiVZ0NEsFbbJvzJALdeH1JFRBD2/s9RKDlChCFY1AWfu8O269d178R4E2zPMy90qY4Q/oxAnZAHcJ7QBJ9MhgMcls68HAjxovruQFH0M8IlDnWjx8MBhUgEwES9+k2ivNKJZhtgsRx6e3lwRoS39f9/kEO0d/HPvLPpWqwE/XRfYN/5+eJ30s6o5fx2WPgFP+fZqnzI3W2p86e0qYenJ0ndW0UQWAdwHWb5+/rPq/zt9E/RzBUd12/z4u2sQ+1RUGdY5cmSM47KLI3USHrBmsc4P6+rvH882jU/Fr+1zvKjZ4rHmgyPjt/vVPr0PC0y3n9KJ1tOxxN/D0SAcp5/SCdD5DOUxL/HufpY8mv7ffo/VlnNDyiiPfqkWmTpE53ENrMwVx0NH58u93OYAHGxKPy+fn5CpvF7x0Qw9QAZmBHPDKkrT3qwylyPX4jqRJhttttzc/Pq9vtZgYJRopzSyUAch2ddon9xmd1ANDlPEfo9s4/A2D6b92euw54UOCMKm3L53WOk/f+LDGgjPfv98Ox97MR0yrxmfyvP4/353mgxT93oBHbmnP7sf7bGCTEfqhjxM5r//Ou688f7yfa2Xi9T1QeCGQiPegN4KDlPCXjgeoQYWyQOqHhYyf4vUSD62AjOi+PIrxB65Sl7p7j/00SB3CIsyN1x0o6A2j4nRueCFY8qnAnFEGqR+9ct05RcMbe99yHO+W6KCDeUwREkXFsAjD1cX+/+43OPDoI+g2Km9TS4uKiUkoZiJDm6XQ6mpuby33mOsexkQGqSyVARw+HwzNG3AMOT6G4PTk9Pa2kpPj9aDTKaaXBYJABzrRLHb3v+uX6FtsTqQMUrkuRkYvAoS7dy3jxdMHp6alSSjmVVxeJ06/RZ9QFUxF4xXuOejvt4vbS20A6y/5yjEskA1zXXeIxHoBGEBKZtQgmEe5vOBzWkgC8Py8Idn/rfjjaqou2sfcFMg5izkOZ50UD7Xb7TJrAB3l0fo7+Y8PWKaCDkWj43Im6oeR87lTj9eKznAfOzvt+miU6bE/FIT6Q/Xf+nSua9490FrxGBfAUkBtOr7GI1+K9p6simPHz1ymTVI0M+O5+zNI0C8yJvyIY9zbgeFgXbxeAADoLEEgp5dQRAIYXhs4NpTMvEch4rQ33Akg5PT3NYOn09DTfM+yLO26e4ejo6EyQ5e9brVZ+jiZIDAwcbPNsdaAQOY/1xK6iG/SR62dMCUZAw/1xP87web2OVJ8GqfMXdfoZnas/d/z9NAs+iPs/z0+43bufxMAjjnfprC+K6d7Y9n4u/877vA4Yu877mIhSZ59jCcpFAtMHApnovHggii6jk3LliN97dOcNHaMHjyL99xgmV+Q4EDyygbrmGJSvLqr3Zz4PNdb97n51G9Mm3LenGbj3ubm5imJhMP1354FWd1iR1XBGzY3S6elprl+oizQioKLvXZnOM2p10YjXcrhx51n93E0QL5zj2XAyLnWgdW5uLjMnRNoeAAA4pHKs9Ho9dbtd9Xq93Ib9fj8zNEdHRxU628eSjydYmKOjI3U6nVxQ7kXZtP9gMKjYCmdfer1evibsgCQtLCzo+Pi4Mp7m5+cfaT9clLhxj7a2TqecKfEAAaHtnTkDyETbzDHRLvs54/HYVYAMYIb7dFvLGJMm9pVx4mOzjiWIALUJ4rYm2hbvQ6nKKMcgKwad9GdMNyF17Cy/i+DBgZb7d7/vOAHDQS/37vcd08Rct86+X7Q8sNg3/r0fi+EgICohQCQWHTKIY8Eh53PFIpqIUUmM2h0ERcWKtQE+uKLBiE4zMgyxnaZd3LhEBYrAEIfmA94NYgR/kQVB4eJMM1fKyAy4QkWJ0TbPUxcNeF/5+IrnqftdHYU7reKBA4wJzxqdW7vdzmxHnT67UcMp8Xt08+TkREVRqNvtamFhIesVDElKZbqB9BTj4Pj4OLe/sywEQ5yL13A4zGBqcXExG3Du/+joKF8PMJxSyvaF9w7Gp12i44rfuU1zuwfIq9MvbCHt4u851gMRZ3C8LaXqrFQ/f6fTyWNgbm4ujx+fXRhtbR1gOS+6r2uPaZeYWpKqzh6BEIizOT1I4TgHex48o2du030ccT63m+4T64J1/xvHFt/V2UjXvRhIxv/jOPhE5YFAJho9v0H/6ywMN8x3KAozIGJKAWOHRKBSFEWmn/2+cKAeQdY1EsfV5eLr7jXeQzz+PIMz7RLbJjqyuijCB6BHgoiDI37jU+24BsrnwMKpf66NYrtjdQXFWNKnXNvPFQ2lOzUHqx7RxuikCeJGK6Zd3RguLi5W2CivL3Hw76DImUwv7mTKM3pxcHBQqUWZn5/Xzs6ODg8PNTc3p/n5+TMpHk9VxfHT6XS0u7ub76fT6WhhYSHfBwC51+vlqd7U9GAH/Pnq6rumUTxFKFXtJu9dYj8jfHZycpJ/7wEk09UBJB6cuOOLzDl9FZkWZ2W8js0dndtytzGcoy544Nxua5sSMEpna0tdog2K/ecv76cICOhPaQI0I1ByFsdt8Hn2MNpB75+6e+VZY5qKgATxvnOQdlHy0EDGbzw+jCPEiPIdsDhd7H8jIxMf0kHQmQcIMxqcKvf/ETdudewCzxHRqiNhB26PolMelcRniv3jhZ8xdejgAonKSj9FgOuOjO8wqJ4SIUKhvyJz5OvRuKJ7H8fIlvPDVvgzOBBwRWyC+PoTUX+kSTvAdvAZxw0Gg9o1LKQJ0HBWZG5uTp1OR4eHhzo+Ptb+/r4WFhY0Nzenw8PDfL6TkxMdHBxob29P7XZb/X6/0sfuZDlvu93O9w4gcRvh61QAgAaDgebm5vLsJQATs5gAX4CgaRcHCT523anF8engNP4G9gxnR3v6WkMcS3t56snb35kDt6lzc3O59skZN87hQJVz+doqHBMDiPuxNk3Qzxgwu156n8b+ls7OnnRm8zzg6dfwtBa/9xSP/ybaTLezXmQfmaBIaOBDGR/+G4IRt7Fc8yL95kMDmYiIz0OZ54EYFOP09LRS3FeXy+Xl4MdzuzHNQKOTd0fJcMYUJ6JIFCzWUWT85ry8Xh1oawozE9F6ZGcwKnVV7xwTUbtUzbFHAyyVC6l5n4LWHeDw/8nJSYV1oe+kCfCKrA3H+zUie+R9hWJJ1Wn3bkymXRxkRjpYKp+LheOYDh2FNooGxfsGRsejOcCpn5M+xlHSZ25EcXIsyHdwcJDBEN+7E6WO6ujoSEVRZJ0+Pj7W3t5e7nfqYLjHlFIG1IuLixfY6o9O3L44/e5t7s7EGQ4HqPwfAQl29+TkJLcN3x0dHZ2pSaL/fIx56hGmjPHloJigk75dWFg4E1h4tO9O3a8VazOaEjTyTP5sPLtU9auxXu88oBCBJS/XU2wjvwGYcowDCvygEwB+b9hd0sB1pIaDojo2EeF3j5IdfeD068jC1NFhPtgchTqA4cUqnA5mXPH4ru5zBzLuUL3gjFVD/f9Wq1UBOOTdnQaTqlN/o+I4tea/i502zRKBjFQ1Gh4ZOTXoTJizUXU0eEwZFUWhw8PDHFW7A3Sg4e3tqwoTWceUB87PFcgNhUc1bugj04Q0JdpDYoBBRETbLywsVKZLsx5PNDAO6qJxOj4+VqfTyUDm4OBABwcHkpQ/Oz4+zjUr9BX6GGcu8t7bnnEBRe5r0LgNobYGxsWjSmpnWq1Wxb4AlpokbkNdXC9d6C9nt2GxHMSw8rODFgeK9AO67Isfcn3E2RjSh91uNwdAOMHj42MtLi7q9PQ0g1AHxNIkLeH6H5/fnXodKz9tEtkkZ9QQ1wHXCQcv/KU/vH4m/oVZc4ADQ+7AmHMS6MCa8RfgRbBPmhY7EP38w7SD+xpnoS5SHjhryQecN3KkzdzBReVypSEi8KXF43EoHUWCDi5iUalHCG7sULDFxcUcObghXFhYqKQqHBxJqiBbnssBD9Ik51fHyHiUFBdN82fzCC1GE96XDj557e/vZwPqv/d78OsBZJzelMo8fa/Xq8zS8SLE2D9194wy0afkjwFuTYj4pEkEFJcjTynllI2kDOi9bXzqNkJ7HB4eSioLagEyOzs7GgwGFSDT6/UyE+LpYZgZIn0YGnQMB7u4uJjvk3saDAba3t7OQc5gMKhE+/FeOSdOk+fit01hY6RqAaUb+ejgzovUPVoHnABoAJpuW+kr9DKm7mOg4gGPVF3Zud1uZ+C8sLCghYUFDQaDnO7D/uIcfRo+wYUD1hhgxjaZdokBg6eEkAjYvH+d3XZAH22sHwNJEI+pE3wZPtJBKXaXvsIWEwx52t9T/HzmAbHjhLoMwEXKx7Wyb2xs/ufleXBXMlceAIpHAq5wrnh0hg+AOLhjBEgHoFDHx8cVJWOPFnLs/jsHa1K1huK8hX4i0p5mcYraI2/p7EwfBwFe9BdTMu6wXJm8FsLrYaKCc07GVKx5AqgQERTFZK+dSIfG2TZ+blckxmqkTB+Vkj0KKYoij3Ufj26MPK0D0wWTJelMGwMGYDj4zvsUVoX0EML/6DDTog8PD/P4gf2BJb19+7a63a663W52kMfHxxkMYReo8zk9Pa2kIxhbRVGcWcsksoZNkMjyemqljhF35ooXQaLbWuypAxdnxV1/GRs4QQ/g4lRrr5nh3IuLi1paWqplEaKv4HkQnH3djKdom6dZImhxG+q2jnbx1BMv96NuZ9EtB/v0H30cbbs0qY/kO+wfPhAgQ4BBAHR6elpZBDPWSXm6StK5NtUBD/JYa2Q80o0Dyx1TSqmiIHxH8R/fHRwcZMPIRnWDwUCHh4c6ODio5HK9s+teXNcBDB2DEgNo6HhfUdSpUQYUSsQzesfU0fm8b4p4FOtK5aDNFdGdXl3qkEJPlAmDRj9ybGRr4vliqg8lc8fskWNMpfgaBtyvNIl0Aa4xPRnp+qb0JaCFdAoMBd/RPox3GEjXXx/rgHvXdQwc/x8fH1f0nNkvnvaF4nY2td1uq9vt5uuQPkL/YWgIeuhHxpcDUwymF/TCQmF42+12Th8zBqddnC118CDV1yoCWrwWxoNEd2xHR0e5HWlTfsv3zo5LE5bN7axH6p6OYEzAtmO/YWZiqpmx6mDbGanoCM9LOU2r1IGv89JlMMEOYrBX6HVRFNlvEujTx8fHx/k7/32dHfN7cUYXvUGPYEoBpRGo+EQABNviSzz4OPbfIxfZn/cFMpGBiQ7OQQWNz0CGXvbGR6Fc0TB6KJ0jzYhiGdTR2RIdUHgGpenMEPcHI9PtdjUYDNTr9SQp7+Lrz46Sel4P59ckJgZxAwFQiP3K80k6Y1h8PLBjMn0JEHX2BWOIYfM+dGqSY7kPwIUX/ZImjAwdAIdUSiys41l9DHstFP3Mcc5GTbPEYnUv3JMmBgOam/aDDZGqUdL29nalSBca2Y8hLbu3t3fGWBIM7O7u5qgQQ8YidgcHB1kXMZq9Xi/n3h3kMmU8GkKmfgN0MKheZOx9f3R09Gg64BFInT2pYyywbYD60WiUmSxnuwkMcXzR1vrxvryF6zljDL0kUIygJvoA6mNOTk60tLSUnyP6jWh33P44gOF3TbK53PN5DtsDx+jvnNWOPvPg4KASOHrmIo5/QCPt5n3stpWgHv+9sLCQdQ42dTQa5WMWFhYqwS/9WFeHJ9Vvw3CRdvahgYyDCRyB10KgWE5RgvhxcoeHh7lTvE7G87R1tTGRlnLkiUP0fJ1HoDGaiY3s69f40us0dIyMuD7v6wrwplUY6F4jwjOcl47hN27QMI77+/tZqTyt5EDGU0w4WleqCFo9WuB/qGwYgJOTk+ywFxcXKyyTT//2Z8Lxc526NpDO5q6nVTz6cfG6Ba8VcoPiM/O8xmJvb6/CyhRFkUEJukJkD3CkXUnj0sauF5wHg8h3UNgxmnTn5ewhRpfaHICL1zgBgPltU4Qx56kz6SwI9/5y3fE0Q3R26KDbVk/7+6xCqVr0HQMCDwz5n7GAOJOAfXb2j+f133nAiD33tJTfw7SL+yGpummjB+H870XZzjhG4HJ4eJhBqNebeqG3n98Z0joSgLHGfdLO2FH3DT67EAZH0pkUP8GPM+1uy+tYt4uQB9bIYOg9KvcbBdD4yxe+g/ra39/PQMapaWdx4nmcenM07krkqNYbCMWgM9rt9pnly+tACr+Nxb6er46MxaOcVnaRwv1GJO3gNFKSGDQvqqQ/ib5Ho9GZGRHOyDhzQCrCDSWKw+8wfEUxqafwgjYX+tYVFKU5OTnJBtSvJVXX7eA8fN4EYxmZI/qI+jB/DvoHcYAzGAy0u7urra2t7PQALERdkjJ4dUrZ65c4F6v+7uzsqCjKegdf68XBMKnffr+fIz7YHmkSPVKs3O1282wpr/FwPYYpaFo6os7Iu82h3bCrscjXWW+CRlhQvqsDQOgn9sBTztHmu5ONtsLT8B7oYhd8vZgoMW3m4DSyNk0QB191zyGdXYHZa9MApB78x2yG+09nrLxPfTxxTa4lqZIiGgwmEwC8fz3gIVXo10PHCWg4j1/bA0sHdBfpNz9uRsbfO5qMHQLdyUwHkL/nz2PRGeeJs2fiIMBwxoERc7F+DiLRKF4Dg8OkM6XqHHhHmX6dpigYA8mj89jG3qf+OdHc4eGh9vb2Kuya53NjgZ80QeoedXM/kiqLtnkf4qRcAQHJKB396tFjURQ52uP+Y/2HG2Z3FE3pTyh9nosZOhgTPmdM86zMICPiPTw81M2bN7W7u5sjv+Pj40pRMH3sU7ldl4qiyEzN+vp6/t3h4WFeRI80LgwMqay1tTX1er0MOmFsGAfYhpWVlcy+RSbGhb7l900ApVJ1cbp4zz723ZG4MwMweBqpLsDwsUAtEbrp0bNH9K5bHky6fro+Onh0ZsHZ2JjGdRYqLqzm91Nnw6dRnK2P2QS+pw29H2OwyP+x9CKOhWhT4zUdOERgitDWlGAQNHAOfHPd7wgo3c4yHjy49OtcZF8+1DoyDgo8KogMTAQnToH5lD8vNPNI2RvbgYMDKMQjfqkaxdQ5P1cUaWLgiBToCP99NJSRCq1Ly0y7xGjL0bo0WUWZAUk7E9V5tOffoYTOhDlw4NyuQM6Y1TldPvNUg1QadqaXjkYjdbvdrByx4NVBjEe4cax4eqIJDBu1CqRZvF09MsOZeXrJ2ZobN25oe3s7R32k76hrcGBJCoK6Fhia0WiUGRxJOfXX7/crU7b7/X7OvXe7XXU6HfX7/QqDRx2U1+e4gfXxgSHEAXsg5FPDmyIOpnmPbYzLVbht84XuPE3rICYCdV9UkrZ1O1wHZPy+op5zDnSMc1NXdXh4eGZdGvqIdWakCWiDlY0SGeNplMhGuC+i7WDRPBvB/wBSn23mkyjQQ67FC1spnd1Y2XXf9Yr+9wwHgk8ktYR/dj/N9ehnno/n9/SVAx6fqHER8kBGxp20P7CDFj5zR+UAxmtiADCuNAxqT9vEHHsEC3WsQUz9RIfk9S/MjsDoUsQUo3bEnarThpHin3aJ6UEfuJGRcAX0wkA3qq4AGEcfwA4s/JwxIiAaBUhxjE/xg33BeVKTgcEriiLXPLkCcT8+Pt1IMq691mbaxWuHJGUAQv95VB91hwDg5OQk74vEWjFSCTjoN6ecKRZeXFxUv9+vnJPZgaPRSEtLS1paWspjhnTT0tJSLixcWlrKbIAbNGdO4/Tyvb099Xq9THHzeSz49qiwCY4PiQGbgwRPQ3gKNeomDtF11O2nLzWBHrn4dTyA8DS+18i4uM4TQHhfMF6ZAcdv3Be4TeX+msSUSlV987Q2LwKEuvSg1zKxHYiDGo6vC76xvehPLIHg/whavfyC33EOMhNcg2egNsbBGZ/XBfc+ZpGLZEvvC2Sc0oufOZJz+j4yNY4meXn07MWJPo3a1xNxitFRJkrqDjcyPM4M0HBEfNxfu93OsyEQBy6xYCkyDU1RsNimEcQgXhcB1emG0vsXB+ogg8Iwn+Hg14hOhr9uqH0s0Y9xvPE9M1M8JegGNUZ33gYor7MZTehPZwfdIDjDJE1mLcR6GtJBtB9RIdMuO51ORVcBMktLS9nBzM/Pa3l5Wd1uV+vr6xoMysXPVlZWdHx8rK2trQyK5ubmcj/Nz89nvUMXPUqL0aU02fF6e3tb165dq4AX6t9ge6gNaZI44xGDKP/cqXqP6j1F4QWh/N71kyUnYPSiQ+Rczg65jmLrfZIG+ipNnB76iZ65nnoq1B0odslBlvubJogH44gDmQgm/OUTXuJUep7fd4/3wDH6zQhOGGORhPB29YwIgk45i88yB9wDLFH0L95v/hnvL0oeeq+lWAvjdRDOyES6M06pZlDi8KCBmb9O9OYgp64B4qBAib3zvUKfY33GBtE/U9w4N+tvOLKNKLsudTLt4oPT2zLSyRjLmLuNBsUNJAub4QiJ0L0QzPdEqiu0ZXzERRIZX0QpdZX6pA9RopOTkxx58nvP0UfmLU41nnbxMewsVUzLSWfXswAEHh0daW9vL0+bb7fb6vV6ee0I0naeAmRF3+XlZRVFoX6/r42NjQwg5+bmtLy8rFu3bqnX6+W+Hg6H2t7ezmmDxcXFnP9njJAijDUwpDGlyYJ5sEPoq287wgyqWMszzeIAOgaLXm/mNs/rJDz1C7OJ0L7tdrmeT6/XU7/fz/rK+ME2ur67OJM6GAwqhai+ejcMW0x74hAPDw8rgBtfwPNx/ljn1hRBF6NtRWLfeprQU4QxJSUpz9pz4EL/sv6Ll0v4XkmSKr7a1/1xFtwBjhMIsGTY5rm5OZ2cnFSWdOA+vR7GfUoMui6sze/3pdNJMa/mSD2CGxrfp4e542Tg0in9fj/T0e4QWYk0ziRxNigWtfHa29vLRamxKCpGDKQoaHA6Kz6/U4PuKJoSKUTwEPvVB7v/lSZtjmOiTQGhy8vLuQai1+tlxxSjP4+4nHKWVKm3ikD45KRcQHFnZ6eyPoaDqhiBkrLkWbnmedGu/512iVE645TP+IvBiylQgMzh4aH29/c1HA61vLycgQxGq9vtajgcZgO5vr6utbU1rays5P6/fPlyrpGhfmZpaUl3797NK/sS0QFKAKaehuD+cWDutL12CYDiz8f5MOJeN9MU8bHp9i2mJjyadlAaV1vGmWFrFxcXtbKyknUVMMj3RPOu/85+xntg886dnR3t7Ozk4lSCDdclACysqTO5RPfYZMZJrKFrim76ciD4CwcTzjbWMcyebnJWC32k6J2+Q++WlpayvQXEuM3levQf/pkZxT4RB5bWiQxf7oH+kyb21tnbOobf7VK0w5+oPDBc8RQLN10XMcR0A5GTI0ucIE6u2+2q3+9nxeJF/tz36KAjo1J5LpiIBBCztbWVI07uxcGIPwcDDTou1hm4ceQ7T3U1RTzlUpe39PccJ03YEj+GcwFkVlZWcsROHQWKBjvjFHcsHHPDHRfsoop/YWEh929RTNYnIW/MeVCWGNW5UfFp3q7sTYji/VlcBxmjHmx4ihT98RVdpcmeTGzncXp6mh0dDMzq6qre9KY3aWlpSVI5K4m+73a7Oj4+zn2/vr6uoigqhdh7e3vZ2eF4PYWIXlO/BpPjM1h4NnfYzvgBfAExTQky3LBHp+Zst7Ok2Fuf0YJOowudTicvPLi6uqqVlRWtrq5WgkaP5D1o9HSS13G4nYfZYZzs7++r3W7nNYm8zsbrYhy8AGgd1LqvcBDQFPGSCOns/lmxxtMzGc7i0N4AUrIWZDAWFhay/0QP8Zm++W5M03nW5ODgIM9aZM23ubm5CvtNoDgYDPJWMX7OaNP9WelLD5YvmmV7YI0Mf12ZfBXNuhlLXuAb61VwfN1uNzs/jKRHC6SYqLfwhbTidXF2RAi+3gQd2Wq1znQMxtCdsqfBPK3l6QnvlCZRnq5U0WjyPHXgxqM/lI6IHVBKREBEDihdWFjIfclAx7j6dEBJZwylTz30VWm9kJdon/GJA2OWhIPNyDxJ1U0kHaROu/Bsbkxi1Oo5cf53EMF3knL/OQMDs0b6aG1tTWtra1peXs7pHX4zGAy0v7+fr93plKv5us4Clvb29iRJy8vLGo3KTUWdPTk6OlKr1crbGsCmScr1Oz7lPvYxz+pAdtrFmW1PHfl7Z6ccxPjCdy7tdjvrn9tabOzS0pL6/X5lZVfsm1TdT83BC7ad9WH8eC+Y95WcPdAgKHXAyfljbZS3T1MkjsfzSjAYu+dlNAjkpEl6EJ3r9XpZZ1dWVrSyspL7FBDjGyhLyteOQObo6Cizaru7u5XaG19ig/vFHo9GozO1bR54ePrbbVNkaC5CHjhryR1XXWO78uGIvADN6W4UK3bAyspKNpIoG87Pc4I0gF/bOxzF8h1WY4PVUeyS8j0T1XmBqNP20Rk2KVKou9cYMdCXSOxzH5hECb1eL7NrODaPEGBpfEfVuLQ5Ch/rY1jgDYrUqXcfZw5KJVU+j0aQsehA1z9vQp/GNBL/w2K48+c7jvW2YVolUROL4HnA4QCGNX/oF2pocECAEQAuhYBeQ+P1LNwjKWCfpXZ0dJRnKHn9kzRJk3o7YLRbrVZmmpwOn2bxwDDWJzgr45/hhHxjThf6YGlpScvLy9kBun7Sp+74JFX6k+v7jMXj4+Ps8KQJaHYb7UCMY2DOCUwJHklVOAvjjr5p6SWpWsDtPgufGv2q2z73naSJYNC8P1dXV7Nu1hEAvqglNtKBMKlAt8/oc7TNUpU9Yk0oVvpFTz3Yd/G+u2iW7aHWkfH/4yumlVzppOp6MNQseMEZtTGeWood4hSZNElzcG2iEgwg1/L7jNRoZGWiU+SZPPIn4o/t05RowZGyRwx11fXevuRKGdj0gxf5YiChselHQKtvF+/OkmvyF4OJofT75n6Hw2GuyfBdyx3ouHE4OTnJU4NdgZqYf0fcsTsDQT7dX14ITK0C7cTO06PRKNeaSKqklNbX13NKAmbMgwXGBLOGOBfTbL3IO7IG3J87NM7peuVrxvhzOIsGE0D9wP7+fmNSSzFActslVdd3ikx0TKGhpw5kCDCceeN/3zwXO+uz+Rw48XKmi+txD9gM35zS+5Nz+QwbB7D0Ic8dazymXTw1x8vbxwFazF74cT6u3X46EbC6uqrV1dWKrcUOY2djDR2MDGmlOKvU00/UXeEP3b6mlM6sY4StcfDkPsbv5yKZ74eafu20mAMAj9DrGBsHAFJ1G3gamqjPGRiP2j1SoAHcMPuAp9Ldp2GCOPf39ysV3ZF1gP7G+bHxZDSS54GZJoiDPKk63Tmmm5xSjpGgNOlLIigv6PW8e5ySzefuhLgXT3WMRqMcjXNP5Gk9TeVpJpeYJiO1EUGMSxNSSoin5dxouD66AYUVIZ/tjsr3JqJNYXcAqMwkdFbVa1e4F67tRtRrHwgOcE6MQVJdXgSKLqKzMT3hRYUOUnkxxbcJ4mBUOtuX0RZ7Gt9trqTMrnndE/bUZxR66sHBaRwf9B2f0+5euE1NFdPgse2sheI+wyN5UoTuLD0l4aC7Kal8wJf3kzPGkYXx2ibvb5go9M77Exvr9Ule8+RAxmvpYjBKu1PbBvA8OTnJtppC/bq6UMcEPpMJ+xExgN/PY08teQO4cjk15p1QV3UN1e1Oj84BYDi15dPLYgqABvXiTugtFrZzEOSKvLCwkGlsl9FolCMN8rfcY6RGcYhNK0KjzWKkINUbTvrNo6E4kKPxc2MnVenEugjagQXn9/72WTf0q6cPqZlwxw7A5TliH8U8vNcHuXOcZsHR+7MRGaGPzkp6pI8uOCvmeXefFQGbgqBD3s+RGaKvAFkAFh8r7ELvOkz012q18lYIGHkfgw5ecIxc0wErtqAJEvso2leezYMPj+Jjaonnj7USnkJwO+ZBJmNDmjDqgENnuOkj10muxzjBnvuUcE+LAYbZhwv7Kin3JWPIbfE0iwMZqcrMeOYChiMexzkcdHjqNK7R5X0XgWhkP9wuOECSlANOiva9//Cvsc5F0rmlJ14vha1yv32RdvahVvZ1Y8hgi9F8XS6Nh3Q0FtctoKH4i5Fz9oRjYwrEjRtKtLCwkAcK5/I6G6+PcJrbwYoXEnu6yhmJpqYknLb0+4+KR9t4YR4CkHTFcnDiLwekTiXHNBdjzH9DZM99R2X16zgQis8qVWsq/HNX9PNyu9MoDippKy/4xFB5pB7pXhxRq9XS2tqaVldX1ev1JE1mMXEtPvNAI0bL9AV6gs0AtLB5pDtfZwYODg4qzo4poKzxRCEj4mOU8/m90wZNELevzjZFpiUGjJGpkSYrszqIgUlzO+l/OY4+dr3E+XgQ5IEOINVBjJ8PXY/OmSnWAB0CFp6Vz7x2rQmsaR0wcQfvLJr7neg/GRPokPtI+th9mgf+0sTGowNemhFtHhkIHwP87z7Ox6lUDQqdSXJAyncA0UdhX+8LZDBGfmFnZpyJiXlAOsUpwug0vBIbKtLnxrti1DUozk2agAx+45vQOVPg1HlUfj+vR0Qx7SLV75w97QIq9sHnhtBTNO4IaT+mTEoTp+ZAwtsZtoQXU+phUGj/aDC9CI378yKyyARIkwXf6C/AlzsDrhPvl2M5TxMMpTQBMgByr2WK4JR2BgRQW0F70B8Y18iaem0T2wtAaUeDhs6jZ8fHxzmt2+12c0qBmqXBYJD13oUUGDNyPBihr+tYGsaYT8lugrjdqWNnoq2NNsnfM6bd4cW0vaeYaP8IZKTJOPNUO/dB6hen5Y42snXn1Y345JAYFHP9+HzTLh44eDt6P0pn6yuxcQTSXh9TFyACVn2pEt478In+yYNIdNBtuQOcaC+d/aPPEe8/xMeyVN1377HVyETQEmckeVQgVbcvZ8C7Y4nFR44qY6qB46GxYUa84yMI8evyP3/diTEIIh0bi9J88EFzRmWKHTXNEmm9mPrjhRPxPnSkz/tIW/sMI6eyfeFDpsV79Ml1MJSeG459G1NOfg/RUPCcks4oZ/yuaeyap2FarVaeveKFeymlCrgHWMQVWL3IMrIYzojOzc3lmRKrq6uVIl6O8yXV+/2+Dg8PNTc3lxcx5P7ceQFyer1eXuSQdBH9LCnXZKysrOTvPdjwMelsaxPEa8McmEYGyyP4OF7pcyJsj9JjkFHnEB3MOFB2Owqj4DbVz+nsqjRZHA7hnDGN5L7G7RC/cWaoCeIBYew/b59o3yKzTBbD2euYpXAf6sSApwjdJmLvSf96usnb3c/tTLiPQf7GQN+f+zwQ6r73E5WH3v3aa198YDmdJJ1dIdVBDMrFQ0Ab09gsX+0K7OIgRVJeAG9/fz8vtsViaaxWiNF2cOOpC+4lokbvJJgIzydG9qkJ4kg8MmhuQJxdcWbNc9pOTTtbRnvhkJgaT2pqNBplVgaDxm9JJ9B/jAf6Mq4Xw9jiPjyadZbFi954JpykdBaMNsFY+qJxtBvMFc/nYBED5M6BtoEdQZzJYDl5lqF3Vm9tba2ymJrbAO5pe3tb9+7d0/7+fl79lZSCVJ3uj+HkL1F/SqnC7K2urqrT6eTFEJmmz/l8Z/QmARqn7WOdWmQso82hDUkhUec0Go0qa2xx3uPjY/X7/Urtiqfc0XvGk89y2d/f1+7urnZ3d7W/v58XUot6inikL018g6ciPWj0FEd06k0RByTuN2NKycGg/3UWxEsvCPiYtcbaTfQP3y0vL1eYaaQoivy7nZ2dvPr9/v5+7kv0hwDF74UggWCWc8YAiHHnv3fbc9HyUMW+vGIRL8dEBO3iaM5prpOTE+3u7mo4HOZVeFHCfr+v1dVVPfXUU7p8+XLO3bOWCJ24t7en7e1t3b59W3fv3tXOzk5lIzOUgo5xypV8bLxnj8w9v+nPHo1+kyJ5xJ/R2Rk3miiOtxvGJeZPT05OtL29nafzeQqKVUUvXbqkp556Smtra3naJwrP77e2tnTnzp3s/Hz6JkaB2gkHl77eiNOeXnRY10/OxmBImiDMIpKUZ4X4vTtwp7jSQY47L/qdqc/DYbmYGZQz51haWtJrr72mS5cu6dq1a7p27ZouX76slZWVzLQdHR1pd3dXN2/e1O3bt/X666/r3r17WQddj1jZ18cXGz7Sh74IYqThPRXq1Lg0YTaaEmTEdIOn5XnFBeki80wawlPxw+EwT26AHbt586Y6nU5eKG9tbU2XL1/W5cuXc9owBpxsD7K5ual79+5pa2srr9LsW4P43nrck7MHXuvCd1xH0hlH7/3XFFvbarUqwbOPeU+rIV7E7H1JsOFAgH6UyiBjb28v28Ber6eVlRVtbGzoqaee0sbGRi7elyYgf2trq2Jn0XXGGYCVzzn/YFBuCgsj5/bfGSPprF85r9bmouSBm0bWNTwSkV4EAB7ZO7XvkQb/o5woRbfb1cbGhl544QU999xzevrpp7W8vJyLxHZ2dnTr1i29+uqrevXVV3Xnzp28kB2gByMNsJEm29iTKkNhU0q1uUiULnaQ11g0Qbmk6q6sTi1H0MJfptJJZxcc84IwBxdOJToz0Ov1dPnyZV27dk3PPfecrly5ovX19VzPtL29rddee00f+9jH9Prrr2trayuv8OqF384OYrhZWRbam88BS05/e397vzob0ATn1+/3K1E6jp8xz/5hfO/pFvrG00E4fpgOQAz7ZdG2m5ub+shHPqKf//mf10svvaSXXnpJzzzzjNbW1tTpdHTv3j3duXNHr732WgYxGF7XPYw0/e9LrTNll/6gRkaaGGNJlTo4Lzr3vD3jd9oF0BHTZXUpCg+oYgrHi7FxqFI1fci6W9ShLS0t6cqVK3rxxRd19epVra+vq9/v57bf3d3V3bt3df36db366qu6detWZmd9qQXpLIBkjFG74Z95issjdsam2yLX3WkXd+oEGNggL3rlGXH2dfbZ2wkmjd/DknqbLy4uam1tLQcaTz/9dNbN4+NjbW9v6/r163rllVd048YNbW1t5ZQvqUUAKeNEmmwA6hu4OiPugMbrYWOqsa5e5iLkgUDGDbtT9lDa3jkxYvLo3aeN0UlFUeSGkpSZFiKAo6Oj3AgeWR8cHGhzc1OvvfaaXnnlFb3++uva2dnRaDTKsy4oWnRFR9noOL7nfny9Gp7BWaQ6tqZJdKfPLpJUKeYENAD4GJCkbGgfBrHXwhDBMw68BoltBu7cuaNbt27p9u3b2tzc1Kd+6qeq1SqXod/b29Orr76qD3/4w/rIRz6imzdvan9/X51OR2tra5WFuohucM7khDHuOGwWh/LiT88ZS2eXyvZxOe1CW3jqDKEf3EAuLy9ntsOdQr/fz0aLdjo9Pa0scLi0tJQLb3d3d3V0dKQbN27k1C4sQavV0tbWVgYxd+7c0dbWlobDcsbSU089pV6vV1n/BMB5cHCQn6nT6eT9XIqiyEAII3t4eJjTHf1+/0zNh6cimtCX0ln21+2LBwWxpsFpfQcMBGWcQ1JmqfkspXJBM7aMoO08AN3f39etW7d0/fp1vf7667p586YODg5UFEVue2wkzpkUhNtZT/3GmjtJZ0C3+xwAHL5n2oX2k1SxnXzmheqSsq30oM39LHaY38clFtBztnjY3NzM+wsWRZHTx/TlK6+8oo9+9KPZbwKA4t6GBKaxzAA/2m5PVv8mve8ZGLerMXV/0cH/Q20aKVWrxxGnvjiWB3Da0Kvj2URuOBxqc3NT29vb2tnZybUUgJErV67o6aefznUvR0dHFSDleb3t7e3sJPf29tTpdPIyzhsbG1pdXa3U6MSiXtJOXiDnqLKuTSJN1gSpY4+iYfPaEv4HOPgCY77o0unpaSVNRN/s7u5qe3s7G73hcKi7d+9qcXFRTz/9dCUVtLW1pVu3blXSSoeHh/rYxz6m9fV1Xbp0KacwHHDST6Q2cNa+aJTvu4VjiJEDxvi8wrRpEyIjr+eSJpGTs5uwFDiX5eVlHRwcKKWUWater1fZfqDf70tSJXrf3t7W4eFhpqxh0nZ3d/Xss8/mYObg4EDb29uVWqcbN27oQx/6UE4Ts/Kzz6woikJ7e3v5PmET5ufnM8PkMyk9fYnuugPwFPi0i6d0Y6o3puQIvpxd9BoGt2MEi6Te2RyQtl1fX9fVq1e1uLiY61+ov5qfn88pBtLGh4eH2tzc1O3bt3P9FGCUInCmyZOG8PRCXKqhjmlxJoZXk+qdvPaO/vRn5rn5HnDAmCdgJCBhQUpP4+/v72fWmnKKTqejjY0NbWxs5NmFTz/9dF7gdTgcZru8s7OTbe2dO3cqG8Cura1pfX09BzC8uDev3fHZb17wHV+0h6Qz7y9CHqrYN9Kc8aZ4MEfkIGicI0vXLy0taTQa5Sj9Ix/5iIbDoVZXV3Px0fPPP6/l5eWKU0GxvJDNI7Fr165pd3dXH/7wh7PD3dzc1PXr1/Xiiy/q+eefV7/fr1C4vDzt5UAsRup1bePFqtMu3odeeBaf0+tFUko5IpaUFYL+XF5ezqm73d1dXb9+XTdu3NDc3Jzu3bun119/XS+88ILe+ta3ZsCDsWURNgwi51xZWdEzzzyjn/zJn9QHP/hBPfXUUzo6OtJrr72mq1ev6plnnlGv1ztTs0NEI1UX6vPndwBTN6OiCSBGqq6hAmjBkUmqpHBwaDj3xcVFra6uSlLWFdbsYN0eSbpx44auX7+upaUlDYdDvfrqq1pbW9Pzzz+fNwZdXl6uTNfm3nq9XmbjLl++rJ/5mZ/RBz7wAT399NO6du2aTk5O9Nxzz+n555/PIArDKCmvKeN1UYAYWEM2JSVQIbIErJJ6aoIQXDnj6Ckk11upmr7w9Br1YgB40vAf+tCH9Nprr+VNQW/fvq3RaKRP+7RP08bGhvb29rS2tpbbGGaHsYPtYGuQ09NTffCDH1RRFHkWWUpJn/Ipn6KXX35ZGxsbOWiECcJ2eJ2MVJ1RiG7yzPF9ExjwVqtVAaKxLs19JrbXAzPYNHQSO4tf9dqzZ599NhfVk7qXqvbP2RbYHWaRXr58WYPBQLdu3crXf/3113V0dKTnn38+b0vCtZmgAwBFbx2kOWsYfSN+x1OJFyEPpeWR5jyvU5wec4dIrh2WhAE9Pz+vlZUVpZS0srKSHeab3/zmvMPus88+q2eeeaayuRn59CtXrmRF7vf7unbtmt70pjdJUl5u+eTkRBsbG7p69WpmBbxg2alOb3RXNlcwfgeV3qTcLVJXnO1O3UEqbAdLkKNgKALV8TBpi4uLeumll7S0tJRnMBDx7e/vq9fraW1tTU899VRO/bAx4XPPPafV1VVtbW1peXlZL7/8st71rnflAvC9vT0NBgOtra3lHH4s9sTYAXB4Jk8zxMJzaVJkyLHTLoxF9JF7BrC4Q08p5QI9qezrtbU1SZN0roN49jobjUY5Qmu32/r0T//0rItHR0fqdrt513qvheh2u7p06VLeBLbdbuvy5ct629velg0zqUj6Ej3c2dnRcDjMqQieiULV09PTnEYmcgTUMl49ym3KOjKIR/CMVy/M9tlZDtx9DREPMiRlFnxjYyNH2ffu3dPCwoLe8Y53qNvt6ujoKBeIeioWtu7SpUuSyvGyvr6uN7/5zVpdXdXR0ZGWlpYkSffu3dP6+nreKd3rE7H3vrCmB6pel+e1I75426OY7fIohODW/aYzpw5iAI7oDr9Fn1jyYHl5ObPR6Ofh4aGuXr2adfjq1ava2NjQyclJtrHr6+uZmeZzgpn19XXNzc3p2Wef1dvf/vYckMCKXrp0KYMYbI2v7wXo8sDfWUIHp9Jkw8nIKF6EPBSQiUrlg0+aUGkoGikD/8wVDfrxpZdeyrk9qbr8OccStS8vL1dqOpaXlzUajXL0Tq7+pZdeqizSxItIbmdnR4uLi5kud+YIibUT/E90G1F2ExyfNOnHWEAY02jOQJFSwmAyAH2ROyJqT0UhsVYDxVxbW6sYy9XV1ezYnn766Qwu3/rWt1YMAechMqBewh2YFzp6vt2fzSMhzwXHWq9pFQCLp1O8vsFThRTU8ozUwywsLGh7eztH8TCjbBSJ4fH6NtqHKJwNXz36Qzfp79GoXFDtpZdeklQFlV7EyNILKaVcO4ctgRkARJPSwHGnlHIqA3YjMm7TLASEsdYp2iD6gGJb+h4bSz/h8GCt3v72t+cJFdIE+LhNpS6KjUQl5SCxKAqtr6/r2rVrmR17/vnn8zk96KFmjVQk6X7qubgHd36MAwAN/1P3QVs0pT/xDc7KxCJo7BbiWQbYLE/h4zevXbuml19+OQcn3vewJPQjbCUviIPV1VVduXIlz2h7+eWXK3U33AdLmOzt7VVWWfdMhttTrzlF+CzihsfGyNCY8TNnMegoR11xamCsm+l2u1pfX6/QVpH54H8arNvtVtIHFPWmlHTlypUzOWSnYgeDgXZ2drS9vV3ZQt4jGqfqPZ9Zl89zyqyOPptWYTCR73TUHNtfmvQdlKKDES/gZhrnyspKTmmAvCNAZAzAsHG+lZWVPOBxWlzP63VQoq2trQrAAbgS0RHVA6z9+t633t9NAjK9Xi/PunP2E1AiTSJ52gT96HQ6WfcAcvQbtQ6XLl3K6RrGSSzQHI1GeSE7N6LLy8t5rAEy+E5Stgf0MWs/EfHxuRef0u9M9/VVwHGcsej1oqO+Ry11Bb2xroJ2ACBi76IOw4zBqDGlmrb0MU9/eCE/0m63s61F72GkvdbQ6yMODw+1vb2dZ5txXZ98gc/w+3DHzzGui03QS+ksWxqfAVtGPzto9Bl9sdwBILKxsaFut1tJK9KWDvYINLCzBJ9cj4CRe+Xl69Rsbm7m8eZjzBfDjOPKj3M7i231Yy5K7gtk4kNyozG/CeNB4y0uLp5JP9FxbtRWV1crShbRHSuESjpThU+k3Wq1siGVqusR+AJrFEi5cWCQ0HkeEURxBsa/b1IRGm2J0eB/qUoF0j4oFIWdMBfuIFAmwCXRuXQWnbNQHgVsbuBwRq1WKztZSZUx5zlaHNpwOMw5W8YedSPxWb2OgHNiWJzOb0J/bm5uZmaM4kxA22hULjroNVCwGEdHR1pZWakU6LFQGgYRgEBNmwNXxsXe3p6Oj4+1tLRUWbvEgQWAyUGO6y7rVRwdHeWC3ljT5CybpAoL43sHIeTsYXigwqddWOk4BoBSdT8wnCRAxse2A02Opb3W1tZyWt+DMEm5IPjg4ECSKuDDZ5B1Op08dqTqSu7SZEHLu3fv6vDwsDLbEPtCX7mtdSa4juV2J9sEMOMp0VhbKlXrnAgqpcmsPC/Sd+YGRqvf7+eJD7FGhfNzDp/RyO85L+SAB4304cHBQV700AvosQNOXNT5dwfgtImDF8/aXIQ8cEG8KK5QDDjymXXfxzSGRxsMbNZ9cRDDFM1Yx+B/3YnSKVwLRFkURZ4u6NeWqtNt6cjIzDyIeYn07zQL/ckzOkjg+9g/GDD6FUfp4mkEQIkjeFi6/f39SqqRa+JocXCdTiePCb8vn5bveWb+EoV2OpO1UNzQR8ZJmoxXNz5NkMgQOpXNdwA9L3olMuOZGb+ReZOU04BEdaSoSBUAeHxGBYDW1wBieiYBB0CTfiUIYSySzkIv+Z+p3zw/4xOmidkd9+7dy1PCm7SOjHS2X33mkn/u0brrWWQz6FtmsfR6vQqTORwOc1CAc/I6Fa7hjAvp4JgGY9FDrz/jb7vdrixiGYNGj+w5nt9z3TpQMI1Cn8W04HnsYB3z5lPwfQx4agp7RxCBzyX1h3iajut50OEBHCloyi6iz+b3Thy4/XEygufFPzxKdu2BjIw/CELD1+X++F6apKFoBAynv/gdDg4DS0dwDU8beSW/F2h6xOjGkuPqjIIDLM6PgkZ611FoTE80QWKkE9NKiFP7vHc073vm0FfOVjmwxDG5YsdqfgcjzuzB2tBnKU2KVrlHNxpOsfJMnlaKwDSmSZx1m3bxvnRqGp3b39+vtC90MfUxgBKYAK9BYUxQiE1xIQZrbm5Oa2trZxYfdEDodSwYTN/OwplejJyzvd6nkirLMHg62sdcnXNtArsmVZ0N+uJpFo6JqQqfmcfnbvOc4UHf0WPAh9tAtwMRjLhdxh5wPKkmj8A9kPB7BjCjo66v2PCYnqizU9MqXmvirATPho7FoNl9ofsp/veVnekHDwyxj24buV70v4wFfkufRGYau+EYwNNI8ZmlKhPldt1ZmYtm1+4LZOrQGA/CX0eOdAid5B1EZ/gKvlS0u7ICWqC3WD8Cp0THwNhAqzuV6qkIr5r3/7lnjnHh+TAc0en6gmxNkjrnF1NJsa/dyEUa0ge7L03uQBPaemdnRzs7OxkE0VewJ4wHX8OC/Hw0XlzDNx7kmejP8wyo11JEYNMkIIMjkCar1xZFuX4OOgNoIMIbjUaVmRGk5ZzCdufv4MLr1drttnZ3d/P5mJILgPJC+n6/r7W1tczoONtHv6KPMEgAq6WlpbxNBetl0Ideh0VtAYyhA6KLpK8fpXiw58GaG3zvm0jfM/Y5F2MZm4e99IUGj4+Ptbu7m/fbAaTSrlyP3zpbJ6nC0kiq9A22ns1NpUntCP/HILGOWXIwF4OPaRZn/REPkJ1RdLuL38Rf0ma0JbvBx1II7BcLHLIHkwfdjAXsbSwS5tg4brzfuZbX8kgTlt/r8Lwd3KY6aLsoeehNIxEaRKoiR0eg3LgbQBSDhmS3XhbiAaBAa7HYHWkEVwDWp3CqDIBBxf1gMMgV1yyfDwDxjuH5PLKva+hI63m9RxOiBMTpP8RBjVS/iSID1J1DRO6AT/qcQlL6cn9/X4NBuRp0nEWzu7ubjR7pBqIENjVkzKCIdcDJ2SH61msHnMr2tKCnVZoQxXtE6+wmYxPAQioHwwKo8c3mfEVO6lYY3/QTAQbpva2trQygmM47GAy0tbWle/fu5cif9WCkCSvgRhsn6Wkgns03r3PQCh3OeEQ4t3R2J/tpF7c57tz464CB493ueIrf25WFRgGb2M/BYKC9vT3t7Ozo8PAwR8vOqKGnrnOAVGwr07mpQWTJBd8TyvXMbSjP4MyMB4te3Ozbn0y7ONPozD3tgH104On2KgZSrnv0J7pJYIg9Y9FClihgJp/XjQGiSE1Jk3WnvO88Pe9ZjQi2vE8dWHlb+HPy+4sEpQ+skYl0ptP5Mdr1TkAx3bCgCIeHhzo4OMhTumBb+I0vCMW0anZaxRADTqiRodGJ6FFUCpaoreC4SN86q8RzOAXmjo/3zkY1Qer6rC61ExXLC2YdkUNZYuxYLXY0GuUUEA4IBdze3s4RN4s8AXYODw/VbpdrjrDAHvUSnBNA5GAG48k48v6Szs4OiGDbqdvIzk27zM/PZ9aC54CJAcTQflDJTIulXmJvb0+tViuzX2zG2mq1ct1JqzXZd4dN53Z2djJgoW9xjEzDhvWRqlsnYAccnKaU8uqygBkMrDSZTQOTRz0WoI3VaXGE7kCnXSKQAbw52+gRs7No0Qni+Gnb/f393HbUGPGdA1XOy95lABkYG8YW/XdwcJCLwZ155Xh03vXRI3uelb+ue9h5rhfT09Ms7uBjoOwpI//rIMfbiHEAEHH/eXBwUJn0Ik0APMG+pJzmp99Go1FeeNR9Kf6WvuVzXoAb6Sz48iJ9gnt8SlyYEjtwkcz3QzEy7vCdto83AkBwZO3HgvTY7IqK6NFolCN5jK07XEejTkdzLJEY5+ZarGHgW83D0BDtOc3u6SacgAMbz+ciTYkSpElBXawjcEWQJkbG0zBOi+LUPAd7eHiYdzPnvdPHHiVSv7G/v1/5riiKys67g8FAu7u7FXDLdaiXcINMDQbHR7oTB1g3fj0X3ARh3GJgMHiDwUCrq6u5uNYjXowli2MVRbkeDIDRoy7f6mNhYSEbt52dncy6UF+RUqosjOjTq/f393X79m31er28cJ2k3I8AWJgbll6nLkdSZedsHOqVK1fyrKV+v6/RaKSlpaUMoKnpaUp/esrbHR52x+sl6GucSB3zjc2kwD6llGeF8V1Kk41yAT78ZmdnJwMlUhmwdoy7u3fv6t69e5nxpH/YCoE1SriesyrOonstZQyc498miPsNZ7djACWdZQ6dtXQwS8AHq+Lr87jtQ//QcU8Lco3FxcU8+4z+Bfzil8mG8FvPgni9IfeH7vsClE5s4EecBHBw84nKQ89ainUT/l2M4nEIPJwPXu8MOgIE6TukSsqd4qt8cj1mudR1BtE6qNWpUWdj6BRvcGddYo6adojplaaIgzOviaGP+AyQGCMKL8COs0FIX3AshaAOSnwBpzrQywwY2BhnxLxYldopXjhfUo1ORbszczqXc3Pvsc6gKdJqTdbYoX1hKwg8YMCYPURktre3V9lUk7E8HA5z2+7t7WWHs729re3t7byjNeOBFVthRhgf1E3t7Ozk2U8wPD712mvmvD/pb9YlIUjBsZNyZLyS7sL+eB9Pu3gU7zYzMqH+mUf3tIkzqwQUfAYbg10FKKKTfh7fzBfA40HjaDTKDLczRdRoYHPpx1g06rodGSXXyxhINqE/cfRuaxBnXdyn4Rvdf3pg4cwIOgF4YdsJD+gl5SUY3Ff5bENSUZIqAaiXY9SllSRVxgH3zHPxP3/9Gb1dLtJ3PtSmkbFojiiaQcYNOltBFOxpGjeUnsP1wYoyeO2Cr2HhAxmU6kqPE6XDATAwCFzDoxeuw31ExsXz+lJ1NlOTgIwXdOEAHZxEsOjRAUrEdwgK4MomTXZ4dUqYNltaWspt7+3IX8BnbGN3sL6ujY8bLzZ0J88zu8H0/vQx3gQwQ7qn3W5nNgTnw5L06BbTM1mEEFaM9ZXY7sEBLilY2K/9/X1tbm7mLQSooWA2kqftoJI9ZdRut/MMqLW1tZwGgkV1JzsYlAtY3r17N48R+pyxSITY7XbzvQJkGHfYmCZI3Zjzcc97tzf+vQMEt5PoGeyZNNl+hZSFL69AIIn+uO3GCXnbul2F2fbaCsApG1V6zUi8R+nszsgRxDRBNyOo5LmlKhuDONvt7enBmNtX2p929Wt5eQb2wfuPe6CPpGqtI+krv44DGGdb3Vf7+MCXcN8IrAzHXSQovS+QicDEo/a6HJc3pFNrNJ4P3Mhy0DHMdnAFIw/PjCR3rB69SZNFzxwJRmTL8W4A6GR3bp7Lq6NBvZirSeLKQZ95ai2iZv/cDZQb0jgWcGKkLYgcqJRnCi3tS/87FUp9DGkJV2hoT5+O6AbBGTafKk6fRkaG8easzTSLs5DMnqOmhPv3mQO0NfUnzrbwzIAP330ao7a9va3r16/r9PRUS0tLWl9fr2wsCFjy1LOknAKkqNj3gvGUJEYbEESNG7VPGE3GzcHBgW7evJnTYDwP16EmpEmBhlRNpWB/I2sRATd66f87K04K3heLvHfvXq6NYgNQX2AQoAow9Xo0Ao3RaJT30POVXt0xOoMgTRyhBzc8r9dQxajdneW0i4MubBu+E6lLmfmzxUCb1B2+zBlqT99hx7F7vrihNCnTYBz5FGy3xfQdtpXzRjLC798DSoTxi+2lJvai2bX7AhmcdKw8l+rnvoME6yhQT1t450qTtRCIqjY3NzMdzv4f/X4/N3ZRFFmhvN6l0+nkvXow7ii2Oz06xTvCQZtH7v7cDs48HdMEulOqrm/gxtH7FbYtFv8iToH7Z07nu+OhP4fDYXaApBh83R+iC4o9KSrb2NjQs88+W6n8J2rw6n0ccV0qyVlDGDtJlSiG30rNyMfv7e1l8OXsE8/QbrfzNgbo8XBYFt7eu3dPt27d0sHBQdbvoijyJoNehOhFpvPz85WA4dlnn62s/MsMNDaA3d7eztsP8LmkyuwJ+tqZG2mSzuB/7AFjh2enbkeq2hlfBLMJ4sxiXWDguhjT2u7wGOvMGOT5qZmi3omd6re2tvK+O2tra+r1emeCT3Ty4OBA9+7d082bN7W/v6+VlRW95S1vyRsaup/AvnptTAw0CDodAMX2qHP40y6epqYf3R9G8OK2LUr0OXFG2NzcXK5tuXv3rm7fvp2DEfYoZN0g7CyAfzQq68o2NjZ06dKlnGoEpHg9DkEmfejsO7/x9DTf+ew09Bii4iLloattPA/qyNLBgDMUdZ04Go0q9REYMBSs3+9nA3Z8fJw3v+r3+5U9IkCnXgNTFJMltJeXlzNrQ/rKKWynzSIgcxqOAeQG0Z8FQ98URiYyZE5zxoEVUzFeWwRap628gJBaCTatu3LlSl6ynl1cV1ZWKjsWS8q5dVIZ0mSvEJa590JxV2iAjKTK0u0e9TnV6cAGcfDWBEYGtgXASM475sAxKJ1OR3fu3MnOyGesDIfDDGJ8aujJyUllT5erV69moHr58mWtrKxodXVV/X4/zx4CaAJg2+22VlZW8kq/HJdSyvl49BSAgk2hbgMDCpDp9/uZ5fNFGqVJEALgcmM7zeJ6ho2N9Qik1vhMqi6H4cEVtq7X61UCDxYOJAq/ceOGOp2Orl27po2NDS0vL+dUozQBkegmqafT01NdvXpVb3rTmzL4cbbbaxVjetnTVV7w6dd0Fp3au6awpVF4bmfSPIAm2PbUkgfS+F6CMGYr+SKT7F+YUsoF3h4wIg5mW62WLl26pOXl5QxC0F9f/gTCwIN6Zwh5DqkK2JhVTP/5+L5oeajUkkfZSMxx8T4iaQTngdHCITmNSTV1r9fLRWSwMsvLy3mNGDocWrvf7+cIjfQAdQBMBySq8CllKBcUqoOSmG6KtRpu8JsCZBysODODAfLZSc6mQQ97zhQHgeNhlhi0IdHW5cuX86ae0mTFXt8xG8PFEuqkLVBeIon9/f1MiWMo/Z7i88XxibjSRbq3KfQ1QMWBmUe40qQQeDgcZvDHPjiMXwCEn4NCbRgcIqh+v6+NjQ21Wq1cOOzppZQmGwOSCiYtiM4eHx/nY7e2tvLCejg0X0qB/mF8kTLytLMHE7BG0mT67kVHfo9SnB2kbx80Hv3ZAT7o2sHBQe4b+gMwiPPq9/t59qCDRVK5o9Eojx1s3ZUrV9Tr9bSxsZE3lCSg5MXsFy8KRyd9eq4Hvv4sboe8RqgJttbLDxzE1LFtzrZ4raFUrX3CTh8cHGT2E51hT7R+v69Lly7lIMVBaywCHwwGmSgoiqKyNhBLLFC0DestVdOZSKwp5TP/3Fm3WLNzEfLA3a8ZeF4/4BGACx0SKTJHbW7QXIF4KN+PhevRMb4fE8g/pVTJu4Fa9/f3M7XtC7IRJTgb4YDNJQIYV7I6BDrt4rS9pw/qlMvzsD7bK1KkjrCdzcCAwhAwowXn6Csyc184LhbZ8qJwNqPb2dnJaQPP0/JM/hyAGy8yxKBEccVqApDx2gme2xkl2gVnziyl/f39rFODwSDvgA2owdlRNOuAnuJ6jN9wOMy7ynNPrVarwoBSP+Pjx2tjDg8Pc4qRnemJGP033rcAFu7bI36vJcAxN0GwPb7ysjQBJe4MAS3ePi7oNk4Jx+fLWwAKV1dXKwtXop8EjcPhsJJaYjsKamoYYxSP7+7u5in6RPL0B8cyXZvxWxdE8tcBQVPEA398hdeeeBrQP3MyQKoWefOetmY8cLzXqWE/yXrAntPu1JxSR+aBKCDGp19zj15G4bbSSywieIsv96kXCUofatZSXD/Fo3Ua3zvCBUMbFdPpJn9wZjf4Lq0+oDHYUKOxnsVBDGyMz4t3w3DeK17Tn0Wa1FY0UeJ9+zOD1KXJcv8waNKEnXHxWSGwJDgr0kc4HV/jhRyvNNnRmP505wyVur29ra2tLR0eHp6JWDD+TsVK1XQoEQoSo0Afi02J+hzUu3HA8EgTepfISlJuU2kyRfPk5ETb29taXV1Vt9vNbTw3N1dJ3QI8nIljfYmUUtZdqG3ansieFwutcQ9Eo74SsS+dD6jy9YkIsuhz7ovakKb0pVSdreNAjHEawQDH8bnbXu9/qVp8Kk0KbonIYco9zUGNGufudDqV1D8LscES7O7u5qn529vbeRFS7lWqrw3hGpEZ9ZSSs61NCBpjKUL8zP2np+s9IIzFtTG49FokSRV2lGAEvcY+OID14IWgY3d3V3fv3tX29naeUeh22lN8/mz+3DyL1x9Kk4kIPgP4sTEysZ4iOgnvHKcKERQkggEcnkfU7kg6ncnux06LoewOJGJl/O7uru7du6e7d+9m5drZ2ck54/MMnIMpFD3mNrlHAJej7SYIDFZk1BjoKNZ5QM3XP0CJPJcNwHSmhs/46xuDch5PL8LYsVYMNR3UdWAcvZZCmii/A7H4DBzrEYKPLTcw0y5Oz2KgYi0BC6ChHxgraQIednd3KzUT6CeGExYHR0c/ppQy60ZtDEGIb0oICwo7yhRp1oRh7x93yKQft7a28vPxjJJykaP3XZyt6EFHE8RtqTOhrl84uxjR+sxKn7UyHA5znwN03HbBbAE4JVXa04XfM+aopXCbu7m5qTt37lS2PnDxGhhpsskp30V2NgaWTdBLqVosS1+6eBqQZ8S2ets7gKf90UO2GPHMhOuJ18Z4v3stjE+uuHv3rm7duqXt7e3KZIpYwM39+3iKmQuO4fn8mJj+vyh5IJCJSNKN/nkomU6KneLKQI2KdyhKSgQPkMHQOj3lDAxFw7u7u9rc3MxRATUy0OiRJo/37krOPXFfnuqKaLsp4mtsOACLQNIHpBccomixuNBfbnS9aNMBDXUMXM/RO+cAmG5tbenOnTuZ9vY0goMYfx6Ajhf+8nmdMXfA6sdPszidK01ShO7EHCCQyj05OVGv18t0NMfu7++r1+tlfYIdYzkEUlLSpN8wnET3jBtYOvqR9BPr0LCNgC+bj+GkqJ9ZWe5wfWwyE2p1dVXSxCk6wwaV3hRhTNdF73wfHYf/huP532sBcUYO3j248LqL84IAzkMxLyCGFX5hYnzaPP3gzhzf4bbcnaTb18hINIEJhwUBiNIndc8o1a+gjrg9cr/n9TPoqKcQSRlTduHsHsw7qzBvbm7q5s2bunPnTmZA48KSnkqKmQoXH4ceIMf04Hkp/jcqD7VFARdmQEZGw4ubcDI+/c8RpVRdjwRFk5SLDHF4XsALkPGIwIuGiQgAMix9TjrJnSYSU0oRyMRoLjpbX2ytCeIDJ9KfDmQQByP0ved0PT3jx6MoviYQwvnrtoBAgWABcH5bW1s5EvEpgM6UYeR8JpSLA9EIxC9yqezHJeghqTzGL1Okid4BK/T10tKS1tbWssGSJvvvYNw4L3pG+mA0GuX9mVqt1pm6NXTeQRT9eO/ePd2+fTtT1hQNDwblejGjUVnsnVLKzOny8nKlCBiKm77c2dnJdT68+N6nezZB6oC5VJ1aLVVtEp97asLrL1zHOZ8HG4wXAkUvCHZmhN8AcgGeOMG7d+/mwm02ho1pCLeRzi7VMWaRwY9tM+3Cs0UWwu2kp1w8qGbfMg+eI5igXQkYsAF8x/UHg0FlmYtWq5WzISxwefv2bd28eVM3btzIG006yIi+ket4/0YsAOMUmRr/7KLlvhYcw+8NSKNGlBgbvS5yiLQSxtgjOG8IojTWkonLqLPNAakkqE0iT4yqAxOPur0gK6JhZwnOe4amSZyiynROH6A+0DwXC4jhM9B/jJ5QJPoOpTo+Ps7TcL2OwpkQ37oCI7m5uZmdn4NaByZEnvRNvC/GsDsIHxs4Xgfk0y57e3u5zZ2BkpTTNq6Dw+FQ3W5X3W5XGxsbebdxoreFhYUMKiji7PV6lSXMAZiAVLYYKYoi5+Z9Kv5gMMizWdio8ujoKAMUn67f7/czU3R0dJT3ikkp5VmMXifCs/lK0owRaULfU+sx7YKeePQa6558LPuCoDitqMOuk4BU0ow4S3R9ZWUlj586Z+ML4u3u7urOnTu6ceNGLsCnQLTVauW6K38m9xmeUnLd5J4jE4NNYQLAtAv3TL2Wp5diiYZU3cncmWXGv884cmDIsaSIST0ROCwvL+cSDQeybNgMCIVNQ5dgVx2EuG3EVzrIxZ+633R760yOBz4XJW/oTAwsVxRnXRzBxVxgROY8GJ3AapM4NpYhJx/v12cmxtbWVq6FoaiXDvcCzzgIYuGRo33u1aN+/97TKU2IEqTqdD6/fwc43j/OZPGMXsEe2Q/P/WJkmSpNLpa1KOKy9pJytOcF2tTKuEJ537nTdBAtVRk0/8yNYaRqOWbaxaNqj8IICpi9ICnT/LxIHVHI7Swjv5XKtul2u9rf39fi4qJ2d3f12muv6dKlSxVAKylv+kpqAtCB0WTaN2tb+F5ci4uLeYo2BtGfz+tveHbqaBiH8/PzldobjmsKkJHOLmHh72NawYGCMzPRWbiT5DjYNQ9K0aGlpaWKrZWUwQ/sGguv3bp1KwPiwWCQ01RuZwgWY4TuPsQdmvsRTxNK1TXLpl3cyfszxRIHqWo3/ZndT6FTDmAie05Kj36isNcJAFJRlF1Qw+aTcAAZfi8+Ht1HuE+P/3M9qTpt21moi5IH1sg4rcdNusI40uOYWHDpg9EHsjsyj5TZRZkpYXRIRIFebOYbQ0oT1O+DyY1+zJ/HFJPfk1OgMdJvknI58xVBGe3ifebfuXMgzcOy5w6OHIGTNgSQ7O/v592UfYfzyOTAwOCYUWR+J53dqNQLtKOBjDS9j2u/ZwdM0y48C7Sy58SJqObn53PBJWMasEixL7PLpMlqur5gFlM5eX/nzh2dnp5qbW1NR0dHldkrzGxhQUvYNfqT5ew9h8+9oUsLCwtaXl7OKWHGEMBHmhhb32DWQSuLdzETqwkSZ+JFsOJ2h79+HOLfO6hHh7BjJycn2trayswsdjQCGa5BXxI0bm1taWdnJ5cPUDDsbCB/SW0g6Ggd2xCDCdfHOBtrWiWCFk/r1KVjIvsUA2qfSBN/i13Gz/kidjDY8d5gLwEw2HuOd9/INemzaH/przhLKQIVBzSPYnXfh2JkPJ0TU0pxcDHwkQgKHNQ4xch3nJcpnYeHh5XVQN0Zke+jurooisoeIZLO0HpECXVgyhvbqXlvA56RjuXYJgj36UoW790NCTODiIils2sbONAlIpOUUwNOSUNDe70T9+UMi9OX1E0ws8mZE49GI6PmaTG/RrwuKam6tphmQXd82rOzIa1WK+9zhaHyTeYAJj5rxQMUwNDi4qJWV1d1+/btDGIlVYp2YV8WFxe1tbWldrtd2RmZCI+xsb6+roWFhZymSilV1pBhBhbGltkVgJNut6uVlRWtrKycSSPCzJDOasqmkTEoBMS5w/D6Fv7HtvH7Onvabrdz0adf7/S03JmcNOHq6qqWlpZyihDhXlgrhvVhJGVAythw4OXBrc+sclvin0tnd7xGhz0FNe3ifUa70DZ877VbMDI4eM9qxLIHT+H4cbQV9hY7G/vcx1ir1cqraTvQZd0n7o3x6IuXcg5eTOd2XxHbQqrWx14kKH0gkEFZHMB4YziNyPGOrEF6Mfp2pxFRpzRhPKizwPB6KovOJ/qOude6azrQQkkcqEnKneLokk6O9x9zydMsPsU1GhuPFPzZHLzS/l7f4v1IX9MmTvfjrIiuo2FCaUejUVZAjwzZ8A7HhAN0Q+h97lH8wsJCNhKcj99hVCK1O+0CuB+NRrlY1lkMCjc9TUN6AGPY6/XyeaSJw2m325W1g1JKWl9fz6tu+9oSAE8AiKdzfKr9wsJC7kNnbZ05XVxczIvtScqFy6QvJOV78xQ0aaeFhQUdHBzkNBa2ownCs0QK39NGDhYiwHEbiLPAFqJPzsi47T4+Ptbdu3czwwaQcbtIGtI3KqUwGDtdFEV+D7tLX/t7Tz84WInMqqezpckSH9MuEbzUBV91zD41izy3s9YOHgCZpHJJHRGUASy97iam8T1YdNBaN9Mvponi/fCcBJoOVvG39HUEQxcl9wUyvtYLCuaUp3/ukQF/Y060TpyS8jx+ROhSdQt0zx1G+tIpaWliJLhv0KzX8MT0SV2u0oGRp2CaoFyS8uZ60iQFSEQvnV20iUHoM8jionUUWNIWPlWeYzB6ON46Fssr++fm5nKkwD35DCOYG+4ZdgzxfuR/2CVy+U7R8nk0tNMsPq3WizedAYkUP+kfT62RHvQoHHDgs59YOA22BWPMMf1+v7LIFquC0i/UuVFkSL0LjBtGnFVI5+fntbq6mmcleWE6jmJnZyenNrkn1kwBcDchgpcmQYaDavrXHR3/e2DJXy/CdPsUbSk6xjU4hrEE2xKZgJRSBsi+WzLpX8ATdsIBmTPeSExle8o/ptLcAU+7sFSEB8zoq/tKt4MOeNzX8NwedGNn6XOAKqDG13xyhsv/l8r+JYiJgMtTxn682+06MOYg1HcD8LIQXwPqouS+QMaprghi4jTLOpYipqSc6vQBDKIEHUKDesf5ubzgk+98erBHkygYz+IN6kWNHpG7U/VI39GyU39NcHzSZHo7Ua2vMxGBhUcOvr8NTkMq221xcbHSrq1Wq7LsPZG271TtU6j5rRtAwFDd+JOq45JzSJPcO0rlINWNhAMzohcfu03oTwdhtJUX9UqTXeXZtLPb7eY+wckzBlZWVtTtdnOA0ul0clEwvwWw4gRpX59RhuGDUZOUi7tpY6ZKR3YBYAwzA9u0tLSUx12sJWGGlbO3nK8J/YgA+pzR5rnoI9rIWRtnNP1zD66cxab/fIzEY6XqLto4SI7FLjvwIjjwglTO58Wq0tnpx+hxDFLYONgdXhOAqTt/2sQDD+8nnH+UyDBLE50HvPju8Ogb58T30V+ARuytgx/6kNmInvJzQsDFx6IzPoxZ7LwzvPh37uUi5aEWxItRtN+4VDYwsx+kKnPCeRBHa57nI4qnk+ICeM6KOBPjKNMjCGmChOkUp8NQIAdLfi3vdH8OV0Kn7pogzrIwSwHD74BCOstqkSZyhoO/Ph7o+1hk5gW73g985wsgcm7f2Zj0VKzJ8jEUo1SPMFzpfN8nf0YHttMu5MCh4ynKHY1GWl5ezsuVo2f7+/sZHAwGg0ot2eLiYt47h7ozacJUuc46lS1NxgHbGHBenBJjimjfI0rGotdTAX5gihYXF3Xz5s1cyJ9Syikq/vc0DNeD8WmKeCG+18C4M+M5PR3qNs/rxTjeA0xnvn0BPABqrCFDV2BhPQj0Fw7VUxs4LgdQjIkYjEb2xcEMdglb0CRby9+Y3qQt3fZ6n3l/OqMFKHA2jUUlIQA4R+xz9A6A48wXwT7fRxDl5wAUOXlQlyo7bwy6bb1IO3tfIOPo0R044g8eBy3gwgGEgwJ3gA5gcGgomuf2/P+6zeCcyotOyRtTqjpcBos7Vu8IqQreIpVWh1inUXAkjtq9z5ylciPq6ScMHw6U5eIdBCIewUFj+vo+CNGEL2jmu1+zMjPGjWMwgjHVGVkzB3CtVitvWElOlyjfq/anXba2trS6upoXqENI5VFf5NG2rxPC1GVP50Ino7PUw7CKbq/XU7vdzjOPMIC0OUCDehU3wsyeYtxwH8xSGg6HefsJ6uEAXBQkswcU98j9YpjZXNZZhiaAUmnCyDDGAe1xeYHoZNxROHXvQVgdQ+U2NxYCxzo31wnuAxvijAJjCN2O44PPuL4z9M7ae1CEkyQt6jZgWsX70FNEMQh0ABAdfwQNtDOzd+k/fBhMdrwPB/eSKtkOJwe81tQZbXQLm+B+nWs7w8Jx/EZSxacgFw1IH7ggXqw94CGj846sR0TZks44GE8LQTuhOL4pZIzyI6L01AFOkVw+Al0exSNGv/+YvoppsRgFNUGI+gAIXuPkaRZJlQEd6WKp2pf+cmDhhXtuLCPr1W63z9TWcC5ADWkHjLRHdu32ZOEpjGFdtOOpQm+PaJibkJJYW1vLOkB7p5TyRp3ohtd7SaroGQwb+/H4fkawMtS+SMqsDvUuUNHdblfPPPNMBqh8jwAuKEJGML6e58fmMH2bAt5Wq5UBJzNr2NDSa0O4J68TaIL4zEvGK/3D+HRx9hthzMc0AvrtzgZgcz9by18CTBwd4J+AEh3mf6laTO/pLtdr18vIBrmDb0ofInVO2hk2F28z2sVBT2TIHMhyrPdfbGP6nWPdh3JNxgtMtdcL0rf+XJzHgZoXl8eANjLlpJ4u0nc+EMggdSkmb3A/xm86KqAbrZjK8cbmexxVPIbP3XFyT9w7EQHXrcvncU4vPPOBEq/N76IyNkFcYRyUgvhxitIkrQBYoBYjphvpX3cmDpg8GvD3KBjGlrZ248e9ShPlcMDK9Xg2p3OpK0DckXM+/y3vI3M3reIzAQF6UM2ul9QwMaXSU4Y4/qIo8t5Gq6urefYRWxBIEyNLkMAU3K2trQx6fKuAGB0yVdvHiDvqlZWVnGLa29urjLuDgwPduXNH0iTAIOBhlWAM8dLSUmbxfJrwtIuvR+VRvP+Ps/BxWge6nUGPjI0LeucO0e2epDMAw22EVA1o3FHXBT1RnJEgXekO9jwQ1yShL2JgFdvT24LfxXVofG8z9MBtldcv1fkvxFNTfl23y+4noz30fiKdGPvbWVfuhed/FIz3Q++15M47MhhORUVHI1XTSFDFEWk71eVAxQ12BD6u1DHtw/kjgKn735UlKrEPGr73v5GynWaBhYkRjiNljBSLJdF+blRdWSJwpN9xmpEdiOCTfnCjxT2A3GP6y4+J/SdNViJ1cBoLjB3g+rj2iHiaxR2ZF8vDbPlMMrYWcEdDStAjbPobtiPWT7HYXbvdzoXFKZX7Mm1ubmp9fT33kTMlrCAKsKQOx+8FNsntzdzcXJ5OzSJ+XJv7dybN8/ydTkerq6sVZmiaxSNsqTpLxZ26213/DolBWgQrMSCLgZ3/jU4RcebV17pxpicyRjHo80DQr+s6G1nwpgipGme0EZ7Zx6wXQdNH+FDa0zf3rFtg0Ns79qn3vx8bJ0Pw27g6M/cSAawzwdF2OtDiGWJwepHyUEDGUSWf8bnnrH1AxkibDvKX02CxZibSaTSOR/d8jzhAcZTpNTOR7vTn8XNEI8Bxfk3eN2XRLZ/xgbhCuDNwg+QDDwfjoMCNlTMfbpgAUQ5cvO+hRlEGGAEiao712icUBZqb+4F18P5i/Ebn59FB7O9pFpgSUoKj0Uj9fl/9fj+nfXzJcnTYV2WmzWHbaCdAEH2wvLyc92XiWoBSFtMjXUXtjfeBp/DoB2hsnzLKVGsADDMQMaqMhbm5ubwKM3UT29vblZogxkNTGJk47jwV4fVqkfWITCSMd7S9dax2DP7cMTFG/DoeaPjx/jsYdfo0svb+vFzfWQDGYWR6uYem1Mgwa8fTau4zz/Ob7vd8qYRYL0oAwnmRSDhIVabGmXCuI1VZl1gvx7UjEPG6Jj9XHFee4WDceA3NRcgDZy1FReKh/QYjPUVDeyogKo7XYriS+aBGHPjU5eHoJDoV8OJsAr+Ps2+84+ue3Z2bD0q/blOoz9imDshi2rCOKvRBH9ODOD2cnbNYbhx9eq6zZc6kkQaBjeEcntL0mgqfduysoBeo49C4BsDK+95TXdMuzOJYWFjQyspK/oyxCVDzZchpH9rYnQZjm5V00d1Op6Ner1fZrVxSLs4F4CwtLZ1xkowbDDJ7P/maKe5kuT5OYDgs949JKVUMq/c3fQgQYv0hAGpTGBmf0eP1a24rAeDohAdn0sROohveZw5snO2O5+CYGIDynQcHkcGJjLqvG+X+gd+47kWH6E6uSay3NBnfUjVQjJkLxAN12FC3TQ7kGBv8xmedRdtVB4DcLvusoxicx/7ir/tV70NsJ/cWg0IAkWOIi5T7Ahl/OJyDO3Q/BvFGi+dyxXHkSQRRF0nEqMKdDg7JrxGjjVjsKE0KrGKneyNjWB2knBddNEXi/bsTk6rT5h3UEGFHlsrHALnSuLw5/RPThFERnVFxJscZHO4lUt/O5vk5+N1wOMxAhoiOsRyBTEqpEVHfaDTK++LEfcgiKxHXfQFEHB8fq9/vV6JoSdrd3c3bBKB3CwsLeYVdxoM0YYZccGDsZs0iahE4wtYMBoM8LZ97436Z1i1NxitF375RJbrKjCfp7Bop0yxE2NG2xrHM5077e4CIPkXAQDv5+iGR/YYhYzwgfO9OuM6RcX2u5+eJQaHrIf/D4sRZMn4PTbC/df2Fk4995ily7zNp0mYxiMcWw15G3fcUv1QFmG673e4BTtx+uD/1ImHsPe8jG07/cayzL9GnXpSkprAJM5nJTGYyk5nMZCZRmsPXzWQmM5nJTGYyk5kEmQGZmcxkJjOZyUxm0liZAZmZzGQmM5nJTGbSWJkBmZnMZCYzmclMZtJYmQGZmcxkJjOZyUxm0liZAZmZzGQmM5nJTGbSWPn/AaLwuM2zHz21AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let us plot a few \"average\" faces\n",
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "plt.subplot(2,5,1)\n",
    "is_young = attribute[\"Young\"][:n_img]==1\n",
    "plt.imshow(np.mean(img_array[is_young,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Young)\")\n",
    "\n",
    "plt.subplot(2,5,2)\n",
    "is_male = attribute[\"Male\"][:n_img]==1\n",
    "plt.imshow(np.mean(img_array[is_male,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Male)\")\n",
    "\n",
    "\n",
    "plt.subplot(2,5,3)\n",
    "is_Goatee = attribute[\"Goatee\"][:n_img]==1\n",
    "plt.imshow(np.mean(img_array[is_Goatee,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Goatee)\")\n",
    "\n",
    "\n",
    "plt.subplot(2,5,4)\n",
    "is_High_Cheekbones = attribute[\"High_Cheekbones\"][:n_img]==1\n",
    "plt.imshow(np.mean(img_array[is_High_Cheekbones,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(High_Cheek)\")\n",
    "\n",
    "\n",
    "plt.subplot(2,5,5)\n",
    "is_Low_Cheekbones = attribute[\"High_Cheekbones\"][:n_img]==-1\n",
    "plt.imshow(np.mean(img_array[is_Low_Cheekbones,:,:], axis=0), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Avg(Low_Cheek)\")\n",
    "\n",
    "#\n",
    "#  FIGURE EXPORT:\n",
    "#\n",
    "# To export figures to include in the pdf report, you can use the \n",
    "# following command, making sure that dpi is high enough in order\n",
    "# to export a figure with reasonable quality\n",
    "plt.savefig(\"high_quality_export.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Young people in the dataset:  42.2 %\n"
     ]
    }
   ],
   "source": [
    "# let us compute the proportion of male images\n",
    "proportion_male = np.mean(attribute[\"Male\"].values==1)\n",
    "print(f\"Proportion of Young people in the dataset: {100*proportion_male: .1f} %\",  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "\n",
    "# General Remarks\n",
    "\n",
    "Your assignment consists in building an algorithm that can automatically tell whether an image corresponds to a Male or Female. \n",
    "\n",
    "1. You are only allowed to use (variants of) logistic regression models (possibly with regularization + feature engineering). In othe words, do not use deep-learning / convolutional-layers / etc.., that is not the purpose of this assignment\n",
    "2. You can only use the first 15,000 images to train your models (note that you do not have to use all the 15,000 first images if you do not want to). The accuracy of your model will be evaluated on the last 5,000 images. The last 5,000 images constitute the test set.\n",
    "3. You are allowed to use whatever optimization algorithm you think is most efficient.\n",
    "4. You are allowed to do whatever pre-processing and feature engineering you deem appropriate.\n",
    "5. You will report the accuracy (i.e. th percentage of correctly classified) on the test dataset (i.e. the last 5,000 images). \n",
    "6. You will as well report the Area Under the Curve (AUC) of your classifier on the test dataset.\n",
    "\n",
    "\n",
    "# Specific Tasks\n",
    "1. How does the accuracy (ie. tested on the last 5,000 images) depend on the size of the training set? Is it necessary to use all the training set, or does the accuracy stabilize before?\n",
    "2. How does the accuracy depend on the resolution of the input image?\n",
    "3. Is it necessary to use colored images (or black & white images are enough)? Is it helpful to increase the contrast of the images? Other preprocessing ideas?\n",
    "4. What if one only uses the area around the eyes? Around the mouth? The hair? The ears? Etc..\n",
    "5. Is it useful to use an ensemble of models (eg. for example, you can use a different model for each part of the face, and then try to find a way to ensemble these models)?\n",
    "6. Report the error rate and AUC of your best model (when evaluated on the last 5,000 images)\n",
    "7. Suppose now that you can only use 1% of the data, i.e. only the first 200 images, to train your model. What is the best model you can come up with? Is it helpful to use data-augmentation strategies? Is it helpful to use regularization strategies? Ensembling? Report the error rate and AUC of your best model (when evaluated on the last 5,000 images).\n",
    "\n",
    "\n",
    "# Last Remark\n",
    "A. Your code needs to be readable and **reproducible**. Make sure that it is possible to run the notebook to reproduce all the results presented in the pdf report. \n",
    "B. You need to submit two files: (1) a jupyter notebook with your code (2) a pdf report explaining your approaches and conclusions.  \n",
    "C. Your report pdf report does not need to be long. It needs to describe the experiments that you have carried out, briefly detail the algorithms that you have used, include a few figures and outline the conclusions of your investigations. You can have a look at these (very good) machine-learning papers available [here](https://nips.cc/Conferences/2021/DatasetsBenchmarks/AcceptedPapers) although (indeed!) your report definitely does not need to be as long as these articles.  \n",
    "D. You need to acknowledge carefully all the sources that you have used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X_train X_test (BW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the 15000 images - train dataset\n",
    "n_train = 15000\n",
    "X_train_bw = np.zeros((n_train, 100,100))\n",
    "for k in range(n_train):\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    im = np.mean(im, axis=2) # average the last channel\n",
    "    X_train_bw[k,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = 5000\n",
    "X_test_bw = np.zeros((n_val, 100, 100))\n",
    "for k in range(15000, 15000 + n_val): \n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    im = np.mean(im, axis=2) \n",
    "    X_test_bw[k - 15000,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bw = X_train_bw.reshape(15000, 100*100)\n",
    "X_test_bw = X_test_bw.reshape(5000, 100*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X_train X_test (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 15000\n",
    "X_train_rgb = np.zeros((n_img, 100,100,3))\n",
    "for k in range(n_img):\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    X_train_rgb[k,:,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 5000\n",
    "X_test_rgb = np.zeros((n_img, 100,100,3))\n",
    "for k in range(15000,20000):\n",
    "    im = imageio.imread(os.path.join(path, all_img[k])).astype(float)\n",
    "    im = resize(im, (100,100) )\n",
    "    X_test_rgb[k-15000,:,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rgb = X_train_rgb.reshape(15000, 100*100*3)\n",
    "X_test_rgb = X_test_rgb.reshape(5000, 100*100*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.asarray(attribute[\"Male\"][0:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.asarray(attribute[\"Male\"][15000:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(beta, x):\n",
    "    \"\"\"\n",
    "    desc:\n",
    "    =====\n",
    "    compute the probability that x is associated to a +1 label\n",
    "\n",
    "    args:\n",
    "    ====\n",
    "     x: vector of dimension 784\n",
    "     beta: vector of dimension 784 (logistic reg param)     \n",
    "    \"\"\"\n",
    "    proba = 1. / (1. + jnp.exp(-jnp.dot(x,beta)))\n",
    "    return proba\n",
    "\n",
    "# let us parallelize the function:\n",
    "# beta: no parallelization\n",
    "# x: parallelization along the axis 0\n",
    "prediction_batch = jax.vmap(prediction, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_error_rate(beta, X, Y):\n",
    "    # compute predictions (True or False)\n",
    "    pred_bool = prediction_batch(beta, X) > 0.5\n",
    "    \n",
    "    # convert to +1/-1 predictions\n",
    "    pred = 2*pred_bool - 1\n",
    "    \n",
    "    # return the error rate\n",
    "    return jnp.mean(Y == pred)\n",
    "\n",
    "# typo!!\n",
    "# this is the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit # makes things faster, compiles the function, when run function again, it will compute much faster\n",
    "def loss_single(beta, x, y):\n",
    "    \"\"\"\n",
    "    desc:\n",
    "    =====\n",
    "    compute the logistic regression loss for a single image\n",
    "\n",
    "    args:\n",
    "    ====\n",
    "     beta: vector of dimension 784 (logistic reg param)\n",
    "     x: vector of dimension 784\n",
    "     y: {+1, -1} label\n",
    "    \"\"\"\n",
    "    return jnp.log(1. + jnp.exp(-y * jnp.dot(x, beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_all = jax.vmap(loss_single, in_axes=(None, 0, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss(beta, X, Y):\n",
    "    \"\"\"\n",
    "    description:\n",
    "    ====\n",
    "     logistic regression loss\n",
    "     ====\n",
    "     args:\n",
    "    ====\n",
    "     beta: LR parameter\n",
    "     X: array[:,:] of images\n",
    "     Y: array[:] of labels\n",
    "    \"\"\"\n",
    "    # compute all the individual losses\n",
    "    loss_individuals = loss_all(beta, X, Y)\n",
    "    \n",
    "    # return the average loss\n",
    "    return jnp.mean(loss_individuals)\n",
    "\n",
    "# let us compute the gradient and compile\n",
    "loss_value_and_grad = jax.jit( jax.value_and_grad(loss) ) # argnums=0, compute gradient wrt first argument (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter of the logistic regression\n",
    "np.random.seed(1)\n",
    "beta_init_bw = np.random.normal(0,scale=1/np.sqrt(100*100),size=(100*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter of the logistic regression\n",
    "np.random.seed(1)\n",
    "beta_init_rgb = np.random.normal(0,scale=1/np.sqrt(100*100*3),size=(100*100*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Gradient Descent with Automatic Step Size Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black and White Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0 \t Loss:71.082 \t error(train):45.5% \t error(val):43.8%\n",
      "iter:1 \t Loss:24.595 \t error(train):47.8% \t error(val):45.7%\n",
      "iter:2 \t Loss:22.864 \t error(train):49.2% \t error(val):47.7%\n",
      "iter:3 \t Loss:22.363 \t error(train):50.1% \t error(val):49.0%\n",
      "iter:4 \t Loss:21.837 \t error(train):48.8% \t error(val):47.2%\n",
      "iter:5 \t Loss:21.184 \t error(train):50.9% \t error(val):49.8%\n",
      "iter:6 \t Loss:20.826 \t error(train):49.5% \t error(val):47.8%\n",
      "iter:7 \t Loss:20.462 \t error(train):51.3% \t error(val):50.3%\n",
      "iter:8 \t Loss:20.145 \t error(train):50.6% \t error(val):48.9%\n",
      "iter:9 \t Loss:19.886 \t error(train):51.8% \t error(val):50.7%\n",
      "iter:10 \t Loss:19.321 \t error(train):50.9% \t error(val):49.2%\n",
      "iter:11 \t Loss:19.052 \t error(train):52.1% \t error(val):50.7%\n",
      "iter:12 \t Loss:18.747 \t error(train):51.1% \t error(val):49.5%\n",
      "iter:13 \t Loss:18.495 \t error(train):52.6% \t error(val):51.5%\n",
      "iter:14 \t Loss:18.199 \t error(train):51.9% \t error(val):50.3%\n",
      "iter:15 \t Loss:18.001 \t error(train):51.9% \t error(val):50.8%\n",
      "iter:16 \t Loss:17.633 \t error(train):52.7% \t error(val):51.9%\n",
      "iter:17 \t Loss:16.594 \t error(train):54.2% \t error(val):53.9%\n",
      "iter:18 \t Loss:14.101 \t error(train):54.7% \t error(val):54.6%\n",
      "iter:19 \t Loss:13.970 \t error(train):55.1% \t error(val):55.4%\n",
      "iter:20 \t Loss:13.839 \t error(train):54.7% \t error(val):54.5%\n",
      "iter:21 \t Loss:13.677 \t error(train):55.3% \t error(val):55.6%\n",
      "iter:22 \t Loss:13.569 \t error(train):55.1% \t error(val):55.0%\n",
      "iter:23 \t Loss:13.383 \t error(train):55.6% \t error(val):56.0%\n",
      "iter:24 \t Loss:13.287 \t error(train):55.2% \t error(val):55.0%\n",
      "iter:25 \t Loss:13.125 \t error(train):55.7% \t error(val):55.8%\n",
      "iter:26 \t Loss:13.023 \t error(train):56.0% \t error(val):56.3%\n",
      "iter:27 \t Loss:12.907 \t error(train):55.8% \t error(val):55.9%\n",
      "iter:28 \t Loss:12.758 \t error(train):56.3% \t error(val):56.4%\n",
      "iter:29 \t Loss:12.676 \t error(train):56.0% \t error(val):55.8%\n",
      "iter:30 \t Loss:12.543 \t error(train):56.4% \t error(val):56.5%\n",
      "iter:31 \t Loss:12.459 \t error(train):56.6% \t error(val):56.6%\n",
      "iter:32 \t Loss:12.365 \t error(train):56.4% \t error(val):56.5%\n",
      "iter:33 \t Loss:12.247 \t error(train):56.9% \t error(val):56.8%\n",
      "iter:34 \t Loss:12.173 \t error(train):56.7% \t error(val):56.6%\n",
      "iter:35 \t Loss:12.049 \t error(train):57.2% \t error(val):57.0%\n",
      "iter:36 \t Loss:11.973 \t error(train):57.0% \t error(val):56.8%\n",
      "iter:37 \t Loss:11.899 \t error(train):57.3% \t error(val):57.1%\n",
      "iter:38 \t Loss:11.833 \t error(train):57.1% \t error(val):56.9%\n",
      "iter:39 \t Loss:11.757 \t error(train):57.4% \t error(val):57.2%\n",
      "iter:40 \t Loss:11.708 \t error(train):57.5% \t error(val):57.5%\n",
      "iter:41 \t Loss:11.614 \t error(train):57.8% \t error(val):57.9%\n",
      "iter:42 \t Loss:11.346 \t error(train):58.4% \t error(val):58.5%\n",
      "iter:43 \t Loss:11.234 \t error(train):58.3% \t error(val):58.2%\n",
      "iter:44 \t Loss:11.152 \t error(train):58.1% \t error(val):58.2%\n",
      "iter:45 \t Loss:11.101 \t error(train):58.3% \t error(val):58.4%\n",
      "iter:46 \t Loss:11.057 \t error(train):58.2% \t error(val):58.1%\n",
      "iter:47 \t Loss:10.968 \t error(train):58.6% \t error(val):58.6%\n",
      "iter:48 \t Loss:10.917 \t error(train):58.4% \t error(val):58.3%\n",
      "iter:49 \t Loss:10.868 \t error(train):58.5% \t error(val):58.7%\n",
      "iter:50 \t Loss:10.833 \t error(train):58.7% \t error(val):58.9%\n",
      "iter:51 \t Loss:10.771 \t error(train):58.8% \t error(val):58.8%\n",
      "iter:52 \t Loss:10.611 \t error(train):58.9% \t error(val):58.9%\n",
      "iter:53 \t Loss:10.577 \t error(train):59.3% \t error(val):59.3%\n",
      "iter:54 \t Loss:10.531 \t error(train):59.1% \t error(val):59.2%\n",
      "iter:55 \t Loss:10.472 \t error(train):59.4% \t error(val):59.4%\n",
      "iter:56 \t Loss:10.437 \t error(train):59.4% \t error(val):59.3%\n",
      "iter:57 \t Loss:10.371 \t error(train):59.6% \t error(val):59.8%\n",
      "iter:58 \t Loss:10.338 \t error(train):59.4% \t error(val):59.2%\n",
      "iter:59 \t Loss:10.276 \t error(train):59.7% \t error(val):59.7%\n",
      "iter:60 \t Loss:10.243 \t error(train):59.9% \t error(val):59.9%\n",
      "iter:61 \t Loss:10.201 \t error(train):59.7% \t error(val):59.7%\n",
      "iter:62 \t Loss:10.147 \t error(train):60.0% \t error(val):60.2%\n",
      "iter:63 \t Loss:10.115 \t error(train):59.8% \t error(val):59.7%\n",
      "iter:64 \t Loss:10.058 \t error(train):60.2% \t error(val):60.6%\n",
      "iter:65 \t Loss:10.025 \t error(train):60.0% \t error(val):60.0%\n",
      "iter:66 \t Loss:9.990 \t error(train):60.3% \t error(val):60.7%\n",
      "iter:67 \t Loss:9.960 \t error(train):60.1% \t error(val):59.9%\n",
      "iter:68 \t Loss:9.924 \t error(train):60.4% \t error(val):61.1%\n",
      "iter:69 \t Loss:9.894 \t error(train):60.2% \t error(val):60.4%\n",
      "iter:70 \t Loss:9.867 \t error(train):60.6% \t error(val):61.3%\n",
      "iter:71 \t Loss:9.814 \t error(train):60.5% \t error(val):61.1%\n",
      "iter:72 \t Loss:9.791 \t error(train):60.4% \t error(val):60.7%\n",
      "iter:73 \t Loss:9.756 \t error(train):61.1% \t error(val):61.9%\n",
      "iter:74 \t Loss:9.694 \t error(train):60.8% \t error(val):61.6%\n",
      "iter:75 \t Loss:9.648 \t error(train):60.5% \t error(val):60.9%\n",
      "iter:76 \t Loss:9.622 \t error(train):60.9% \t error(val):61.6%\n",
      "iter:77 \t Loss:9.598 \t error(train):60.7% \t error(val):61.1%\n",
      "iter:78 \t Loss:9.569 \t error(train):60.9% \t error(val):61.7%\n",
      "iter:79 \t Loss:9.546 \t error(train):60.7% \t error(val):61.2%\n",
      "iter:80 \t Loss:9.517 \t error(train):61.0% \t error(val):61.9%\n",
      "iter:81 \t Loss:9.493 \t error(train):60.8% \t error(val):61.6%\n",
      "iter:82 \t Loss:9.470 \t error(train):61.4% \t error(val):62.2%\n",
      "iter:83 \t Loss:9.433 \t error(train):61.0% \t error(val):62.0%\n",
      "iter:84 \t Loss:9.406 \t error(train):61.0% \t error(val):61.7%\n",
      "iter:85 \t Loss:9.377 \t error(train):61.4% \t error(val):62.3%\n",
      "iter:86 \t Loss:9.343 \t error(train):61.1% \t error(val):62.0%\n",
      "iter:87 \t Loss:9.319 \t error(train):61.4% \t error(val):62.4%\n",
      "iter:88 \t Loss:9.296 \t error(train):61.1% \t error(val):62.0%\n",
      "iter:89 \t Loss:9.277 \t error(train):61.7% \t error(val):62.5%\n",
      "iter:90 \t Loss:9.240 \t error(train):61.4% \t error(val):62.5%\n",
      "iter:91 \t Loss:9.215 \t error(train):61.4% \t error(val):62.4%\n",
      "iter:92 \t Loss:9.187 \t error(train):62.0% \t error(val):62.9%\n",
      "iter:93 \t Loss:9.123 \t error(train):61.7% \t error(val):62.7%\n",
      "iter:94 \t Loss:9.097 \t error(train):61.6% \t error(val):62.8%\n",
      "iter:95 \t Loss:9.075 \t error(train):62.0% \t error(val):62.9%\n",
      "iter:96 \t Loss:9.051 \t error(train):61.7% \t error(val):62.9%\n",
      "iter:97 \t Loss:9.029 \t error(train):62.1% \t error(val):63.0%\n",
      "iter:98 \t Loss:9.002 \t error(train):61.9% \t error(val):63.1%\n",
      "iter:99 \t Loss:8.986 \t error(train):61.9% \t error(val):63.0%\n",
      "iter:100 \t Loss:8.966 \t error(train):62.3% \t error(val):63.0%\n",
      "iter:101 \t Loss:8.941 \t error(train):62.0% \t error(val):63.1%\n",
      "iter:102 \t Loss:8.924 \t error(train):62.3% \t error(val):63.2%\n",
      "iter:103 \t Loss:8.894 \t error(train):62.1% \t error(val):63.2%\n",
      "iter:104 \t Loss:8.880 \t error(train):62.4% \t error(val):63.3%\n",
      "iter:105 \t Loss:8.849 \t error(train):62.1% \t error(val):63.4%\n",
      "iter:106 \t Loss:8.832 \t error(train):62.4% \t error(val):63.4%\n",
      "iter:107 \t Loss:8.814 \t error(train):62.2% \t error(val):63.4%\n",
      "iter:108 \t Loss:8.798 \t error(train):62.6% \t error(val):63.6%\n",
      "iter:109 \t Loss:8.780 \t error(train):62.3% \t error(val):63.3%\n",
      "iter:110 \t Loss:8.766 \t error(train):62.3% \t error(val):63.4%\n",
      "iter:111 \t Loss:8.742 \t error(train):62.5% \t error(val):63.6%\n",
      "iter:112 \t Loss:8.671 \t error(train):62.9% \t error(val):63.8%\n",
      "iter:113 \t Loss:8.484 \t error(train):62.9% \t error(val):64.0%\n",
      "iter:114 \t Loss:8.467 \t error(train):62.9% \t error(val):64.0%\n",
      "iter:115 \t Loss:8.453 \t error(train):63.0% \t error(val):64.0%\n",
      "iter:116 \t Loss:8.437 \t error(train):63.0% \t error(val):64.0%\n",
      "iter:117 \t Loss:8.425 \t error(train):63.1% \t error(val):64.1%\n",
      "iter:118 \t Loss:8.404 \t error(train):63.2% \t error(val):64.4%\n",
      "iter:119 \t Loss:8.346 \t error(train):63.2% \t error(val):64.2%\n",
      "iter:120 \t Loss:8.335 \t error(train):63.2% \t error(val):64.3%\n",
      "iter:121 \t Loss:8.317 \t error(train):63.4% \t error(val):64.5%\n",
      "iter:122 \t Loss:8.275 \t error(train):63.4% \t error(val):64.2%\n",
      "iter:123 \t Loss:8.262 \t error(train):63.4% \t error(val):64.2%\n",
      "iter:124 \t Loss:8.248 \t error(train):63.4% \t error(val):64.5%\n",
      "iter:125 \t Loss:8.231 \t error(train):63.5% \t error(val):64.2%\n",
      "iter:126 \t Loss:8.219 \t error(train):63.5% \t error(val):64.4%\n",
      "iter:127 \t Loss:8.199 \t error(train):63.6% \t error(val):64.3%\n",
      "iter:128 \t Loss:8.188 \t error(train):63.6% \t error(val):64.6%\n",
      "iter:129 \t Loss:8.167 \t error(train):63.6% \t error(val):64.5%\n",
      "iter:130 \t Loss:8.157 \t error(train):63.6% \t error(val):64.4%\n",
      "iter:131 \t Loss:8.143 \t error(train):63.8% \t error(val):64.9%\n",
      "iter:132 \t Loss:8.117 \t error(train):63.7% \t error(val):64.5%\n",
      "iter:133 \t Loss:8.098 \t error(train):63.7% \t error(val):64.5%\n",
      "iter:134 \t Loss:8.087 \t error(train):63.8% \t error(val):64.5%\n",
      "iter:135 \t Loss:8.077 \t error(train):63.8% \t error(val):64.5%\n",
      "iter:136 \t Loss:8.058 \t error(train):63.8% \t error(val):64.6%\n",
      "iter:137 \t Loss:8.046 \t error(train):63.8% \t error(val):64.6%\n",
      "iter:138 \t Loss:8.032 \t error(train):63.9% \t error(val):64.5%\n",
      "iter:139 \t Loss:8.004 \t error(train):63.9% \t error(val):64.7%\n",
      "iter:140 \t Loss:7.986 \t error(train):64.0% \t error(val):64.9%\n",
      "iter:141 \t Loss:7.975 \t error(train):63.9% \t error(val):64.7%\n",
      "iter:142 \t Loss:7.966 \t error(train):64.1% \t error(val):65.0%\n",
      "iter:143 \t Loss:7.954 \t error(train):64.0% \t error(val):64.7%\n",
      "iter:144 \t Loss:7.944 \t error(train):64.2% \t error(val):65.0%\n",
      "iter:145 \t Loss:7.932 \t error(train):64.1% \t error(val):64.9%\n",
      "iter:146 \t Loss:7.923 \t error(train):64.1% \t error(val):64.9%\n",
      "iter:147 \t Loss:7.906 \t error(train):64.1% \t error(val):64.7%\n",
      "iter:148 \t Loss:7.865 \t error(train):64.2% \t error(val):64.9%\n",
      "iter:149 \t Loss:7.854 \t error(train):64.2% \t error(val):65.1%\n",
      "iter:150 \t Loss:7.841 \t error(train):64.2% \t error(val):64.8%\n",
      "iter:151 \t Loss:7.811 \t error(train):64.3% \t error(val):65.1%\n",
      "iter:152 \t Loss:7.799 \t error(train):64.4% \t error(val):65.1%\n",
      "iter:153 \t Loss:7.788 \t error(train):64.3% \t error(val):65.0%\n",
      "iter:154 \t Loss:7.777 \t error(train):64.4% \t error(val):65.2%\n",
      "iter:155 \t Loss:7.766 \t error(train):64.3% \t error(val):65.1%\n",
      "iter:156 \t Loss:7.751 \t error(train):64.5% \t error(val):65.2%\n",
      "iter:157 \t Loss:7.741 \t error(train):64.4% \t error(val):65.3%\n",
      "iter:158 \t Loss:7.732 \t error(train):64.6% \t error(val):65.4%\n",
      "iter:159 \t Loss:7.721 \t error(train):64.5% \t error(val):65.3%\n",
      "iter:160 \t Loss:7.710 \t error(train):64.6% \t error(val):65.5%\n",
      "iter:161 \t Loss:7.695 \t error(train):64.5% \t error(val):65.3%\n",
      "iter:162 \t Loss:7.688 \t error(train):64.7% \t error(val):65.5%\n",
      "iter:163 \t Loss:7.672 \t error(train):64.6% \t error(val):65.4%\n",
      "iter:164 \t Loss:7.663 \t error(train):64.6% \t error(val):65.6%\n",
      "iter:165 \t Loss:7.653 \t error(train):64.6% \t error(val):65.4%\n",
      "iter:166 \t Loss:7.645 \t error(train):64.7% \t error(val):65.6%\n",
      "iter:167 \t Loss:7.635 \t error(train):64.6% \t error(val):65.4%\n",
      "iter:168 \t Loss:7.626 \t error(train):64.7% \t error(val):65.5%\n",
      "iter:169 \t Loss:7.618 \t error(train):64.6% \t error(val):65.5%\n",
      "iter:170 \t Loss:7.603 \t error(train):64.7% \t error(val):65.4%\n",
      "iter:171 \t Loss:7.595 \t error(train):64.8% \t error(val):65.5%\n",
      "iter:172 \t Loss:7.585 \t error(train):64.7% \t error(val):65.4%\n",
      "iter:173 \t Loss:7.571 \t error(train):64.8% \t error(val):65.5%\n",
      "iter:174 \t Loss:7.563 \t error(train):64.7% \t error(val):65.6%\n",
      "iter:175 \t Loss:7.549 \t error(train):64.8% \t error(val):65.6%\n",
      "iter:176 \t Loss:7.542 \t error(train):64.8% \t error(val):65.7%\n",
      "iter:177 \t Loss:7.532 \t error(train):64.8% \t error(val):65.7%\n",
      "iter:178 \t Loss:7.519 \t error(train):64.9% \t error(val):65.6%\n",
      "iter:179 \t Loss:7.511 \t error(train):64.9% \t error(val):65.8%\n",
      "iter:180 \t Loss:7.497 \t error(train):64.9% \t error(val):65.8%\n",
      "iter:181 \t Loss:7.489 \t error(train):64.8% \t error(val):65.8%\n",
      "iter:182 \t Loss:7.477 \t error(train):64.9% \t error(val):65.8%\n",
      "iter:183 \t Loss:7.467 \t error(train):64.9% \t error(val):65.9%\n",
      "iter:184 \t Loss:7.457 \t error(train):65.0% \t error(val):66.0%\n",
      "iter:185 \t Loss:7.444 \t error(train):64.9% \t error(val):65.9%\n",
      "iter:186 \t Loss:7.436 \t error(train):65.0% \t error(val):66.0%\n",
      "iter:187 \t Loss:7.424 \t error(train):65.0% \t error(val):66.0%\n",
      "iter:188 \t Loss:7.416 \t error(train):65.0% \t error(val):66.0%\n",
      "iter:189 \t Loss:7.407 \t error(train):65.0% \t error(val):66.1%\n",
      "iter:190 \t Loss:7.395 \t error(train):65.0% \t error(val):66.0%\n",
      "iter:191 \t Loss:7.387 \t error(train):65.0% \t error(val):66.1%\n",
      "iter:192 \t Loss:7.374 \t error(train):65.0% \t error(val):66.1%\n",
      "iter:193 \t Loss:7.366 \t error(train):65.0% \t error(val):66.1%\n",
      "iter:194 \t Loss:7.358 \t error(train):65.1% \t error(val):66.2%\n",
      "iter:195 \t Loss:7.351 \t error(train):65.1% \t error(val):66.1%\n",
      "iter:196 \t Loss:7.342 \t error(train):65.0% \t error(val):66.3%\n",
      "iter:197 \t Loss:7.334 \t error(train):65.1% \t error(val):66.1%\n",
      "iter:198 \t Loss:7.328 \t error(train):65.1% \t error(val):66.3%\n",
      "iter:199 \t Loss:7.315 \t error(train):65.1% \t error(val):66.1%\n",
      "iter:200 \t Loss:7.308 \t error(train):65.1% \t error(val):66.2%\n",
      "iter:201 \t Loss:7.299 \t error(train):65.2% \t error(val):66.6%\n",
      "iter:202 \t Loss:7.282 \t error(train):65.2% \t error(val):66.3%\n",
      "iter:203 \t Loss:7.270 \t error(train):65.2% \t error(val):66.2%\n",
      "iter:204 \t Loss:7.262 \t error(train):65.2% \t error(val):66.3%\n",
      "iter:205 \t Loss:7.256 \t error(train):65.1% \t error(val):66.3%\n",
      "iter:206 \t Loss:7.244 \t error(train):65.3% \t error(val):66.3%\n",
      "iter:207 \t Loss:7.235 \t error(train):65.3% \t error(val):66.4%\n",
      "iter:208 \t Loss:7.226 \t error(train):65.2% \t error(val):66.4%\n",
      "iter:209 \t Loss:7.207 \t error(train):65.3% \t error(val):66.4%\n",
      "iter:210 \t Loss:7.196 \t error(train):65.3% \t error(val):66.6%\n",
      "iter:211 \t Loss:7.188 \t error(train):65.3% \t error(val):66.4%\n",
      "iter:212 \t Loss:7.182 \t error(train):65.4% \t error(val):66.6%\n",
      "iter:213 \t Loss:7.173 \t error(train):65.3% \t error(val):66.4%\n",
      "iter:214 \t Loss:7.167 \t error(train):65.4% \t error(val):66.7%\n",
      "iter:215 \t Loss:7.159 \t error(train):65.3% \t error(val):66.6%\n",
      "iter:216 \t Loss:7.152 \t error(train):65.3% \t error(val):66.7%\n",
      "iter:217 \t Loss:7.141 \t error(train):65.4% \t error(val):66.6%\n",
      "iter:218 \t Loss:7.112 \t error(train):65.4% \t error(val):66.7%\n",
      "iter:219 \t Loss:7.106 \t error(train):65.4% \t error(val):66.8%\n",
      "iter:220 \t Loss:7.097 \t error(train):65.4% \t error(val):66.6%\n",
      "iter:221 \t Loss:7.075 \t error(train):65.5% \t error(val):66.8%\n",
      "iter:222 \t Loss:7.067 \t error(train):65.5% \t error(val):66.9%\n",
      "iter:223 \t Loss:7.060 \t error(train):65.4% \t error(val):66.7%\n",
      "iter:224 \t Loss:7.051 \t error(train):65.5% \t error(val):67.0%\n",
      "iter:225 \t Loss:7.044 \t error(train):65.4% \t error(val):66.8%\n",
      "iter:226 \t Loss:7.034 \t error(train):65.6% \t error(val):67.1%\n",
      "iter:227 \t Loss:7.027 \t error(train):65.5% \t error(val):66.9%\n",
      "iter:228 \t Loss:7.017 \t error(train):65.6% \t error(val):66.9%\n",
      "iter:229 \t Loss:7.010 \t error(train):65.6% \t error(val):67.1%\n",
      "iter:230 \t Loss:7.003 \t error(train):65.5% \t error(val):66.9%\n",
      "iter:231 \t Loss:6.993 \t error(train):65.6% \t error(val):67.2%\n",
      "iter:232 \t Loss:6.987 \t error(train):65.5% \t error(val):67.0%\n",
      "iter:233 \t Loss:6.976 \t error(train):65.7% \t error(val):67.0%\n",
      "iter:234 \t Loss:6.971 \t error(train):65.7% \t error(val):67.1%\n",
      "iter:235 \t Loss:6.964 \t error(train):65.7% \t error(val):67.1%\n",
      "iter:236 \t Loss:6.951 \t error(train):65.7% \t error(val):67.1%\n",
      "iter:237 \t Loss:6.941 \t error(train):65.7% \t error(val):67.0%\n",
      "iter:238 \t Loss:6.935 \t error(train):65.7% \t error(val):67.2%\n",
      "iter:239 \t Loss:6.929 \t error(train):65.7% \t error(val):67.1%\n",
      "iter:240 \t Loss:6.918 \t error(train):65.7% \t error(val):67.2%\n",
      "iter:241 \t Loss:6.913 \t error(train):65.7% \t error(val):67.2%\n",
      "iter:242 \t Loss:6.905 \t error(train):65.8% \t error(val):67.2%\n",
      "iter:243 \t Loss:6.890 \t error(train):65.9% \t error(val):67.2%\n",
      "iter:244 \t Loss:6.881 \t error(train):65.8% \t error(val):67.3%\n",
      "iter:245 \t Loss:6.875 \t error(train):65.9% \t error(val):67.2%\n",
      "iter:246 \t Loss:6.870 \t error(train):65.8% \t error(val):67.2%\n",
      "iter:247 \t Loss:6.859 \t error(train):65.8% \t error(val):67.3%\n",
      "iter:248 \t Loss:6.853 \t error(train):65.9% \t error(val):67.3%\n",
      "iter:249 \t Loss:6.845 \t error(train):65.9% \t error(val):67.2%\n",
      "iter:250 \t Loss:6.826 \t error(train):65.9% \t error(val):67.4%\n",
      "iter:251 \t Loss:6.819 \t error(train):66.0% \t error(val):67.3%\n",
      "iter:252 \t Loss:6.813 \t error(train):66.0% \t error(val):67.3%\n",
      "iter:253 \t Loss:6.805 \t error(train):66.0% \t error(val):67.3%\n",
      "iter:254 \t Loss:6.799 \t error(train):66.0% \t error(val):67.4%\n",
      "iter:255 \t Loss:6.790 \t error(train):66.0% \t error(val):67.4%\n",
      "iter:256 \t Loss:6.784 \t error(train):66.1% \t error(val):67.4%\n",
      "iter:257 \t Loss:6.775 \t error(train):66.0% \t error(val):67.4%\n",
      "iter:258 \t Loss:6.769 \t error(train):66.0% \t error(val):67.3%\n",
      "iter:259 \t Loss:6.763 \t error(train):66.0% \t error(val):67.5%\n",
      "iter:260 \t Loss:6.754 \t error(train):66.0% \t error(val):67.3%\n",
      "iter:261 \t Loss:6.749 \t error(train):66.1% \t error(val):67.4%\n",
      "iter:262 \t Loss:6.739 \t error(train):66.1% \t error(val):67.4%\n",
      "iter:263 \t Loss:6.733 \t error(train):66.1% \t error(val):67.5%\n",
      "iter:264 \t Loss:6.727 \t error(train):66.1% \t error(val):67.4%\n",
      "iter:265 \t Loss:6.722 \t error(train):66.1% \t error(val):67.6%\n",
      "iter:266 \t Loss:6.716 \t error(train):66.1% \t error(val):67.4%\n",
      "iter:267 \t Loss:6.712 \t error(train):66.2% \t error(val):67.4%\n",
      "iter:268 \t Loss:6.703 \t error(train):66.2% \t error(val):67.6%\n",
      "iter:269 \t Loss:6.680 \t error(train):66.3% \t error(val):67.8%\n",
      "iter:270 \t Loss:6.668 \t error(train):66.2% \t error(val):67.7%\n",
      "iter:271 \t Loss:6.661 \t error(train):66.3% \t error(val):67.5%\n",
      "iter:272 \t Loss:6.656 \t error(train):66.2% \t error(val):67.7%\n",
      "iter:273 \t Loss:6.650 \t error(train):66.2% \t error(val):67.6%\n",
      "iter:274 \t Loss:6.645 \t error(train):66.3% \t error(val):67.6%\n",
      "iter:275 \t Loss:6.637 \t error(train):66.4% \t error(val):67.7%\n",
      "iter:276 \t Loss:6.613 \t error(train):66.3% \t error(val):67.7%\n",
      "iter:277 \t Loss:6.608 \t error(train):66.4% \t error(val):67.8%\n",
      "iter:278 \t Loss:6.602 \t error(train):66.4% \t error(val):67.6%\n",
      "iter:279 \t Loss:6.598 \t error(train):66.4% \t error(val):67.6%\n",
      "iter:280 \t Loss:6.590 \t error(train):66.5% \t error(val):67.7%\n",
      "iter:281 \t Loss:6.567 \t error(train):66.7% \t error(val):68.1%\n",
      "iter:282 \t Loss:6.517 \t error(train):66.7% \t error(val):68.0%\n",
      "iter:283 \t Loss:6.500 \t error(train):66.6% \t error(val):68.0%\n",
      "iter:284 \t Loss:6.495 \t error(train):66.6% \t error(val):68.0%\n",
      "iter:285 \t Loss:6.488 \t error(train):66.7% \t error(val):68.0%\n",
      "iter:286 \t Loss:6.468 \t error(train):66.8% \t error(val):68.0%\n",
      "iter:287 \t Loss:6.464 \t error(train):66.7% \t error(val):68.0%\n",
      "iter:288 \t Loss:6.458 \t error(train):66.8% \t error(val):68.1%\n",
      "iter:289 \t Loss:6.454 \t error(train):66.7% \t error(val):68.0%\n",
      "iter:290 \t Loss:6.448 \t error(train):66.8% \t error(val):68.1%\n",
      "iter:291 \t Loss:6.444 \t error(train):66.8% \t error(val):68.2%\n",
      "iter:292 \t Loss:6.437 \t error(train):66.9% \t error(val):68.2%\n",
      "iter:293 \t Loss:6.415 \t error(train):66.9% \t error(val):68.1%\n",
      "iter:294 \t Loss:6.402 \t error(train):66.9% \t error(val):68.2%\n",
      "iter:295 \t Loss:6.396 \t error(train):66.9% \t error(val):68.1%\n",
      "iter:296 \t Loss:6.389 \t error(train):66.9% \t error(val):68.4%\n",
      "iter:297 \t Loss:6.384 \t error(train):66.9% \t error(val):68.2%\n",
      "iter:298 \t Loss:6.379 \t error(train):66.9% \t error(val):68.4%\n",
      "iter:299 \t Loss:6.375 \t error(train):67.0% \t error(val):68.2%\n",
      "iter:300 \t Loss:6.367 \t error(train):67.0% \t error(val):68.3%\n",
      "iter:301 \t Loss:6.361 \t error(train):67.0% \t error(val):68.4%\n",
      "iter:302 \t Loss:6.355 \t error(train):67.1% \t error(val):68.3%\n",
      "iter:303 \t Loss:6.340 \t error(train):67.0% \t error(val):68.3%\n",
      "iter:304 \t Loss:6.335 \t error(train):67.0% \t error(val):68.7%\n",
      "iter:305 \t Loss:6.329 \t error(train):67.1% \t error(val):68.4%\n",
      "iter:306 \t Loss:6.323 \t error(train):67.0% \t error(val):68.6%\n",
      "iter:307 \t Loss:6.319 \t error(train):67.1% \t error(val):68.4%\n",
      "iter:308 \t Loss:6.311 \t error(train):67.0% \t error(val):68.8%\n",
      "iter:309 \t Loss:6.307 \t error(train):67.1% \t error(val):68.4%\n",
      "iter:310 \t Loss:6.302 \t error(train):67.1% \t error(val):68.8%\n",
      "iter:311 \t Loss:6.298 \t error(train):67.2% \t error(val):68.5%\n",
      "iter:312 \t Loss:6.290 \t error(train):67.1% \t error(val):68.5%\n",
      "iter:313 \t Loss:6.285 \t error(train):67.1% \t error(val):68.6%\n",
      "iter:314 \t Loss:6.278 \t error(train):67.2% \t error(val):68.5%\n",
      "iter:315 \t Loss:6.263 \t error(train):67.3% \t error(val):68.8%\n",
      "iter:316 \t Loss:6.258 \t error(train):67.2% \t error(val):68.8%\n",
      "iter:317 \t Loss:6.253 \t error(train):67.2% \t error(val):68.6%\n",
      "iter:318 \t Loss:6.247 \t error(train):67.3% \t error(val):68.8%\n",
      "iter:319 \t Loss:6.243 \t error(train):67.3% \t error(val):68.6%\n",
      "iter:320 \t Loss:6.235 \t error(train):67.2% \t error(val):68.9%\n",
      "iter:321 \t Loss:6.231 \t error(train):67.3% \t error(val):68.7%\n",
      "iter:322 \t Loss:6.226 \t error(train):67.3% \t error(val):68.9%\n",
      "iter:323 \t Loss:6.222 \t error(train):67.3% \t error(val):68.7%\n",
      "iter:324 \t Loss:6.217 \t error(train):67.3% \t error(val):68.9%\n",
      "iter:325 \t Loss:6.213 \t error(train):67.3% \t error(val):68.8%\n",
      "iter:326 \t Loss:6.208 \t error(train):67.4% \t error(val):68.9%\n",
      "iter:327 \t Loss:6.204 \t error(train):67.4% \t error(val):68.8%\n",
      "iter:328 \t Loss:6.198 \t error(train):67.3% \t error(val):68.8%\n",
      "iter:329 \t Loss:6.180 \t error(train):67.4% \t error(val):68.9%\n",
      "iter:330 \t Loss:6.176 \t error(train):67.5% \t error(val):68.9%\n",
      "iter:331 \t Loss:6.170 \t error(train):67.3% \t error(val):68.7%\n",
      "iter:332 \t Loss:6.157 \t error(train):67.4% \t error(val):68.9%\n",
      "iter:333 \t Loss:6.152 \t error(train):67.5% \t error(val):68.9%\n",
      "iter:334 \t Loss:6.147 \t error(train):67.4% \t error(val):68.9%\n",
      "iter:335 \t Loss:6.142 \t error(train):67.6% \t error(val):68.9%\n",
      "iter:336 \t Loss:6.137 \t error(train):67.4% \t error(val):69.0%\n",
      "iter:337 \t Loss:6.131 \t error(train):67.6% \t error(val):69.0%\n",
      "iter:338 \t Loss:6.127 \t error(train):67.4% \t error(val):68.8%\n",
      "iter:339 \t Loss:6.121 \t error(train):67.5% \t error(val):68.9%\n",
      "iter:340 \t Loss:6.116 \t error(train):67.6% \t error(val):69.0%\n",
      "iter:341 \t Loss:6.111 \t error(train):67.5% \t error(val):68.9%\n",
      "iter:342 \t Loss:6.105 \t error(train):67.7% \t error(val):69.0%\n",
      "iter:343 \t Loss:6.101 \t error(train):67.5% \t error(val):68.9%\n",
      "iter:344 \t Loss:6.095 \t error(train):67.6% \t error(val):68.9%\n",
      "iter:345 \t Loss:6.091 \t error(train):67.7% \t error(val):69.0%\n",
      "iter:346 \t Loss:6.086 \t error(train):67.5% \t error(val):69.0%\n",
      "iter:347 \t Loss:6.081 \t error(train):67.7% \t error(val):69.0%\n",
      "iter:348 \t Loss:6.077 \t error(train):67.5% \t error(val):69.0%\n",
      "iter:349 \t Loss:6.070 \t error(train):67.7% \t error(val):69.0%\n",
      "iter:350 \t Loss:6.066 \t error(train):67.5% \t error(val):68.9%\n",
      "iter:351 \t Loss:6.060 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:352 \t Loss:6.056 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:353 \t Loss:6.051 \t error(train):67.6% \t error(val):68.9%\n",
      "iter:354 \t Loss:6.045 \t error(train):67.8% \t error(val):69.1%\n",
      "iter:355 \t Loss:6.041 \t error(train):67.6% \t error(val):68.9%\n",
      "iter:356 \t Loss:6.035 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:357 \t Loss:6.031 \t error(train):67.7% \t error(val):69.2%\n",
      "iter:358 \t Loss:6.027 \t error(train):67.7% \t error(val):69.0%\n",
      "iter:359 \t Loss:6.021 \t error(train):67.8% \t error(val):69.2%\n",
      "iter:360 \t Loss:6.017 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:361 \t Loss:6.011 \t error(train):67.8% \t error(val):69.2%\n",
      "iter:362 \t Loss:6.007 \t error(train):67.6% \t error(val):69.0%\n",
      "iter:363 \t Loss:6.001 \t error(train):67.8% \t error(val):69.1%\n",
      "iter:364 \t Loss:5.997 \t error(train):67.8% \t error(val):69.2%\n",
      "iter:365 \t Loss:5.992 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:366 \t Loss:5.986 \t error(train):67.9% \t error(val):69.2%\n",
      "iter:367 \t Loss:5.982 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:368 \t Loss:5.976 \t error(train):67.8% \t error(val):69.2%\n",
      "iter:369 \t Loss:5.972 \t error(train):67.9% \t error(val):69.2%\n",
      "iter:370 \t Loss:5.968 \t error(train):67.7% \t error(val):69.1%\n",
      "iter:371 \t Loss:5.962 \t error(train):67.9% \t error(val):69.2%\n",
      "iter:372 \t Loss:5.959 \t error(train):67.8% \t error(val):69.1%\n",
      "iter:373 \t Loss:5.953 \t error(train):67.9% \t error(val):69.2%\n",
      "iter:374 \t Loss:5.948 \t error(train):67.8% \t error(val):69.1%\n",
      "iter:375 \t Loss:5.945 \t error(train):67.9% \t error(val):69.2%\n",
      "iter:376 \t Loss:5.941 \t error(train):67.8% \t error(val):69.2%\n",
      "iter:377 \t Loss:5.937 \t error(train):67.9% \t error(val):69.3%\n",
      "iter:378 \t Loss:5.933 \t error(train):67.9% \t error(val):69.3%\n",
      "iter:379 \t Loss:5.930 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:380 \t Loss:5.923 \t error(train):67.9% \t error(val):69.3%\n",
      "iter:381 \t Loss:5.920 \t error(train):67.9% \t error(val):69.3%\n",
      "iter:382 \t Loss:5.916 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:383 \t Loss:5.907 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:384 \t Loss:5.902 \t error(train):67.9% \t error(val):69.3%\n",
      "iter:385 \t Loss:5.898 \t error(train):68.0% \t error(val):69.4%\n",
      "iter:386 \t Loss:5.895 \t error(train):67.8% \t error(val):69.3%\n",
      "iter:387 \t Loss:5.888 \t error(train):67.9% \t error(val):69.3%\n",
      "iter:388 \t Loss:5.885 \t error(train):68.0% \t error(val):69.4%\n",
      "iter:389 \t Loss:5.880 \t error(train):67.8% \t error(val):69.2%\n",
      "iter:390 \t Loss:5.871 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:391 \t Loss:5.865 \t error(train):68.0% \t error(val):69.4%\n",
      "iter:392 \t Loss:5.861 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:393 \t Loss:5.858 \t error(train):68.1% \t error(val):69.4%\n",
      "iter:394 \t Loss:5.854 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:395 \t Loss:5.850 \t error(train):68.1% \t error(val):69.6%\n",
      "iter:396 \t Loss:5.846 \t error(train):68.0% \t error(val):69.3%\n",
      "iter:397 \t Loss:5.843 \t error(train):68.0% \t error(val):69.4%\n",
      "iter:398 \t Loss:5.838 \t error(train):68.0% \t error(val):69.4%\n",
      "iter:399 \t Loss:5.822 \t error(train):68.1% \t error(val):69.4%\n",
      "iter:400 \t Loss:5.820 \t error(train):68.1% \t error(val):69.5%\n",
      "iter:401 \t Loss:5.815 \t error(train):68.1% \t error(val):69.4%\n",
      "iter:402 \t Loss:5.803 \t error(train):68.1% \t error(val):69.4%\n",
      "iter:403 \t Loss:5.800 \t error(train):68.1% \t error(val):69.4%\n",
      "iter:404 \t Loss:5.796 \t error(train):68.1% \t error(val):69.5%\n",
      "iter:405 \t Loss:5.792 \t error(train):68.1% \t error(val):69.4%\n",
      "iter:406 \t Loss:5.788 \t error(train):68.1% \t error(val):69.5%\n",
      "iter:407 \t Loss:5.782 \t error(train):68.2% \t error(val):69.4%\n",
      "iter:408 \t Loss:5.779 \t error(train):68.2% \t error(val):69.4%\n",
      "iter:409 \t Loss:5.773 \t error(train):68.2% \t error(val):69.5%\n",
      "iter:410 \t Loss:5.770 \t error(train):68.2% \t error(val):69.5%\n",
      "iter:411 \t Loss:5.766 \t error(train):68.1% \t error(val):69.5%\n",
      "iter:412 \t Loss:5.759 \t error(train):68.3% \t error(val):69.6%\n",
      "iter:413 \t Loss:5.754 \t error(train):68.3% \t error(val):69.6%\n",
      "iter:414 \t Loss:5.750 \t error(train):68.3% \t error(val):69.6%\n",
      "iter:415 \t Loss:5.747 \t error(train):68.3% \t error(val):69.6%\n",
      "iter:416 \t Loss:5.742 \t error(train):68.3% \t error(val):69.6%\n",
      "iter:417 \t Loss:5.738 \t error(train):68.3% \t error(val):69.6%\n",
      "iter:418 \t Loss:5.734 \t error(train):68.3% \t error(val):69.7%\n",
      "iter:419 \t Loss:5.725 \t error(train):68.3% \t error(val):69.7%\n",
      "iter:420 \t Loss:5.720 \t error(train):68.3% \t error(val):69.7%\n",
      "iter:421 \t Loss:5.717 \t error(train):68.3% \t error(val):69.7%\n",
      "iter:422 \t Loss:5.714 \t error(train):68.3% \t error(val):69.7%\n",
      "iter:423 \t Loss:5.708 \t error(train):68.3% \t error(val):69.7%\n",
      "iter:424 \t Loss:5.704 \t error(train):68.4% \t error(val):69.7%\n",
      "iter:425 \t Loss:5.700 \t error(train):68.4% \t error(val):69.7%\n",
      "iter:426 \t Loss:5.689 \t error(train):68.4% \t error(val):69.7%\n",
      "iter:427 \t Loss:5.685 \t error(train):68.4% \t error(val):69.8%\n",
      "iter:428 \t Loss:5.681 \t error(train):68.4% \t error(val):69.6%\n",
      "iter:429 \t Loss:5.677 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:430 \t Loss:5.673 \t error(train):68.5% \t error(val):69.7%\n",
      "iter:431 \t Loss:5.669 \t error(train):68.4% \t error(val):69.7%\n",
      "iter:432 \t Loss:5.666 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:433 \t Loss:5.662 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:434 \t Loss:5.658 \t error(train):68.5% \t error(val):69.9%\n",
      "iter:435 \t Loss:5.655 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:436 \t Loss:5.650 \t error(train):68.5% \t error(val):69.9%\n",
      "iter:437 \t Loss:5.647 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:438 \t Loss:5.641 \t error(train):68.5% \t error(val):69.9%\n",
      "iter:439 \t Loss:5.638 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:440 \t Loss:5.635 \t error(train):68.6% \t error(val):69.9%\n",
      "iter:441 \t Loss:5.632 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:442 \t Loss:5.628 \t error(train):68.5% \t error(val):69.9%\n",
      "iter:443 \t Loss:5.626 \t error(train):68.5% \t error(val):69.9%\n",
      "iter:444 \t Loss:5.621 \t error(train):68.6% \t error(val):69.9%\n",
      "iter:445 \t Loss:5.607 \t error(train):68.5% \t error(val):69.8%\n",
      "iter:446 \t Loss:5.583 \t error(train):68.6% \t error(val):69.9%\n",
      "iter:447 \t Loss:5.567 \t error(train):68.7% \t error(val):70.0%\n",
      "iter:448 \t Loss:5.563 \t error(train):68.8% \t error(val):70.0%\n",
      "iter:449 \t Loss:5.559 \t error(train):68.7% \t error(val):70.0%\n",
      "iter:450 \t Loss:5.546 \t error(train):68.8% \t error(val):70.0%\n",
      "iter:451 \t Loss:5.544 \t error(train):68.7% \t error(val):70.0%\n",
      "iter:452 \t Loss:5.540 \t error(train):68.8% \t error(val):70.0%\n",
      "iter:453 \t Loss:5.537 \t error(train):68.7% \t error(val):70.0%\n",
      "iter:454 \t Loss:5.534 \t error(train):68.8% \t error(val):70.0%\n",
      "iter:455 \t Loss:5.532 \t error(train):68.8% \t error(val):70.0%\n",
      "iter:456 \t Loss:5.527 \t error(train):68.9% \t error(val):70.0%\n",
      "iter:457 \t Loss:5.514 \t error(train):68.9% \t error(val):70.1%\n",
      "iter:458 \t Loss:5.511 \t error(train):68.9% \t error(val):70.0%\n",
      "iter:459 \t Loss:5.508 \t error(train):68.8% \t error(val):70.1%\n",
      "iter:460 \t Loss:5.505 \t error(train):68.9% \t error(val):70.1%\n",
      "iter:461 \t Loss:5.502 \t error(train):68.8% \t error(val):70.1%\n",
      "iter:462 \t Loss:5.497 \t error(train):68.9% \t error(val):70.1%\n",
      "iter:463 \t Loss:5.495 \t error(train):68.9% \t error(val):70.1%\n",
      "iter:464 \t Loss:5.491 \t error(train):68.9% \t error(val):70.2%\n",
      "iter:465 \t Loss:5.485 \t error(train):68.9% \t error(val):70.1%\n",
      "iter:466 \t Loss:5.480 \t error(train):69.0% \t error(val):70.1%\n",
      "iter:467 \t Loss:5.477 \t error(train):68.9% \t error(val):70.1%\n",
      "iter:468 \t Loss:5.475 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:469 \t Loss:5.470 \t error(train):69.0% \t error(val):70.1%\n",
      "iter:470 \t Loss:5.467 \t error(train):69.0% \t error(val):70.1%\n",
      "iter:471 \t Loss:5.463 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:472 \t Loss:5.455 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:473 \t Loss:5.451 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:474 \t Loss:5.448 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:475 \t Loss:5.445 \t error(train):69.0% \t error(val):70.3%\n",
      "iter:476 \t Loss:5.441 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:477 \t Loss:5.437 \t error(train):69.0% \t error(val):70.2%\n",
      "iter:478 \t Loss:5.433 \t error(train):69.1% \t error(val):70.4%\n",
      "iter:479 \t Loss:5.422 \t error(train):69.1% \t error(val):70.2%\n",
      "iter:480 \t Loss:5.420 \t error(train):69.1% \t error(val):70.2%\n",
      "iter:481 \t Loss:5.417 \t error(train):69.1% \t error(val):70.3%\n",
      "iter:482 \t Loss:5.411 \t error(train):69.1% \t error(val):70.3%\n",
      "iter:483 \t Loss:5.406 \t error(train):69.1% \t error(val):70.3%\n",
      "iter:484 \t Loss:5.404 \t error(train):69.1% \t error(val):70.3%\n",
      "iter:485 \t Loss:5.401 \t error(train):69.2% \t error(val):70.3%\n",
      "iter:486 \t Loss:5.397 \t error(train):69.1% \t error(val):70.3%\n",
      "iter:487 \t Loss:5.394 \t error(train):69.2% \t error(val):70.4%\n",
      "iter:488 \t Loss:5.391 \t error(train):69.3% \t error(val):70.4%\n",
      "iter:489 \t Loss:5.383 \t error(train):69.1% \t error(val):70.4%\n",
      "iter:490 \t Loss:5.379 \t error(train):69.2% \t error(val):70.5%\n",
      "iter:491 \t Loss:5.377 \t error(train):69.2% \t error(val):70.4%\n",
      "iter:492 \t Loss:5.374 \t error(train):69.2% \t error(val):70.4%\n",
      "iter:493 \t Loss:5.370 \t error(train):69.2% \t error(val):70.5%\n",
      "iter:494 \t Loss:5.366 \t error(train):69.2% \t error(val):70.4%\n",
      "iter:495 \t Loss:5.363 \t error(train):69.3% \t error(val):70.5%\n",
      "iter:496 \t Loss:5.354 \t error(train):69.3% \t error(val):70.5%\n",
      "iter:497 \t Loss:5.351 \t error(train):69.2% \t error(val):70.5%\n",
      "iter:498 \t Loss:5.348 \t error(train):69.3% \t error(val):70.5%\n",
      "iter:499 \t Loss:5.345 \t error(train):69.2% \t error(val):70.5%\n",
      "iter:500 \t Loss:5.342 \t error(train):69.3% \t error(val):70.6%\n",
      "iter:501 \t Loss:5.338 \t error(train):69.3% \t error(val):70.5%\n",
      "iter:502 \t Loss:5.335 \t error(train):69.3% \t error(val):70.5%\n",
      "iter:503 \t Loss:5.332 \t error(train):69.3% \t error(val):70.6%\n",
      "iter:504 \t Loss:5.330 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:505 \t Loss:5.325 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:506 \t Loss:5.322 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:507 \t Loss:5.318 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:508 \t Loss:5.309 \t error(train):69.3% \t error(val):70.6%\n",
      "iter:509 \t Loss:5.307 \t error(train):69.4% \t error(val):70.7%\n",
      "iter:510 \t Loss:5.304 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:511 \t Loss:5.300 \t error(train):69.4% \t error(val):70.7%\n",
      "iter:512 \t Loss:5.298 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:513 \t Loss:5.293 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:514 \t Loss:5.291 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:515 \t Loss:5.288 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:516 \t Loss:5.286 \t error(train):69.4% \t error(val):70.6%\n",
      "iter:517 \t Loss:5.282 \t error(train):69.5% \t error(val):70.8%\n",
      "iter:518 \t Loss:5.278 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:519 \t Loss:5.274 \t error(train):69.5% \t error(val):70.6%\n",
      "iter:520 \t Loss:5.265 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:521 \t Loss:5.263 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:522 \t Loss:5.260 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:523 \t Loss:5.256 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:524 \t Loss:5.254 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:525 \t Loss:5.249 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:526 \t Loss:5.247 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:527 \t Loss:5.244 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:528 \t Loss:5.242 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:529 \t Loss:5.239 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:530 \t Loss:5.237 \t error(train):69.5% \t error(val):70.7%\n",
      "iter:531 \t Loss:5.234 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:532 \t Loss:5.231 \t error(train):69.6% \t error(val):70.8%\n",
      "iter:533 \t Loss:5.228 \t error(train):69.7% \t error(val):70.8%\n",
      "iter:534 \t Loss:5.218 \t error(train):69.7% \t error(val):70.8%\n",
      "iter:535 \t Loss:5.215 \t error(train):69.7% \t error(val):70.8%\n",
      "iter:536 \t Loss:5.211 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:537 \t Loss:5.204 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:538 \t Loss:5.201 \t error(train):69.6% \t error(val):70.9%\n",
      "iter:539 \t Loss:5.198 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:540 \t Loss:5.196 \t error(train):69.6% \t error(val):70.7%\n",
      "iter:541 \t Loss:5.192 \t error(train):69.7% \t error(val):70.8%\n",
      "iter:542 \t Loss:5.188 \t error(train):69.7% \t error(val):70.8%\n",
      "iter:543 \t Loss:5.185 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:544 \t Loss:5.175 \t error(train):69.8% \t error(val):70.9%\n",
      "iter:545 \t Loss:5.172 \t error(train):69.6% \t error(val):70.9%\n",
      "iter:546 \t Loss:5.170 \t error(train):69.8% \t error(val):70.9%\n",
      "iter:547 \t Loss:5.167 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:548 \t Loss:5.165 \t error(train):69.8% \t error(val):70.9%\n",
      "iter:549 \t Loss:5.163 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:550 \t Loss:5.159 \t error(train):69.9% \t error(val):70.9%\n",
      "iter:551 \t Loss:5.148 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:552 \t Loss:5.146 \t error(train):69.9% \t error(val):70.9%\n",
      "iter:553 \t Loss:5.143 \t error(train):69.7% \t error(val):71.0%\n",
      "iter:554 \t Loss:5.141 \t error(train):69.9% \t error(val):71.0%\n",
      "iter:555 \t Loss:5.139 \t error(train):69.7% \t error(val):70.9%\n",
      "iter:556 \t Loss:5.134 \t error(train):69.9% \t error(val):71.0%\n",
      "iter:557 \t Loss:5.132 \t error(train):69.7% \t error(val):71.0%\n",
      "iter:558 \t Loss:5.129 \t error(train):69.9% \t error(val):71.0%\n",
      "iter:559 \t Loss:5.127 \t error(train):69.9% \t error(val):71.0%\n",
      "iter:560 \t Loss:5.124 \t error(train):69.7% \t error(val):71.0%\n",
      "iter:561 \t Loss:5.115 \t error(train):70.0% \t error(val):71.0%\n",
      "iter:562 \t Loss:5.113 \t error(train):69.8% \t error(val):71.0%\n",
      "iter:563 \t Loss:5.110 \t error(train):70.0% \t error(val):71.1%\n",
      "iter:564 \t Loss:5.108 \t error(train):69.8% \t error(val):71.0%\n",
      "iter:565 \t Loss:5.105 \t error(train):70.0% \t error(val):71.0%\n",
      "iter:566 \t Loss:5.104 \t error(train):70.0% \t error(val):71.0%\n",
      "iter:567 \t Loss:5.100 \t error(train):70.0% \t error(val):71.1%\n",
      "iter:568 \t Loss:5.090 \t error(train):70.1% \t error(val):71.3%\n",
      "iter:569 \t Loss:5.062 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:570 \t Loss:5.059 \t error(train):69.9% \t error(val):71.1%\n",
      "iter:571 \t Loss:5.057 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:572 \t Loss:5.055 \t error(train):69.9% \t error(val):71.1%\n",
      "iter:573 \t Loss:5.051 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:574 \t Loss:5.048 \t error(train):69.9% \t error(val):71.1%\n",
      "iter:575 \t Loss:5.046 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:576 \t Loss:5.044 \t error(train):69.9% \t error(val):71.1%\n",
      "iter:577 \t Loss:5.041 \t error(train):70.1% \t error(val):71.1%\n",
      "iter:578 \t Loss:5.039 \t error(train):70.1% \t error(val):71.1%\n",
      "iter:579 \t Loss:5.036 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:580 \t Loss:5.026 \t error(train):70.0% \t error(val):70.8%\n",
      "iter:581 \t Loss:5.016 \t error(train):70.0% \t error(val):71.1%\n",
      "iter:582 \t Loss:5.011 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:583 \t Loss:5.009 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:584 \t Loss:5.006 \t error(train):70.1% \t error(val):71.2%\n",
      "iter:585 \t Loss:4.997 \t error(train):70.2% \t error(val):71.4%\n",
      "iter:586 \t Loss:4.994 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:587 \t Loss:4.992 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:588 \t Loss:4.988 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:589 \t Loss:4.986 \t error(train):70.2% \t error(val):71.3%\n",
      "iter:590 \t Loss:4.982 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:591 \t Loss:4.980 \t error(train):70.2% \t error(val):71.4%\n",
      "iter:592 \t Loss:4.977 \t error(train):70.2% \t error(val):71.3%\n",
      "iter:593 \t Loss:4.974 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:594 \t Loss:4.971 \t error(train):70.3% \t error(val):71.4%\n",
      "iter:595 \t Loss:4.966 \t error(train):70.2% \t error(val):71.3%\n",
      "iter:596 \t Loss:4.962 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:597 \t Loss:4.960 \t error(train):70.3% \t error(val):71.4%\n",
      "iter:598 \t Loss:4.958 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:599 \t Loss:4.956 \t error(train):70.3% \t error(val):71.4%\n",
      "iter:600 \t Loss:4.954 \t error(train):70.2% \t error(val):71.2%\n",
      "iter:601 \t Loss:4.951 \t error(train):70.3% \t error(val):71.3%\n",
      "iter:602 \t Loss:4.949 \t error(train):70.3% \t error(val):71.3%\n",
      "iter:603 \t Loss:4.946 \t error(train):70.3% \t error(val):71.5%\n",
      "iter:604 \t Loss:4.937 \t error(train):70.3% \t error(val):71.2%\n",
      "iter:605 \t Loss:4.935 \t error(train):70.4% \t error(val):71.4%\n",
      "iter:606 \t Loss:4.933 \t error(train):70.3% \t error(val):71.2%\n",
      "iter:607 \t Loss:4.929 \t error(train):70.4% \t error(val):71.4%\n",
      "iter:608 \t Loss:4.927 \t error(train):70.3% \t error(val):71.2%\n",
      "iter:609 \t Loss:4.923 \t error(train):70.3% \t error(val):71.4%\n",
      "iter:610 \t Loss:4.922 \t error(train):70.4% \t error(val):71.4%\n",
      "iter:611 \t Loss:4.919 \t error(train):70.3% \t error(val):71.1%\n",
      "iter:612 \t Loss:4.913 \t error(train):70.4% \t error(val):71.3%\n",
      "iter:613 \t Loss:4.911 \t error(train):70.4% \t error(val):71.5%\n",
      "iter:614 \t Loss:4.908 \t error(train):70.4% \t error(val):71.4%\n",
      "iter:615 \t Loss:4.907 \t error(train):70.4% \t error(val):71.5%\n",
      "iter:616 \t Loss:4.903 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:617 \t Loss:4.901 \t error(train):70.4% \t error(val):71.4%\n",
      "iter:618 \t Loss:4.898 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:619 \t Loss:4.892 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:620 \t Loss:4.889 \t error(train):70.5% \t error(val):71.4%\n",
      "iter:621 \t Loss:4.887 \t error(train):70.5% \t error(val):71.6%\n",
      "iter:622 \t Loss:4.884 \t error(train):70.5% \t error(val):71.4%\n",
      "iter:623 \t Loss:4.882 \t error(train):70.5% \t error(val):71.6%\n",
      "iter:624 \t Loss:4.879 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:625 \t Loss:4.877 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:626 \t Loss:4.874 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:627 \t Loss:4.871 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:628 \t Loss:4.869 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:629 \t Loss:4.866 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:630 \t Loss:4.864 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:631 \t Loss:4.861 \t error(train):70.6% \t error(val):71.5%\n",
      "iter:632 \t Loss:4.859 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:633 \t Loss:4.857 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:634 \t Loss:4.854 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:635 \t Loss:4.852 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:636 \t Loss:4.848 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:637 \t Loss:4.847 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:638 \t Loss:4.843 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:639 \t Loss:4.841 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:640 \t Loss:4.839 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:641 \t Loss:4.834 \t error(train):70.7% \t error(val):71.5%\n",
      "iter:642 \t Loss:4.831 \t error(train):70.6% \t error(val):71.6%\n",
      "iter:643 \t Loss:4.829 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:644 \t Loss:4.827 \t error(train):70.5% \t error(val):71.5%\n",
      "iter:645 \t Loss:4.824 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:646 \t Loss:4.822 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:647 \t Loss:4.819 \t error(train):70.6% \t error(val):71.4%\n",
      "iter:648 \t Loss:4.814 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:649 \t Loss:4.811 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:650 \t Loss:4.809 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:651 \t Loss:4.807 \t error(train):70.7% \t error(val):71.7%\n",
      "iter:652 \t Loss:4.804 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:653 \t Loss:4.801 \t error(train):70.7% \t error(val):71.6%\n",
      "iter:654 \t Loss:4.798 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:655 \t Loss:4.791 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:656 \t Loss:4.790 \t error(train):70.7% \t error(val):71.7%\n",
      "iter:657 \t Loss:4.787 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:658 \t Loss:4.784 \t error(train):70.7% \t error(val):71.7%\n",
      "iter:659 \t Loss:4.783 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:660 \t Loss:4.779 \t error(train):70.7% \t error(val):71.7%\n",
      "iter:661 \t Loss:4.777 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:662 \t Loss:4.775 \t error(train):70.7% \t error(val):71.7%\n",
      "iter:663 \t Loss:4.774 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:664 \t Loss:4.771 \t error(train):70.8% \t error(val):71.6%\n",
      "iter:665 \t Loss:4.769 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:666 \t Loss:4.767 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:667 \t Loss:4.765 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:668 \t Loss:4.762 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:669 \t Loss:4.755 \t error(train):70.8% \t error(val):71.8%\n",
      "iter:670 \t Loss:4.752 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:671 \t Loss:4.750 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:672 \t Loss:4.744 \t error(train):70.8% \t error(val):71.8%\n",
      "iter:673 \t Loss:4.742 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:674 \t Loss:4.739 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:675 \t Loss:4.738 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:676 \t Loss:4.736 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:677 \t Loss:4.734 \t error(train):70.8% \t error(val):71.7%\n",
      "iter:678 \t Loss:4.732 \t error(train):70.9% \t error(val):71.7%\n",
      "iter:679 \t Loss:4.729 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:680 \t Loss:4.727 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:681 \t Loss:4.725 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:682 \t Loss:4.723 \t error(train):70.9% \t error(val):71.9%\n",
      "iter:683 \t Loss:4.721 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:684 \t Loss:4.718 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:685 \t Loss:4.716 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:686 \t Loss:4.714 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:687 \t Loss:4.712 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:688 \t Loss:4.710 \t error(train):71.0% \t error(val):71.8%\n",
      "iter:689 \t Loss:4.708 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:690 \t Loss:4.707 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:691 \t Loss:4.703 \t error(train):71.0% \t error(val):71.8%\n",
      "iter:692 \t Loss:4.702 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:693 \t Loss:4.700 \t error(train):70.9% \t error(val):71.8%\n",
      "iter:694 \t Loss:4.695 \t error(train):71.0% \t error(val):71.8%\n",
      "iter:695 \t Loss:4.692 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:696 \t Loss:4.690 \t error(train):71.0% \t error(val):71.8%\n",
      "iter:697 \t Loss:4.689 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:698 \t Loss:4.685 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:699 \t Loss:4.684 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:700 \t Loss:4.681 \t error(train):71.1% \t error(val):71.9%\n",
      "iter:701 \t Loss:4.676 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:702 \t Loss:4.673 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:703 \t Loss:4.671 \t error(train):71.1% \t error(val):71.9%\n",
      "iter:704 \t Loss:4.669 \t error(train):71.1% \t error(val):71.9%\n",
      "iter:705 \t Loss:4.667 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:706 \t Loss:4.664 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:707 \t Loss:4.663 \t error(train):71.1% \t error(val):71.9%\n",
      "iter:708 \t Loss:4.660 \t error(train):71.1% \t error(val):71.9%\n",
      "iter:709 \t Loss:4.658 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:710 \t Loss:4.656 \t error(train):71.2% \t error(val):71.9%\n",
      "iter:711 \t Loss:4.652 \t error(train):71.1% \t error(val):71.9%\n",
      "iter:712 \t Loss:4.649 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:713 \t Loss:4.647 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:714 \t Loss:4.646 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:715 \t Loss:4.642 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:716 \t Loss:4.641 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:717 \t Loss:4.639 \t error(train):71.0% \t error(val):71.9%\n",
      "iter:718 \t Loss:4.634 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:719 \t Loss:4.631 \t error(train):71.2% \t error(val):72.0%\n",
      "iter:720 \t Loss:4.629 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:721 \t Loss:4.628 \t error(train):71.3% \t error(val):71.9%\n",
      "iter:722 \t Loss:4.625 \t error(train):71.1% \t error(val):72.0%\n",
      "iter:723 \t Loss:4.623 \t error(train):71.1% \t error(val):72.1%\n",
      "iter:724 \t Loss:4.620 \t error(train):71.3% \t error(val):72.0%\n",
      "iter:725 \t Loss:4.615 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:726 \t Loss:4.613 \t error(train):71.1% \t error(val):72.1%\n",
      "iter:727 \t Loss:4.611 \t error(train):71.3% \t error(val):72.0%\n",
      "iter:728 \t Loss:4.608 \t error(train):71.1% \t error(val):72.1%\n",
      "iter:729 \t Loss:4.606 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:730 \t Loss:4.604 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:731 \t Loss:4.602 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:732 \t Loss:4.600 \t error(train):71.2% \t error(val):72.0%\n",
      "iter:733 \t Loss:4.598 \t error(train):71.3% \t error(val):72.0%\n",
      "iter:734 \t Loss:4.595 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:735 \t Loss:4.593 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:736 \t Loss:4.591 \t error(train):71.4% \t error(val):72.1%\n",
      "iter:737 \t Loss:4.585 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:738 \t Loss:4.583 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:739 \t Loss:4.581 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:740 \t Loss:4.579 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:741 \t Loss:4.577 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:742 \t Loss:4.574 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:743 \t Loss:4.572 \t error(train):71.4% \t error(val):72.1%\n",
      "iter:744 \t Loss:4.570 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:745 \t Loss:4.568 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:746 \t Loss:4.566 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:747 \t Loss:4.563 \t error(train):71.2% \t error(val):72.1%\n",
      "iter:748 \t Loss:4.561 \t error(train):71.5% \t error(val):72.1%\n",
      "iter:749 \t Loss:4.559 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:750 \t Loss:4.557 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:751 \t Loss:4.555 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:752 \t Loss:4.552 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:753 \t Loss:4.551 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:754 \t Loss:4.548 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:755 \t Loss:4.546 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:756 \t Loss:4.544 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:757 \t Loss:4.543 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:758 \t Loss:4.541 \t error(train):71.3% \t error(val):72.1%\n",
      "iter:759 \t Loss:4.539 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:760 \t Loss:4.537 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:761 \t Loss:4.536 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:762 \t Loss:4.533 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:763 \t Loss:4.526 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:764 \t Loss:4.524 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:765 \t Loss:4.522 \t error(train):71.5% \t error(val):72.3%\n",
      "iter:766 \t Loss:4.517 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:767 \t Loss:4.515 \t error(train):71.5% \t error(val):72.3%\n",
      "iter:768 \t Loss:4.513 \t error(train):71.4% \t error(val):72.2%\n",
      "iter:769 \t Loss:4.511 \t error(train):71.5% \t error(val):72.3%\n",
      "iter:770 \t Loss:4.509 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:771 \t Loss:4.506 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:772 \t Loss:4.504 \t error(train):71.5% \t error(val):72.4%\n",
      "iter:773 \t Loss:4.497 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:774 \t Loss:4.496 \t error(train):71.5% \t error(val):72.4%\n",
      "iter:775 \t Loss:4.494 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:776 \t Loss:4.492 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:777 \t Loss:4.490 \t error(train):71.5% \t error(val):72.2%\n",
      "iter:778 \t Loss:4.489 \t error(train):71.5% \t error(val):72.3%\n",
      "iter:779 \t Loss:4.486 \t error(train):71.5% \t error(val):72.3%\n",
      "iter:780 \t Loss:4.479 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:781 \t Loss:4.478 \t error(train):71.5% \t error(val):72.3%\n",
      "iter:782 \t Loss:4.476 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:783 \t Loss:4.474 \t error(train):71.6% \t error(val):72.2%\n",
      "iter:784 \t Loss:4.473 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:785 \t Loss:4.470 \t error(train):71.6% \t error(val):72.3%\n",
      "iter:786 \t Loss:4.468 \t error(train):71.6% \t error(val):72.3%\n",
      "iter:787 \t Loss:4.466 \t error(train):71.7% \t error(val):72.5%\n",
      "iter:788 \t Loss:4.463 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:789 \t Loss:4.460 \t error(train):71.6% \t error(val):72.3%\n",
      "iter:790 \t Loss:4.458 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:791 \t Loss:4.457 \t error(train):71.6% \t error(val):72.3%\n",
      "iter:792 \t Loss:4.454 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:793 \t Loss:4.452 \t error(train):71.6% \t error(val):72.4%\n",
      "iter:794 \t Loss:4.450 \t error(train):71.7% \t error(val):72.4%\n",
      "iter:795 \t Loss:4.446 \t error(train):71.7% \t error(val):72.4%\n",
      "iter:796 \t Loss:4.443 \t error(train):71.7% \t error(val):72.4%\n",
      "iter:797 \t Loss:4.442 \t error(train):71.7% \t error(val):72.4%\n",
      "iter:798 \t Loss:4.440 \t error(train):71.8% \t error(val):72.4%\n",
      "iter:799 \t Loss:4.438 \t error(train):71.7% \t error(val):72.5%\n",
      "iter:800 \t Loss:4.435 \t error(train):71.7% \t error(val):72.4%\n",
      "iter:801 \t Loss:4.433 \t error(train):71.8% \t error(val):72.5%\n",
      "iter:802 \t Loss:4.427 \t error(train):71.7% \t error(val):72.5%\n",
      "iter:803 \t Loss:4.426 \t error(train):71.7% \t error(val):72.5%\n",
      "iter:804 \t Loss:4.424 \t error(train):71.8% \t error(val):72.7%\n",
      "iter:805 \t Loss:4.421 \t error(train):71.7% \t error(val):72.6%\n",
      "iter:806 \t Loss:4.418 \t error(train):71.8% \t error(val):72.4%\n",
      "iter:807 \t Loss:4.417 \t error(train):71.7% \t error(val):72.6%\n",
      "iter:808 \t Loss:4.415 \t error(train):71.8% \t error(val):72.5%\n",
      "iter:809 \t Loss:4.412 \t error(train):71.8% \t error(val):72.5%\n",
      "iter:810 \t Loss:4.411 \t error(train):71.7% \t error(val):72.6%\n",
      "iter:811 \t Loss:4.409 \t error(train):71.9% \t error(val):72.6%\n",
      "iter:812 \t Loss:4.405 \t error(train):71.8% \t error(val):72.5%\n",
      "iter:813 \t Loss:4.403 \t error(train):71.8% \t error(val):72.6%\n",
      "iter:814 \t Loss:4.401 \t error(train):71.8% \t error(val):72.5%\n",
      "iter:815 \t Loss:4.400 \t error(train):71.9% \t error(val):72.8%\n",
      "iter:816 \t Loss:4.397 \t error(train):71.8% \t error(val):72.6%\n",
      "iter:817 \t Loss:4.395 \t error(train):71.8% \t error(val):72.5%\n",
      "iter:818 \t Loss:4.393 \t error(train):71.9% \t error(val):72.8%\n",
      "iter:819 \t Loss:4.388 \t error(train):71.8% \t error(val):72.6%\n",
      "iter:820 \t Loss:4.386 \t error(train):71.8% \t error(val):72.6%\n",
      "iter:821 \t Loss:4.384 \t error(train):71.9% \t error(val):72.8%\n",
      "iter:822 \t Loss:4.382 \t error(train):71.9% \t error(val):72.6%\n",
      "iter:823 \t Loss:4.381 \t error(train):71.9% \t error(val):72.8%\n",
      "iter:824 \t Loss:4.378 \t error(train):71.9% \t error(val):72.6%\n",
      "iter:825 \t Loss:4.377 \t error(train):71.9% \t error(val):72.6%\n",
      "iter:826 \t Loss:4.375 \t error(train):71.9% \t error(val):72.6%\n",
      "iter:827 \t Loss:4.374 \t error(train):72.0% \t error(val):72.9%\n",
      "iter:828 \t Loss:4.371 \t error(train):71.9% \t error(val):72.7%\n",
      "iter:829 \t Loss:4.369 \t error(train):71.9% \t error(val):72.7%\n",
      "iter:830 \t Loss:4.367 \t error(train):72.0% \t error(val):72.9%\n",
      "iter:831 \t Loss:4.362 \t error(train):71.9% \t error(val):72.7%\n",
      "iter:832 \t Loss:4.360 \t error(train):71.9% \t error(val):72.7%\n",
      "iter:833 \t Loss:4.359 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:834 \t Loss:4.356 \t error(train):72.0% \t error(val):72.7%\n",
      "iter:835 \t Loss:4.355 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:836 \t Loss:4.352 \t error(train):72.0% \t error(val):72.7%\n",
      "iter:837 \t Loss:4.351 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:838 \t Loss:4.349 \t error(train):72.0% \t error(val):72.7%\n",
      "iter:839 \t Loss:4.348 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:840 \t Loss:4.346 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:841 \t Loss:4.345 \t error(train):72.0% \t error(val):72.9%\n",
      "iter:842 \t Loss:4.343 \t error(train):72.0% \t error(val):72.7%\n",
      "iter:843 \t Loss:4.342 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:844 \t Loss:4.339 \t error(train):72.1% \t error(val):72.7%\n",
      "iter:845 \t Loss:4.333 \t error(train):72.0% \t error(val):72.8%\n",
      "iter:846 \t Loss:4.332 \t error(train):72.1% \t error(val):72.9%\n",
      "iter:847 \t Loss:4.330 \t error(train):72.1% \t error(val):72.7%\n",
      "iter:848 \t Loss:4.325 \t error(train):72.1% \t error(val):72.8%\n",
      "iter:849 \t Loss:4.323 \t error(train):72.1% \t error(val):72.9%\n",
      "iter:850 \t Loss:4.322 \t error(train):72.1% \t error(val):72.9%\n",
      "iter:851 \t Loss:4.320 \t error(train):72.1% \t error(val):73.1%\n",
      "iter:852 \t Loss:4.318 \t error(train):72.2% \t error(val):72.9%\n",
      "iter:853 \t Loss:4.316 \t error(train):72.1% \t error(val):72.9%\n",
      "iter:854 \t Loss:4.314 \t error(train):72.1% \t error(val):73.0%\n",
      "iter:855 \t Loss:4.308 \t error(train):72.2% \t error(val):72.9%\n",
      "iter:856 \t Loss:4.306 \t error(train):72.1% \t error(val):73.0%\n",
      "iter:857 \t Loss:4.305 \t error(train):72.2% \t error(val):72.9%\n",
      "iter:858 \t Loss:4.303 \t error(train):72.1% \t error(val):73.1%\n",
      "iter:859 \t Loss:4.302 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:860 \t Loss:4.300 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:861 \t Loss:4.298 \t error(train):72.2% \t error(val):72.9%\n",
      "iter:862 \t Loss:4.292 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:863 \t Loss:4.290 \t error(train):72.2% \t error(val):72.9%\n",
      "iter:864 \t Loss:4.289 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:865 \t Loss:4.287 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:866 \t Loss:4.286 \t error(train):72.2% \t error(val):73.1%\n",
      "iter:867 \t Loss:4.284 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:868 \t Loss:4.282 \t error(train):72.2% \t error(val):73.0%\n",
      "iter:869 \t Loss:4.281 \t error(train):72.3% \t error(val):73.3%\n",
      "iter:870 \t Loss:4.277 \t error(train):72.3% \t error(val):73.0%\n",
      "iter:871 \t Loss:4.275 \t error(train):72.3% \t error(val):73.0%\n",
      "iter:872 \t Loss:4.274 \t error(train):72.2% \t error(val):73.1%\n",
      "iter:873 \t Loss:4.272 \t error(train):72.3% \t error(val):72.9%\n",
      "iter:874 \t Loss:4.270 \t error(train):72.3% \t error(val):73.1%\n",
      "iter:875 \t Loss:4.268 \t error(train):72.3% \t error(val):73.1%\n",
      "iter:876 \t Loss:4.267 \t error(train):72.3% \t error(val):72.9%\n",
      "iter:877 \t Loss:4.262 \t error(train):72.3% \t error(val):73.0%\n",
      "iter:878 \t Loss:4.261 \t error(train):72.3% \t error(val):73.1%\n",
      "iter:879 \t Loss:4.259 \t error(train):72.3% \t error(val):72.9%\n",
      "iter:880 \t Loss:4.257 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:881 \t Loss:4.256 \t error(train):72.4% \t error(val):72.9%\n",
      "iter:882 \t Loss:4.253 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:883 \t Loss:4.252 \t error(train):72.4% \t error(val):72.9%\n",
      "iter:884 \t Loss:4.250 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:885 \t Loss:4.249 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:886 \t Loss:4.247 \t error(train):72.4% \t error(val):72.9%\n",
      "iter:887 \t Loss:4.245 \t error(train):72.4% \t error(val):73.2%\n",
      "iter:888 \t Loss:4.244 \t error(train):72.4% \t error(val):73.0%\n",
      "iter:889 \t Loss:4.241 \t error(train):72.4% \t error(val):73.2%\n",
      "iter:890 \t Loss:4.240 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:891 \t Loss:4.238 \t error(train):72.4% \t error(val):73.2%\n",
      "iter:892 \t Loss:4.237 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:893 \t Loss:4.235 \t error(train):72.4% \t error(val):73.3%\n",
      "iter:894 \t Loss:4.234 \t error(train):72.4% \t error(val):72.9%\n",
      "iter:895 \t Loss:4.233 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:896 \t Loss:4.231 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:897 \t Loss:4.229 \t error(train):72.5% \t error(val):73.4%\n",
      "iter:898 \t Loss:4.224 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:899 \t Loss:4.222 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:900 \t Loss:4.220 \t error(train):72.5% \t error(val):73.4%\n",
      "iter:901 \t Loss:4.216 \t error(train):72.4% \t error(val):73.2%\n",
      "iter:902 \t Loss:4.214 \t error(train):72.4% \t error(val):73.1%\n",
      "iter:903 \t Loss:4.212 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:904 \t Loss:4.211 \t error(train):72.4% \t error(val):73.0%\n",
      "iter:905 \t Loss:4.209 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:906 \t Loss:4.207 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:907 \t Loss:4.205 \t error(train):72.5% \t error(val):73.1%\n",
      "iter:908 \t Loss:4.199 \t error(train):72.5% \t error(val):73.3%\n",
      "iter:909 \t Loss:4.198 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:910 \t Loss:4.197 \t error(train):72.5% \t error(val):73.3%\n",
      "iter:911 \t Loss:4.195 \t error(train):72.5% \t error(val):73.1%\n",
      "iter:912 \t Loss:4.194 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:913 \t Loss:4.192 \t error(train):72.5% \t error(val):73.2%\n",
      "iter:914 \t Loss:4.190 \t error(train):72.5% \t error(val):73.3%\n",
      "iter:915 \t Loss:4.184 \t error(train):72.5% \t error(val):73.3%\n",
      "iter:916 \t Loss:4.183 \t error(train):72.6% \t error(val):73.4%\n",
      "iter:917 \t Loss:4.182 \t error(train):72.6% \t error(val):73.3%\n",
      "iter:918 \t Loss:4.181 \t error(train):72.6% \t error(val):73.3%\n",
      "iter:919 \t Loss:4.179 \t error(train):72.6% \t error(val):73.3%\n",
      "iter:920 \t Loss:4.173 \t error(train):72.6% \t error(val):73.1%\n",
      "iter:921 \t Loss:4.166 \t error(train):72.5% \t error(val):73.3%\n",
      "iter:922 \t Loss:4.164 \t error(train):72.6% \t error(val):73.4%\n",
      "iter:923 \t Loss:4.163 \t error(train):72.6% \t error(val):73.3%\n",
      "iter:924 \t Loss:4.161 \t error(train):72.6% \t error(val):73.5%\n",
      "iter:925 \t Loss:4.159 \t error(train):72.6% \t error(val):73.3%\n",
      "iter:926 \t Loss:4.158 \t error(train):72.7% \t error(val):73.5%\n",
      "iter:927 \t Loss:4.156 \t error(train):72.6% \t error(val):73.3%\n",
      "iter:928 \t Loss:4.155 \t error(train):72.6% \t error(val):73.5%\n",
      "iter:929 \t Loss:4.154 \t error(train):72.7% \t error(val):73.3%\n",
      "iter:930 \t Loss:4.153 \t error(train):72.7% \t error(val):73.3%\n",
      "iter:931 \t Loss:4.151 \t error(train):72.7% \t error(val):73.4%\n",
      "iter:932 \t Loss:4.145 \t error(train):72.8% \t error(val):73.5%\n",
      "iter:933 \t Loss:4.128 \t error(train):72.7% \t error(val):73.4%\n",
      "iter:934 \t Loss:4.126 \t error(train):72.7% \t error(val):73.6%\n",
      "iter:935 \t Loss:4.124 \t error(train):72.7% \t error(val):73.4%\n",
      "iter:936 \t Loss:4.123 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:937 \t Loss:4.122 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:938 \t Loss:4.119 \t error(train):72.8% \t error(val):73.6%\n",
      "iter:939 \t Loss:4.114 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:940 \t Loss:4.113 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:941 \t Loss:4.111 \t error(train):72.8% \t error(val):73.6%\n",
      "iter:942 \t Loss:4.107 \t error(train):72.8% \t error(val):73.5%\n",
      "iter:943 \t Loss:4.105 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:944 \t Loss:4.104 \t error(train):72.8% \t error(val):73.6%\n",
      "iter:945 \t Loss:4.102 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:946 \t Loss:4.101 \t error(train):72.8% \t error(val):73.6%\n",
      "iter:947 \t Loss:4.099 \t error(train):72.8% \t error(val):73.4%\n",
      "iter:948 \t Loss:4.098 \t error(train):72.9% \t error(val):73.6%\n",
      "iter:949 \t Loss:4.096 \t error(train):72.8% \t error(val):73.5%\n",
      "iter:950 \t Loss:4.094 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:951 \t Loss:4.093 \t error(train):72.9% \t error(val):73.6%\n",
      "iter:952 \t Loss:4.091 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:953 \t Loss:4.090 \t error(train):72.9% \t error(val):73.6%\n",
      "iter:954 \t Loss:4.088 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:955 \t Loss:4.087 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:956 \t Loss:4.085 \t error(train):72.9% \t error(val):73.6%\n",
      "iter:957 \t Loss:4.083 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:958 \t Loss:4.082 \t error(train):72.9% \t error(val):73.7%\n",
      "iter:959 \t Loss:4.080 \t error(train):72.9% \t error(val):73.4%\n",
      "iter:960 \t Loss:4.079 \t error(train):73.0% \t error(val):73.7%\n",
      "iter:961 \t Loss:4.077 \t error(train):72.9% \t error(val):73.6%\n",
      "iter:962 \t Loss:4.076 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:963 \t Loss:4.074 \t error(train):73.0% \t error(val):73.7%\n",
      "iter:964 \t Loss:4.072 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:965 \t Loss:4.071 \t error(train):73.0% \t error(val):73.7%\n",
      "iter:966 \t Loss:4.069 \t error(train):72.9% \t error(val):73.7%\n",
      "iter:967 \t Loss:4.068 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:968 \t Loss:4.067 \t error(train):73.1% \t error(val):73.8%\n",
      "iter:969 \t Loss:4.064 \t error(train):73.0% \t error(val):73.7%\n",
      "iter:970 \t Loss:4.062 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:971 \t Loss:4.061 \t error(train):73.0% \t error(val):73.7%\n",
      "iter:972 \t Loss:4.060 \t error(train):72.9% \t error(val):73.4%\n",
      "iter:973 \t Loss:4.057 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:974 \t Loss:4.056 \t error(train):73.0% \t error(val):73.6%\n",
      "iter:975 \t Loss:4.055 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:976 \t Loss:4.052 \t error(train):72.9% \t error(val):73.5%\n",
      "iter:977 \t Loss:4.050 \t error(train):73.0% \t error(val):73.8%\n",
      "iter:978 \t Loss:4.049 \t error(train):73.0% \t error(val):73.5%\n",
      "iter:979 \t Loss:4.048 \t error(train):73.0% \t error(val):73.8%\n",
      "iter:980 \t Loss:4.045 \t error(train):73.1% \t error(val):73.6%\n",
      "iter:981 \t Loss:4.044 \t error(train):73.0% \t error(val):73.6%\n",
      "iter:982 \t Loss:4.042 \t error(train):73.1% \t error(val):73.9%\n",
      "iter:983 \t Loss:4.039 \t error(train):73.1% \t error(val):73.7%\n",
      "iter:984 \t Loss:4.037 \t error(train):73.0% \t error(val):73.6%\n",
      "iter:985 \t Loss:4.036 \t error(train):73.1% \t error(val):73.8%\n",
      "iter:986 \t Loss:4.034 \t error(train):73.0% \t error(val):73.6%\n",
      "iter:987 \t Loss:4.033 \t error(train):73.1% \t error(val):73.8%\n",
      "iter:988 \t Loss:4.031 \t error(train):73.0% \t error(val):73.6%\n",
      "iter:989 \t Loss:4.030 \t error(train):73.1% \t error(val):73.9%\n",
      "iter:990 \t Loss:4.028 \t error(train):73.1% \t error(val):73.8%\n",
      "iter:991 \t Loss:4.027 \t error(train):73.1% \t error(val):73.6%\n",
      "iter:992 \t Loss:4.025 \t error(train):73.1% \t error(val):73.8%\n",
      "iter:993 \t Loss:4.023 \t error(train):73.1% \t error(val):73.6%\n",
      "iter:994 \t Loss:4.022 \t error(train):73.2% \t error(val):73.9%\n",
      "iter:995 \t Loss:4.020 \t error(train):73.1% \t error(val):73.8%\n",
      "iter:996 \t Loss:4.019 \t error(train):73.1% \t error(val):73.6%\n",
      "iter:997 \t Loss:4.018 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:998 \t Loss:4.016 \t error(train):73.1% \t error(val):73.7%\n",
      "iter:999 \t Loss:4.015 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1000 \t Loss:4.013 \t error(train):73.1% \t error(val):73.7%\n",
      "iter:1001 \t Loss:4.012 \t error(train):73.2% \t error(val):73.9%\n",
      "iter:1002 \t Loss:4.010 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1003 \t Loss:4.009 \t error(train):73.1% \t error(val):73.7%\n",
      "iter:1004 \t Loss:4.007 \t error(train):73.2% \t error(val):74.1%\n",
      "iter:1005 \t Loss:4.005 \t error(train):73.2% \t error(val):73.9%\n",
      "iter:1006 \t Loss:4.003 \t error(train):73.1% \t error(val):73.7%\n",
      "iter:1007 \t Loss:4.002 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1008 \t Loss:4.001 \t error(train):73.2% \t error(val):73.7%\n",
      "iter:1009 \t Loss:3.998 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1010 \t Loss:3.997 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1011 \t Loss:3.996 \t error(train):73.2% \t error(val):73.7%\n",
      "iter:1012 \t Loss:3.992 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1013 \t Loss:3.991 \t error(train):73.2% \t error(val):74.0%\n",
      "iter:1014 \t Loss:3.989 \t error(train):73.2% \t error(val):73.8%\n",
      "iter:1015 \t Loss:3.988 \t error(train):73.3% \t error(val):74.1%\n",
      "iter:1016 \t Loss:3.986 \t error(train):73.2% \t error(val):73.9%\n",
      "iter:1017 \t Loss:3.985 \t error(train):73.2% \t error(val):73.9%\n",
      "iter:1018 \t Loss:3.983 \t error(train):73.3% \t error(val):74.1%\n",
      "iter:1019 \t Loss:3.979 \t error(train):73.2% \t error(val):74.0%\n",
      "iter:1020 \t Loss:3.978 \t error(train):73.2% \t error(val):73.9%\n",
      "iter:1021 \t Loss:3.977 \t error(train):73.3% \t error(val):74.0%\n",
      "iter:1022 \t Loss:3.975 \t error(train):73.3% \t error(val):73.9%\n",
      "iter:1023 \t Loss:3.974 \t error(train):73.2% \t error(val):74.0%\n",
      "iter:1024 \t Loss:3.972 \t error(train):73.3% \t error(val):73.8%\n",
      "iter:1025 \t Loss:3.971 \t error(train):73.3% \t error(val):74.0%\n",
      "iter:1026 \t Loss:3.969 \t error(train):73.3% \t error(val):73.8%\n",
      "iter:1027 \t Loss:3.968 \t error(train):73.3% \t error(val):74.0%\n",
      "iter:1028 \t Loss:3.967 \t error(train):73.3% \t error(val):73.8%\n",
      "iter:1029 \t Loss:3.966 \t error(train):73.2% \t error(val):74.1%\n",
      "iter:1030 \t Loss:3.965 \t error(train):73.3% \t error(val):73.9%\n",
      "iter:1031 \t Loss:3.963 \t error(train):73.3% \t error(val):74.1%\n",
      "iter:1032 \t Loss:3.962 \t error(train):73.3% \t error(val):73.7%\n",
      "iter:1033 \t Loss:3.957 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1034 \t Loss:3.956 \t error(train):73.3% \t error(val):74.1%\n",
      "iter:1035 \t Loss:3.954 \t error(train):73.3% \t error(val):73.9%\n",
      "iter:1036 \t Loss:3.951 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1037 \t Loss:3.949 \t error(train):73.3% \t error(val):74.2%\n",
      "iter:1038 \t Loss:3.948 \t error(train):73.3% \t error(val):73.8%\n",
      "iter:1039 \t Loss:3.946 \t error(train):73.3% \t error(val):74.1%\n",
      "iter:1040 \t Loss:3.945 \t error(train):73.4% \t error(val):73.8%\n",
      "iter:1041 \t Loss:3.943 \t error(train):73.3% \t error(val):74.2%\n",
      "iter:1042 \t Loss:3.942 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1043 \t Loss:3.941 \t error(train):73.3% \t error(val):74.3%\n",
      "iter:1044 \t Loss:3.939 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1045 \t Loss:3.938 \t error(train):73.3% \t error(val):74.3%\n",
      "iter:1046 \t Loss:3.936 \t error(train):73.4% \t error(val):74.0%\n",
      "iter:1047 \t Loss:3.935 \t error(train):73.3% \t error(val):74.3%\n",
      "iter:1048 \t Loss:3.933 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1049 \t Loss:3.932 \t error(train):73.3% \t error(val):74.2%\n",
      "iter:1050 \t Loss:3.931 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1051 \t Loss:3.930 \t error(train):73.4% \t error(val):74.2%\n",
      "iter:1052 \t Loss:3.929 \t error(train):73.4% \t error(val):74.0%\n",
      "iter:1053 \t Loss:3.927 \t error(train):73.4% \t error(val):74.2%\n",
      "iter:1054 \t Loss:3.927 \t error(train):73.4% \t error(val):73.9%\n",
      "iter:1055 \t Loss:3.924 \t error(train):73.4% \t error(val):74.0%\n",
      "iter:1056 \t Loss:3.924 \t error(train):73.4% \t error(val):74.2%\n",
      "iter:1057 \t Loss:3.922 \t error(train):73.4% \t error(val):74.0%\n",
      "iter:1058 \t Loss:3.919 \t error(train):73.4% \t error(val):74.0%\n",
      "iter:1059 \t Loss:3.918 \t error(train):73.4% \t error(val):74.2%\n",
      "iter:1060 \t Loss:3.917 \t error(train):73.4% \t error(val):74.0%\n",
      "iter:1061 \t Loss:3.916 \t error(train):73.5% \t error(val):74.4%\n",
      "iter:1062 \t Loss:3.914 \t error(train):73.4% \t error(val):74.2%\n",
      "iter:1063 \t Loss:3.913 \t error(train):73.5% \t error(val):74.1%\n",
      "iter:1064 \t Loss:3.911 \t error(train):73.5% \t error(val):74.3%\n",
      "iter:1065 \t Loss:3.908 \t error(train):73.5% \t error(val):74.2%\n",
      "iter:1066 \t Loss:3.906 \t error(train):73.5% \t error(val):74.0%\n",
      "iter:1067 \t Loss:3.905 \t error(train):73.5% \t error(val):74.4%\n",
      "iter:1068 \t Loss:3.904 \t error(train):73.5% \t error(val):74.1%\n",
      "iter:1069 \t Loss:3.902 \t error(train):73.5% \t error(val):74.3%\n",
      "iter:1070 \t Loss:3.901 \t error(train):73.5% \t error(val):74.1%\n",
      "iter:1071 \t Loss:3.900 \t error(train):73.5% \t error(val):74.4%\n",
      "iter:1072 \t Loss:3.898 \t error(train):73.5% \t error(val):74.2%\n",
      "iter:1073 \t Loss:3.897 \t error(train):73.5% \t error(val):74.1%\n",
      "iter:1074 \t Loss:3.896 \t error(train):73.5% \t error(val):74.3%\n",
      "iter:1075 \t Loss:3.894 \t error(train):73.5% \t error(val):74.2%\n",
      "iter:1076 \t Loss:3.893 \t error(train):73.5% \t error(val):74.4%\n",
      "iter:1077 \t Loss:3.891 \t error(train):73.5% \t error(val):74.1%\n",
      "iter:1078 \t Loss:3.890 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1079 \t Loss:3.889 \t error(train):73.5% \t error(val):74.2%\n",
      "iter:1080 \t Loss:3.888 \t error(train):73.6% \t error(val):74.4%\n",
      "iter:1081 \t Loss:3.886 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1082 \t Loss:3.884 \t error(train):73.6% \t error(val):74.2%\n",
      "iter:1083 \t Loss:3.883 \t error(train):73.6% \t error(val):74.4%\n",
      "iter:1084 \t Loss:3.879 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1085 \t Loss:3.878 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1086 \t Loss:3.876 \t error(train):73.6% \t error(val):74.4%\n",
      "iter:1087 \t Loss:3.874 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1088 \t Loss:3.872 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1089 \t Loss:3.871 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1090 \t Loss:3.870 \t error(train):73.6% \t error(val):74.2%\n",
      "iter:1091 \t Loss:3.868 \t error(train):73.6% \t error(val):74.3%\n",
      "iter:1092 \t Loss:3.867 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1093 \t Loss:3.866 \t error(train):73.7% \t error(val):74.2%\n",
      "iter:1094 \t Loss:3.863 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1095 \t Loss:3.861 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1096 \t Loss:3.860 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1097 \t Loss:3.859 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1098 \t Loss:3.857 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1099 \t Loss:3.856 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1100 \t Loss:3.855 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1101 \t Loss:3.851 \t error(train):73.7% \t error(val):74.4%\n",
      "iter:1102 \t Loss:3.850 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1103 \t Loss:3.849 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1104 \t Loss:3.847 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1105 \t Loss:3.846 \t error(train):73.8% \t error(val):74.4%\n",
      "iter:1106 \t Loss:3.844 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1107 \t Loss:3.843 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1108 \t Loss:3.842 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1109 \t Loss:3.841 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1110 \t Loss:3.839 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1111 \t Loss:3.838 \t error(train):73.7% \t error(val):74.5%\n",
      "iter:1112 \t Loss:3.837 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1113 \t Loss:3.833 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1114 \t Loss:3.832 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1115 \t Loss:3.831 \t error(train):73.8% \t error(val):74.4%\n",
      "iter:1116 \t Loss:3.829 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1117 \t Loss:3.828 \t error(train):73.8% \t error(val):74.4%\n",
      "iter:1118 \t Loss:3.826 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1119 \t Loss:3.825 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1120 \t Loss:3.824 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1121 \t Loss:3.823 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1122 \t Loss:3.822 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1123 \t Loss:3.821 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1124 \t Loss:3.820 \t error(train):73.8% \t error(val):74.6%\n",
      "iter:1125 \t Loss:3.819 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1126 \t Loss:3.817 \t error(train):73.8% \t error(val):74.4%\n",
      "iter:1127 \t Loss:3.813 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1128 \t Loss:3.812 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1129 \t Loss:3.810 \t error(train):73.8% \t error(val):74.4%\n",
      "iter:1130 \t Loss:3.807 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1131 \t Loss:3.806 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1132 \t Loss:3.805 \t error(train):73.8% \t error(val):74.5%\n",
      "iter:1133 \t Loss:3.803 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1134 \t Loss:3.802 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1135 \t Loss:3.800 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1136 \t Loss:3.799 \t error(train):73.8% \t error(val):74.4%\n",
      "iter:1137 \t Loss:3.798 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1138 \t Loss:3.797 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1139 \t Loss:3.796 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1140 \t Loss:3.794 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1141 \t Loss:3.793 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1142 \t Loss:3.791 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1143 \t Loss:3.791 \t error(train):73.9% \t error(val):74.6%\n",
      "iter:1144 \t Loss:3.789 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1145 \t Loss:3.788 \t error(train):73.9% \t error(val):74.7%\n",
      "iter:1146 \t Loss:3.787 \t error(train):74.0% \t error(val):74.5%\n",
      "iter:1147 \t Loss:3.785 \t error(train):73.9% \t error(val):74.7%\n",
      "iter:1148 \t Loss:3.784 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1149 \t Loss:3.782 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1150 \t Loss:3.782 \t error(train):74.0% \t error(val):74.7%\n",
      "iter:1151 \t Loss:3.780 \t error(train):73.9% \t error(val):74.5%\n",
      "iter:1152 \t Loss:3.778 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1153 \t Loss:3.776 \t error(train):74.0% \t error(val):74.7%\n",
      "iter:1154 \t Loss:3.775 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1155 \t Loss:3.774 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1156 \t Loss:3.773 \t error(train):74.0% \t error(val):74.7%\n",
      "iter:1157 \t Loss:3.772 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1158 \t Loss:3.770 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1159 \t Loss:3.768 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1160 \t Loss:3.766 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1161 \t Loss:3.765 \t error(train):74.0% \t error(val):74.8%\n",
      "iter:1162 \t Loss:3.764 \t error(train):74.0% \t error(val):74.5%\n",
      "iter:1163 \t Loss:3.763 \t error(train):74.0% \t error(val):74.7%\n",
      "iter:1164 \t Loss:3.761 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1165 \t Loss:3.760 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1166 \t Loss:3.756 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1167 \t Loss:3.755 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1168 \t Loss:3.754 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1169 \t Loss:3.753 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1170 \t Loss:3.752 \t error(train):74.0% \t error(val):74.6%\n",
      "iter:1171 \t Loss:3.750 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1172 \t Loss:3.749 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1173 \t Loss:3.748 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1174 \t Loss:3.747 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1175 \t Loss:3.746 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1176 \t Loss:3.745 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1177 \t Loss:3.744 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1178 \t Loss:3.742 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1179 \t Loss:3.741 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1180 \t Loss:3.740 \t error(train):74.1% \t error(val):74.7%\n",
      "iter:1181 \t Loss:3.739 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1182 \t Loss:3.738 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1183 \t Loss:3.737 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1184 \t Loss:3.736 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1185 \t Loss:3.731 \t error(train):74.2% \t error(val):74.9%\n",
      "iter:1186 \t Loss:3.729 \t error(train):74.2% \t error(val):74.9%\n",
      "iter:1187 \t Loss:3.728 \t error(train):74.1% \t error(val):74.8%\n",
      "iter:1188 \t Loss:3.727 \t error(train):74.2% \t error(val):74.9%\n",
      "iter:1189 \t Loss:3.726 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1190 \t Loss:3.725 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1191 \t Loss:3.723 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1192 \t Loss:3.720 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1193 \t Loss:3.718 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1194 \t Loss:3.717 \t error(train):74.2% \t error(val):74.8%\n",
      "iter:1195 \t Loss:3.714 \t error(train):74.2% \t error(val):74.9%\n",
      "iter:1196 \t Loss:3.712 \t error(train):74.3% \t error(val):75.0%\n",
      "iter:1197 \t Loss:3.711 \t error(train):74.2% \t error(val):74.9%\n",
      "iter:1198 \t Loss:3.711 \t error(train):74.3% \t error(val):74.9%\n",
      "iter:1199 \t Loss:3.709 \t error(train):74.2% \t error(val):74.9%\n",
      "iter:1200 \t Loss:3.708 \t error(train):74.3% \t error(val):74.9%\n",
      "iter:1201 \t Loss:3.706 \t error(train):74.3% \t error(val):75.1%\n",
      "iter:1202 \t Loss:3.702 \t error(train):74.3% \t error(val):74.9%\n",
      "iter:1203 \t Loss:3.701 \t error(train):74.3% \t error(val):75.0%\n",
      "iter:1204 \t Loss:3.700 \t error(train):74.3% \t error(val):75.0%\n",
      "iter:1205 \t Loss:3.698 \t error(train):74.3% \t error(val):74.9%\n",
      "iter:1206 \t Loss:3.697 \t error(train):74.3% \t error(val):75.0%\n",
      "iter:1207 \t Loss:3.694 \t error(train):74.3% \t error(val):75.0%\n",
      "iter:1208 \t Loss:3.693 \t error(train):74.3% \t error(val):74.9%\n",
      "iter:1209 \t Loss:3.692 \t error(train):74.4% \t error(val):75.1%\n",
      "iter:1210 \t Loss:3.690 \t error(train):74.3% \t error(val):75.0%\n",
      "iter:1211 \t Loss:3.689 \t error(train):74.4% \t error(val):75.1%\n",
      "iter:1212 \t Loss:3.688 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1213 \t Loss:3.687 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1214 \t Loss:3.686 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1215 \t Loss:3.685 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1216 \t Loss:3.684 \t error(train):74.4% \t error(val):74.9%\n",
      "iter:1217 \t Loss:3.683 \t error(train):74.4% \t error(val):75.1%\n",
      "iter:1218 \t Loss:3.682 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1219 \t Loss:3.681 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1220 \t Loss:3.680 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1221 \t Loss:3.676 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1222 \t Loss:3.675 \t error(train):74.4% \t error(val):75.1%\n",
      "iter:1223 \t Loss:3.674 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1224 \t Loss:3.670 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1225 \t Loss:3.669 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1226 \t Loss:3.668 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1227 \t Loss:3.667 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1228 \t Loss:3.666 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1229 \t Loss:3.665 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1230 \t Loss:3.664 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1231 \t Loss:3.662 \t error(train):74.5% \t error(val):75.0%\n",
      "iter:1232 \t Loss:3.661 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1233 \t Loss:3.660 \t error(train):74.4% \t error(val):74.9%\n",
      "iter:1234 \t Loss:3.658 \t error(train):74.5% \t error(val):75.0%\n",
      "iter:1235 \t Loss:3.657 \t error(train):74.5% \t error(val):75.2%\n",
      "iter:1236 \t Loss:3.656 \t error(train):74.5% \t error(val):75.0%\n",
      "iter:1237 \t Loss:3.655 \t error(train):74.4% \t error(val):75.1%\n",
      "iter:1238 \t Loss:3.654 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1239 \t Loss:3.653 \t error(train):74.6% \t error(val):75.0%\n",
      "iter:1240 \t Loss:3.651 \t error(train):74.4% \t error(val):75.0%\n",
      "iter:1241 \t Loss:3.649 \t error(train):74.5% \t error(val):75.2%\n",
      "iter:1242 \t Loss:3.648 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1243 \t Loss:3.647 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1244 \t Loss:3.646 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1245 \t Loss:3.644 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1246 \t Loss:3.643 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1247 \t Loss:3.642 \t error(train):74.5% \t error(val):75.1%\n",
      "iter:1248 \t Loss:3.639 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1249 \t Loss:3.638 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1250 \t Loss:3.637 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1251 \t Loss:3.636 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1252 \t Loss:3.635 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1253 \t Loss:3.633 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1254 \t Loss:3.632 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1255 \t Loss:3.631 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1256 \t Loss:3.630 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1257 \t Loss:3.629 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1258 \t Loss:3.628 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1259 \t Loss:3.627 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1260 \t Loss:3.623 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1261 \t Loss:3.622 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1262 \t Loss:3.621 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1263 \t Loss:3.620 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1264 \t Loss:3.619 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1265 \t Loss:3.618 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1266 \t Loss:3.617 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1267 \t Loss:3.616 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1268 \t Loss:3.615 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1269 \t Loss:3.614 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1270 \t Loss:3.613 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1271 \t Loss:3.612 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1272 \t Loss:3.611 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1273 \t Loss:3.610 \t error(train):74.6% \t error(val):75.1%\n",
      "iter:1274 \t Loss:3.606 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1275 \t Loss:3.605 \t error(train):74.8% \t error(val):75.1%\n",
      "iter:1276 \t Loss:3.604 \t error(train):74.6% \t error(val):75.2%\n",
      "iter:1277 \t Loss:3.601 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1278 \t Loss:3.600 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1279 \t Loss:3.599 \t error(train):74.6% \t error(val):75.2%\n",
      "iter:1280 \t Loss:3.598 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1281 \t Loss:3.597 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1282 \t Loss:3.596 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1283 \t Loss:3.595 \t error(train):74.7% \t error(val):75.3%\n",
      "iter:1284 \t Loss:3.594 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1285 \t Loss:3.593 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1286 \t Loss:3.592 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1287 \t Loss:3.590 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1288 \t Loss:3.590 \t error(train):74.7% \t error(val):75.2%\n",
      "iter:1289 \t Loss:3.588 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1290 \t Loss:3.587 \t error(train):74.7% \t error(val):75.1%\n",
      "iter:1291 \t Loss:3.586 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1292 \t Loss:3.585 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1293 \t Loss:3.584 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1294 \t Loss:3.584 \t error(train):74.8% \t error(val):75.1%\n",
      "iter:1295 \t Loss:3.583 \t error(train):74.8% \t error(val):75.3%\n",
      "iter:1296 \t Loss:3.581 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1297 \t Loss:3.580 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1298 \t Loss:3.579 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1299 \t Loss:3.577 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1300 \t Loss:3.576 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1301 \t Loss:3.575 \t error(train):74.9% \t error(val):75.2%\n",
      "iter:1302 \t Loss:3.574 \t error(train):74.8% \t error(val):75.3%\n",
      "iter:1303 \t Loss:3.573 \t error(train):74.8% \t error(val):75.2%\n",
      "iter:1304 \t Loss:3.572 \t error(train):74.9% \t error(val):75.2%\n",
      "iter:1305 \t Loss:3.571 \t error(train):74.8% \t error(val):75.4%\n",
      "iter:1306 \t Loss:3.569 \t error(train):74.9% \t error(val):75.2%\n",
      "iter:1307 \t Loss:3.567 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1308 \t Loss:3.566 \t error(train):74.9% \t error(val):75.2%\n",
      "iter:1309 \t Loss:3.566 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1310 \t Loss:3.564 \t error(train):74.9% \t error(val):75.2%\n",
      "iter:1311 \t Loss:3.563 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1312 \t Loss:3.562 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1313 \t Loss:3.559 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1314 \t Loss:3.558 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1315 \t Loss:3.557 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1316 \t Loss:3.556 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1317 \t Loss:3.555 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1318 \t Loss:3.553 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1319 \t Loss:3.553 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1320 \t Loss:3.552 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1321 \t Loss:3.551 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1322 \t Loss:3.550 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1323 \t Loss:3.548 \t error(train):75.0% \t error(val):75.3%\n",
      "iter:1324 \t Loss:3.547 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1325 \t Loss:3.544 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1326 \t Loss:3.543 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1327 \t Loss:3.542 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1328 \t Loss:3.541 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1329 \t Loss:3.540 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1330 \t Loss:3.539 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1331 \t Loss:3.538 \t error(train):75.0% \t error(val):75.3%\n",
      "iter:1332 \t Loss:3.537 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1333 \t Loss:3.536 \t error(train):74.9% \t error(val):75.3%\n",
      "iter:1334 \t Loss:3.535 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1335 \t Loss:3.534 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1336 \t Loss:3.532 \t error(train):75.0% \t error(val):75.3%\n",
      "iter:1337 \t Loss:3.529 \t error(train):75.0% \t error(val):75.5%\n",
      "iter:1338 \t Loss:3.528 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1339 \t Loss:3.527 \t error(train):75.0% \t error(val):75.5%\n",
      "iter:1340 \t Loss:3.527 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1341 \t Loss:3.526 \t error(train):75.0% \t error(val):75.5%\n",
      "iter:1342 \t Loss:3.524 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1343 \t Loss:3.524 \t error(train):75.0% \t error(val):75.6%\n",
      "iter:1344 \t Loss:3.522 \t error(train):75.0% \t error(val):75.5%\n",
      "iter:1345 \t Loss:3.521 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1346 \t Loss:3.520 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1347 \t Loss:3.519 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1348 \t Loss:3.518 \t error(train):75.0% \t error(val):75.6%\n",
      "iter:1349 \t Loss:3.517 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1350 \t Loss:3.516 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1351 \t Loss:3.515 \t error(train):75.1% \t error(val):75.6%\n",
      "iter:1352 \t Loss:3.514 \t error(train):75.1% \t error(val):75.4%\n",
      "iter:1353 \t Loss:3.513 \t error(train):75.1% \t error(val):75.6%\n",
      "iter:1354 \t Loss:3.512 \t error(train):75.0% \t error(val):75.4%\n",
      "iter:1355 \t Loss:3.511 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1356 \t Loss:3.510 \t error(train):75.1% \t error(val):75.4%\n",
      "iter:1357 \t Loss:3.509 \t error(train):75.1% \t error(val):75.6%\n",
      "iter:1358 \t Loss:3.508 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1359 \t Loss:3.507 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1360 \t Loss:3.506 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1361 \t Loss:3.503 \t error(train):75.1% \t error(val):75.4%\n",
      "iter:1362 \t Loss:3.501 \t error(train):75.1% \t error(val):75.5%\n",
      "iter:1363 \t Loss:3.501 \t error(train):75.1% \t error(val):75.4%\n",
      "iter:1364 \t Loss:3.499 \t error(train):75.1% \t error(val):75.6%\n",
      "iter:1365 \t Loss:3.498 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1366 \t Loss:3.498 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1367 \t Loss:3.496 \t error(train):75.1% \t error(val):75.4%\n",
      "iter:1368 \t Loss:3.493 \t error(train):75.2% \t error(val):75.6%\n",
      "iter:1369 \t Loss:3.492 \t error(train):75.1% \t error(val):75.4%\n",
      "iter:1370 \t Loss:3.491 \t error(train):75.2% \t error(val):75.6%\n",
      "iter:1371 \t Loss:3.490 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1372 \t Loss:3.489 \t error(train):75.2% \t error(val):75.7%\n",
      "iter:1373 \t Loss:3.488 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1374 \t Loss:3.487 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1375 \t Loss:3.486 \t error(train):75.2% \t error(val):75.7%\n",
      "iter:1376 \t Loss:3.484 \t error(train):75.2% \t error(val):75.6%\n",
      "iter:1377 \t Loss:3.483 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1378 \t Loss:3.482 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1379 \t Loss:3.481 \t error(train):75.2% \t error(val):75.4%\n",
      "iter:1380 \t Loss:3.480 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1381 \t Loss:3.479 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1382 \t Loss:3.478 \t error(train):75.3% \t error(val):75.4%\n",
      "iter:1383 \t Loss:3.476 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1384 \t Loss:3.475 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1385 \t Loss:3.474 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1386 \t Loss:3.473 \t error(train):75.2% \t error(val):75.8%\n",
      "iter:1387 \t Loss:3.472 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1388 \t Loss:3.471 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1389 \t Loss:3.469 \t error(train):75.3% \t error(val):75.8%\n",
      "iter:1390 \t Loss:3.467 \t error(train):75.2% \t error(val):75.5%\n",
      "iter:1391 \t Loss:3.466 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1392 \t Loss:3.465 \t error(train):75.3% \t error(val):75.7%\n",
      "iter:1393 \t Loss:3.464 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1394 \t Loss:3.463 \t error(train):75.3% \t error(val):75.7%\n",
      "iter:1395 \t Loss:3.461 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1396 \t Loss:3.461 \t error(train):75.3% \t error(val):75.6%\n",
      "iter:1397 \t Loss:3.460 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1398 \t Loss:3.459 \t error(train):75.3% \t error(val):75.6%\n",
      "iter:1399 \t Loss:3.458 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1400 \t Loss:3.457 \t error(train):75.3% \t error(val):75.7%\n",
      "iter:1401 \t Loss:3.456 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1402 \t Loss:3.456 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1403 \t Loss:3.454 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1404 \t Loss:3.451 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1405 \t Loss:3.450 \t error(train):75.3% \t error(val):75.6%\n",
      "iter:1406 \t Loss:3.449 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1407 \t Loss:3.447 \t error(train):75.3% \t error(val):75.5%\n",
      "iter:1408 \t Loss:3.446 \t error(train):75.3% \t error(val):75.7%\n",
      "iter:1409 \t Loss:3.445 \t error(train):75.4% \t error(val):75.6%\n",
      "iter:1410 \t Loss:3.444 \t error(train):75.3% \t error(val):75.7%\n",
      "iter:1411 \t Loss:3.443 \t error(train):75.3% \t error(val):75.6%\n",
      "iter:1412 \t Loss:3.441 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1413 \t Loss:3.441 \t error(train):75.4% \t error(val):75.6%\n",
      "iter:1414 \t Loss:3.439 \t error(train):75.4% \t error(val):75.6%\n",
      "iter:1415 \t Loss:3.439 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1416 \t Loss:3.438 \t error(train):75.4% \t error(val):75.6%\n",
      "iter:1417 \t Loss:3.436 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1418 \t Loss:3.436 \t error(train):75.4% \t error(val):75.6%\n",
      "iter:1419 \t Loss:3.434 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1420 \t Loss:3.434 \t error(train):75.4% \t error(val):75.6%\n",
      "iter:1421 \t Loss:3.433 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1422 \t Loss:3.432 \t error(train):75.4% \t error(val):75.5%\n",
      "iter:1423 \t Loss:3.431 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1424 \t Loss:3.430 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1425 \t Loss:3.429 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1426 \t Loss:3.426 \t error(train):75.4% \t error(val):75.9%\n",
      "iter:1427 \t Loss:3.424 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1428 \t Loss:3.423 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1429 \t Loss:3.422 \t error(train):75.4% \t error(val):75.8%\n",
      "iter:1430 \t Loss:3.422 \t error(train):75.4% \t error(val):75.7%\n",
      "iter:1431 \t Loss:3.421 \t error(train):75.4% \t error(val):75.8%\n",
      "iter:1432 \t Loss:3.420 \t error(train):75.5% \t error(val):75.6%\n",
      "iter:1433 \t Loss:3.416 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1434 \t Loss:3.415 \t error(train):75.5% \t error(val):75.6%\n",
      "iter:1435 \t Loss:3.414 \t error(train):75.4% \t error(val):75.8%\n",
      "iter:1436 \t Loss:3.414 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1437 \t Loss:3.413 \t error(train):75.4% \t error(val):75.8%\n",
      "iter:1438 \t Loss:3.412 \t error(train):75.4% \t error(val):75.8%\n",
      "iter:1439 \t Loss:3.411 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1440 \t Loss:3.410 \t error(train):75.4% \t error(val):75.9%\n",
      "iter:1441 \t Loss:3.408 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1442 \t Loss:3.407 \t error(train):75.5% \t error(val):75.6%\n",
      "iter:1443 \t Loss:3.406 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1444 \t Loss:3.405 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1445 \t Loss:3.404 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1446 \t Loss:3.403 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1447 \t Loss:3.402 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1448 \t Loss:3.400 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1449 \t Loss:3.399 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1450 \t Loss:3.398 \t error(train):75.5% \t error(val):75.7%\n",
      "iter:1451 \t Loss:3.397 \t error(train):75.4% \t error(val):76.0%\n",
      "iter:1452 \t Loss:3.396 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1453 \t Loss:3.395 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1454 \t Loss:3.394 \t error(train):75.5% \t error(val):75.9%\n",
      "iter:1455 \t Loss:3.391 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1456 \t Loss:3.390 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1457 \t Loss:3.389 \t error(train):75.5% \t error(val):75.9%\n",
      "iter:1458 \t Loss:3.388 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1459 \t Loss:3.388 \t error(train):75.5% \t error(val):75.9%\n",
      "iter:1460 \t Loss:3.386 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1461 \t Loss:3.385 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1462 \t Loss:3.385 \t error(train):75.5% \t error(val):75.8%\n",
      "iter:1463 \t Loss:3.384 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1464 \t Loss:3.383 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1465 \t Loss:3.382 \t error(train):75.5% \t error(val):75.9%\n",
      "iter:1466 \t Loss:3.381 \t error(train):75.5% \t error(val):75.9%\n",
      "iter:1467 \t Loss:3.381 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1468 \t Loss:3.379 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1469 \t Loss:3.376 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1470 \t Loss:3.375 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1471 \t Loss:3.374 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1472 \t Loss:3.372 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1473 \t Loss:3.371 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1474 \t Loss:3.370 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1475 \t Loss:3.369 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1476 \t Loss:3.368 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1477 \t Loss:3.367 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1478 \t Loss:3.366 \t error(train):75.6% \t error(val):75.8%\n",
      "iter:1479 \t Loss:3.365 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1480 \t Loss:3.364 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1481 \t Loss:3.364 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1482 \t Loss:3.362 \t error(train):75.6% \t error(val):76.0%\n",
      "iter:1483 \t Loss:3.362 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1484 \t Loss:3.360 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1485 \t Loss:3.360 \t error(train):75.6% \t error(val):76.0%\n",
      "iter:1486 \t Loss:3.359 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1487 \t Loss:3.358 \t error(train):75.6% \t error(val):75.9%\n",
      "iter:1488 \t Loss:3.357 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1489 \t Loss:3.356 \t error(train):75.6% \t error(val):76.0%\n",
      "iter:1490 \t Loss:3.355 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1491 \t Loss:3.354 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1492 \t Loss:3.353 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1493 \t Loss:3.352 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1494 \t Loss:3.350 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1495 \t Loss:3.349 \t error(train):75.6% \t error(val):76.0%\n",
      "iter:1496 \t Loss:3.348 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1497 \t Loss:3.348 \t error(train):75.6% \t error(val):76.1%\n",
      "iter:1498 \t Loss:3.346 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1499 \t Loss:3.346 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1500 \t Loss:3.345 \t error(train):75.6% \t error(val):76.2%\n",
      "iter:1501 \t Loss:3.343 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1502 \t Loss:3.342 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1503 \t Loss:3.341 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1504 \t Loss:3.340 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1505 \t Loss:3.339 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1506 \t Loss:3.338 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1507 \t Loss:3.337 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1508 \t Loss:3.334 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1509 \t Loss:3.333 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1510 \t Loss:3.333 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1511 \t Loss:3.331 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1512 \t Loss:3.331 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1513 \t Loss:3.329 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1514 \t Loss:3.329 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1515 \t Loss:3.328 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1516 \t Loss:3.327 \t error(train):75.7% \t error(val):75.9%\n",
      "iter:1517 \t Loss:3.326 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1518 \t Loss:3.325 \t error(train):75.7% \t error(val):76.1%\n",
      "iter:1519 \t Loss:3.324 \t error(train):75.8% \t error(val):76.0%\n",
      "iter:1520 \t Loss:3.321 \t error(train):75.7% \t error(val):76.2%\n",
      "iter:1521 \t Loss:3.320 \t error(train):75.8% \t error(val):76.0%\n",
      "iter:1522 \t Loss:3.320 \t error(train):75.7% \t error(val):76.2%\n",
      "iter:1523 \t Loss:3.319 \t error(train):75.7% \t error(val):76.0%\n",
      "iter:1524 \t Loss:3.318 \t error(train):75.7% \t error(val):76.2%\n",
      "iter:1525 \t Loss:3.317 \t error(train):75.8% \t error(val):76.0%\n",
      "iter:1526 \t Loss:3.316 \t error(train):75.7% \t error(val):76.3%\n",
      "iter:1527 \t Loss:3.315 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1528 \t Loss:3.314 \t error(train):75.8% \t error(val):76.0%\n",
      "iter:1529 \t Loss:3.313 \t error(train):75.7% \t error(val):76.3%\n",
      "iter:1530 \t Loss:3.312 \t error(train):75.7% \t error(val):76.2%\n",
      "iter:1531 \t Loss:3.310 \t error(train):75.8% \t error(val):76.1%\n",
      "iter:1532 \t Loss:3.310 \t error(train):75.7% \t error(val):76.2%\n",
      "iter:1533 \t Loss:3.309 \t error(train):75.8% \t error(val):76.1%\n",
      "iter:1534 \t Loss:3.308 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1535 \t Loss:3.307 \t error(train):75.8% \t error(val):76.1%\n",
      "iter:1536 \t Loss:3.306 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1537 \t Loss:3.306 \t error(train):75.8% \t error(val):76.1%\n",
      "iter:1538 \t Loss:3.305 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1539 \t Loss:3.301 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1540 \t Loss:3.300 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1541 \t Loss:3.300 \t error(train):75.8% \t error(val):76.1%\n",
      "iter:1542 \t Loss:3.299 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1543 \t Loss:3.298 \t error(train):75.8% \t error(val):76.1%\n",
      "iter:1544 \t Loss:3.297 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1545 \t Loss:3.296 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1546 \t Loss:3.295 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1547 \t Loss:3.294 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1548 \t Loss:3.293 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1549 \t Loss:3.292 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1550 \t Loss:3.291 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1551 \t Loss:3.291 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1552 \t Loss:3.290 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1553 \t Loss:3.289 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1554 \t Loss:3.288 \t error(train):75.8% \t error(val):76.2%\n",
      "iter:1555 \t Loss:3.287 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1556 \t Loss:3.286 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1557 \t Loss:3.285 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1558 \t Loss:3.284 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1559 \t Loss:3.283 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1560 \t Loss:3.282 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1561 \t Loss:3.281 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1562 \t Loss:3.281 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1563 \t Loss:3.280 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1564 \t Loss:3.279 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1565 \t Loss:3.278 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1566 \t Loss:3.277 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1567 \t Loss:3.276 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1568 \t Loss:3.275 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1569 \t Loss:3.275 \t error(train):75.9% \t error(val):76.2%\n",
      "iter:1570 \t Loss:3.273 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1571 \t Loss:3.272 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1572 \t Loss:3.271 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1573 \t Loss:3.269 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1574 \t Loss:3.268 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1575 \t Loss:3.267 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1576 \t Loss:3.267 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1577 \t Loss:3.266 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1578 \t Loss:3.265 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1579 \t Loss:3.264 \t error(train):75.9% \t error(val):76.4%\n",
      "iter:1580 \t Loss:3.263 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1581 \t Loss:3.262 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1582 \t Loss:3.261 \t error(train):75.9% \t error(val):76.4%\n",
      "iter:1583 \t Loss:3.260 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1584 \t Loss:3.259 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1585 \t Loss:3.258 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1586 \t Loss:3.258 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1587 \t Loss:3.257 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1588 \t Loss:3.256 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1589 \t Loss:3.255 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1590 \t Loss:3.254 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1591 \t Loss:3.253 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1592 \t Loss:3.252 \t error(train):75.9% \t error(val):76.3%\n",
      "iter:1593 \t Loss:3.252 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1594 \t Loss:3.251 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1595 \t Loss:3.250 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1596 \t Loss:3.249 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1597 \t Loss:3.246 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1598 \t Loss:3.245 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1599 \t Loss:3.245 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1600 \t Loss:3.244 \t error(train):76.0% \t error(val):76.5%\n",
      "iter:1601 \t Loss:3.243 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1602 \t Loss:3.242 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1603 \t Loss:3.241 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1604 \t Loss:3.238 \t error(train):76.0% \t error(val):76.5%\n",
      "iter:1605 \t Loss:3.237 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1606 \t Loss:3.236 \t error(train):76.0% \t error(val):76.5%\n",
      "iter:1607 \t Loss:3.236 \t error(train):76.0% \t error(val):76.3%\n",
      "iter:1608 \t Loss:3.235 \t error(train):76.0% \t error(val):76.5%\n",
      "iter:1609 \t Loss:3.234 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1610 \t Loss:3.233 \t error(train):76.0% \t error(val):76.4%\n",
      "iter:1611 \t Loss:3.233 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1612 \t Loss:3.231 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1613 \t Loss:3.230 \t error(train):76.1% \t error(val):76.4%\n",
      "iter:1614 \t Loss:3.229 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1615 \t Loss:3.228 \t error(train):76.1% \t error(val):76.4%\n",
      "iter:1616 \t Loss:3.227 \t error(train):76.1% \t error(val):76.4%\n",
      "iter:1617 \t Loss:3.227 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1618 \t Loss:3.226 \t error(train):76.1% \t error(val):76.4%\n",
      "iter:1619 \t Loss:3.224 \t error(train):76.1% \t error(val):76.4%\n",
      "iter:1620 \t Loss:3.223 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1621 \t Loss:3.222 \t error(train):76.1% \t error(val):76.4%\n",
      "iter:1622 \t Loss:3.221 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1623 \t Loss:3.220 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1624 \t Loss:3.219 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1625 \t Loss:3.218 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1626 \t Loss:3.216 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1627 \t Loss:3.215 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1628 \t Loss:3.214 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1629 \t Loss:3.213 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1630 \t Loss:3.213 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1631 \t Loss:3.212 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1632 \t Loss:3.211 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1633 \t Loss:3.210 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1634 \t Loss:3.209 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1635 \t Loss:3.209 \t error(train):76.2% \t error(val):76.5%\n",
      "iter:1636 \t Loss:3.208 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1637 \t Loss:3.207 \t error(train):76.1% \t error(val):76.6%\n",
      "iter:1638 \t Loss:3.206 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1639 \t Loss:3.206 \t error(train):76.1% \t error(val):76.5%\n",
      "iter:1640 \t Loss:3.205 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1641 \t Loss:3.204 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1642 \t Loss:3.204 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1643 \t Loss:3.202 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1644 \t Loss:3.202 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1645 \t Loss:3.201 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1646 \t Loss:3.200 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1647 \t Loss:3.200 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1648 \t Loss:3.199 \t error(train):76.2% \t error(val):76.5%\n",
      "iter:1649 \t Loss:3.198 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1650 \t Loss:3.197 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1651 \t Loss:3.196 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1652 \t Loss:3.196 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1653 \t Loss:3.195 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1654 \t Loss:3.194 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1655 \t Loss:3.192 \t error(train):76.3% \t error(val):76.6%\n",
      "iter:1656 \t Loss:3.191 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1657 \t Loss:3.190 \t error(train):76.3% \t error(val):76.6%\n",
      "iter:1658 \t Loss:3.190 \t error(train):76.2% \t error(val):76.6%\n",
      "iter:1659 \t Loss:3.189 \t error(train):76.2% \t error(val):76.7%\n",
      "iter:1660 \t Loss:3.188 \t error(train):76.2% \t error(val):76.7%\n",
      "iter:1661 \t Loss:3.188 \t error(train):76.2% \t error(val):76.7%\n",
      "iter:1662 \t Loss:3.185 \t error(train):76.3% \t error(val):76.9%\n",
      "iter:1663 \t Loss:3.179 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1664 \t Loss:3.176 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1665 \t Loss:3.175 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1666 \t Loss:3.174 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1667 \t Loss:3.172 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1668 \t Loss:3.171 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1669 \t Loss:3.171 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1670 \t Loss:3.170 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1671 \t Loss:3.169 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1672 \t Loss:3.168 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1673 \t Loss:3.167 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1674 \t Loss:3.167 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1675 \t Loss:3.166 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1676 \t Loss:3.165 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1677 \t Loss:3.165 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1678 \t Loss:3.164 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1679 \t Loss:3.163 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1680 \t Loss:3.162 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1681 \t Loss:3.160 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1682 \t Loss:3.159 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1683 \t Loss:3.158 \t error(train):76.3% \t error(val):76.7%\n",
      "iter:1684 \t Loss:3.156 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1685 \t Loss:3.155 \t error(train):76.3% \t error(val):76.8%\n",
      "iter:1686 \t Loss:3.154 \t error(train):76.4% \t error(val):76.7%\n",
      "iter:1687 \t Loss:3.154 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1688 \t Loss:3.153 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1689 \t Loss:3.152 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1690 \t Loss:3.151 \t error(train):76.4% \t error(val):76.7%\n",
      "iter:1691 \t Loss:3.150 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1692 \t Loss:3.150 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1693 \t Loss:3.149 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1694 \t Loss:3.148 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1695 \t Loss:3.147 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1696 \t Loss:3.146 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1697 \t Loss:3.145 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1698 \t Loss:3.145 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1699 \t Loss:3.144 \t error(train):76.4% \t error(val):76.8%\n",
      "iter:1700 \t Loss:3.143 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1701 \t Loss:3.143 \t error(train):76.4% \t error(val):76.9%\n",
      "iter:1702 \t Loss:3.142 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1703 \t Loss:3.139 \t error(train):76.5% \t error(val):76.8%\n",
      "iter:1704 \t Loss:3.138 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1705 \t Loss:3.137 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1706 \t Loss:3.137 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1707 \t Loss:3.136 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1708 \t Loss:3.135 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1709 \t Loss:3.134 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1710 \t Loss:3.131 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1711 \t Loss:3.131 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1712 \t Loss:3.130 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1713 \t Loss:3.130 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1714 \t Loss:3.129 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1715 \t Loss:3.126 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1716 \t Loss:3.121 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1717 \t Loss:3.118 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1718 \t Loss:3.117 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1719 \t Loss:3.116 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1720 \t Loss:3.114 \t error(train):76.5% \t error(val):76.9%\n",
      "iter:1721 \t Loss:3.113 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1722 \t Loss:3.113 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1723 \t Loss:3.112 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1724 \t Loss:3.111 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1725 \t Loss:3.110 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1726 \t Loss:3.109 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1727 \t Loss:3.109 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1728 \t Loss:3.108 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1729 \t Loss:3.108 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1730 \t Loss:3.107 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1731 \t Loss:3.106 \t error(train):76.6% \t error(val):76.9%\n",
      "iter:1732 \t Loss:3.106 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1733 \t Loss:3.105 \t error(train):76.6% \t error(val):76.9%\n",
      "iter:1734 \t Loss:3.102 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1735 \t Loss:3.101 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1736 \t Loss:3.101 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1737 \t Loss:3.099 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1738 \t Loss:3.098 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1739 \t Loss:3.097 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1740 \t Loss:3.096 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1741 \t Loss:3.096 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1742 \t Loss:3.095 \t error(train):76.7% \t error(val):77.1%\n",
      "iter:1743 \t Loss:3.094 \t error(train):76.6% \t error(val):76.9%\n",
      "iter:1744 \t Loss:3.093 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1745 \t Loss:3.093 \t error(train):76.7% \t error(val):77.1%\n",
      "iter:1746 \t Loss:3.092 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1747 \t Loss:3.091 \t error(train):76.7% \t error(val):77.1%\n",
      "iter:1748 \t Loss:3.090 \t error(train):76.6% \t error(val):77.0%\n",
      "iter:1749 \t Loss:3.089 \t error(train):76.7% \t error(val):77.1%\n",
      "iter:1750 \t Loss:3.089 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1751 \t Loss:3.088 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1752 \t Loss:3.087 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1753 \t Loss:3.087 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1754 \t Loss:3.086 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1755 \t Loss:3.085 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1756 \t Loss:3.083 \t error(train):76.7% \t error(val):77.1%\n",
      "iter:1757 \t Loss:3.082 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1758 \t Loss:3.081 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1759 \t Loss:3.080 \t error(train):76.7% \t error(val):77.2%\n",
      "iter:1760 \t Loss:3.079 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1761 \t Loss:3.079 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1762 \t Loss:3.078 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1763 \t Loss:3.075 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1764 \t Loss:3.075 \t error(train):76.7% \t error(val):77.0%\n",
      "iter:1765 \t Loss:3.074 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1766 \t Loss:3.074 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1767 \t Loss:3.073 \t error(train):76.7% \t error(val):77.1%\n",
      "iter:1768 \t Loss:3.070 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1769 \t Loss:3.066 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1770 \t Loss:3.062 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1771 \t Loss:3.062 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1772 \t Loss:3.061 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1773 \t Loss:3.059 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1774 \t Loss:3.058 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1775 \t Loss:3.057 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1776 \t Loss:3.057 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1777 \t Loss:3.056 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1778 \t Loss:3.055 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1779 \t Loss:3.054 \t error(train):76.8% \t error(val):77.3%\n",
      "iter:1780 \t Loss:3.054 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1781 \t Loss:3.053 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1782 \t Loss:3.053 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1783 \t Loss:3.052 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1784 \t Loss:3.051 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1785 \t Loss:3.051 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1786 \t Loss:3.050 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1787 \t Loss:3.047 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1788 \t Loss:3.047 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1789 \t Loss:3.046 \t error(train):76.8% \t error(val):77.1%\n",
      "iter:1790 \t Loss:3.044 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1791 \t Loss:3.043 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1792 \t Loss:3.043 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1793 \t Loss:3.042 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1794 \t Loss:3.041 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1795 \t Loss:3.040 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1796 \t Loss:3.040 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1797 \t Loss:3.039 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1798 \t Loss:3.038 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1799 \t Loss:3.038 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1800 \t Loss:3.037 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1801 \t Loss:3.036 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1802 \t Loss:3.035 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1803 \t Loss:3.035 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1804 \t Loss:3.034 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1805 \t Loss:3.033 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1806 \t Loss:3.033 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1807 \t Loss:3.032 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1808 \t Loss:3.031 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1809 \t Loss:3.030 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1810 \t Loss:3.030 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1811 \t Loss:3.029 \t error(train):76.8% \t error(val):77.2%\n",
      "iter:1812 \t Loss:3.028 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1813 \t Loss:3.027 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1814 \t Loss:3.026 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1815 \t Loss:3.026 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1816 \t Loss:3.025 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1817 \t Loss:3.024 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1818 \t Loss:3.023 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1819 \t Loss:3.022 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1820 \t Loss:3.021 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1821 \t Loss:3.020 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1822 \t Loss:3.020 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1823 \t Loss:3.019 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1824 \t Loss:3.018 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1825 \t Loss:3.017 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1826 \t Loss:3.015 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1827 \t Loss:3.015 \t error(train):76.9% \t error(val):77.4%\n",
      "iter:1828 \t Loss:3.014 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1829 \t Loss:3.013 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1830 \t Loss:3.013 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1831 \t Loss:3.012 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1832 \t Loss:3.011 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1833 \t Loss:3.010 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1834 \t Loss:3.010 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1835 \t Loss:3.009 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1836 \t Loss:3.009 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1837 \t Loss:3.008 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1838 \t Loss:3.008 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1839 \t Loss:3.007 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1840 \t Loss:3.004 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1841 \t Loss:3.004 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1842 \t Loss:3.003 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1843 \t Loss:3.001 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1844 \t Loss:3.000 \t error(train):76.9% \t error(val):77.3%\n",
      "iter:1845 \t Loss:3.000 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1846 \t Loss:2.999 \t error(train):76.9% \t error(val):77.2%\n",
      "iter:1847 \t Loss:2.998 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1848 \t Loss:2.998 \t error(train):77.0% \t error(val):77.4%\n",
      "iter:1849 \t Loss:2.997 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1850 \t Loss:2.994 \t error(train):77.1% \t error(val):77.5%\n",
      "iter:1851 \t Loss:2.994 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1852 \t Loss:2.993 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1853 \t Loss:2.993 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1854 \t Loss:2.992 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1855 \t Loss:2.992 \t error(train):77.1% \t error(val):77.3%\n",
      "iter:1856 \t Loss:2.991 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1857 \t Loss:2.988 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1858 \t Loss:2.988 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1859 \t Loss:2.987 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1860 \t Loss:2.987 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1861 \t Loss:2.986 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1862 \t Loss:2.985 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1863 \t Loss:2.985 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1864 \t Loss:2.984 \t error(train):77.1% \t error(val):77.3%\n",
      "iter:1865 \t Loss:2.984 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1866 \t Loss:2.983 \t error(train):77.0% \t error(val):77.3%\n",
      "iter:1867 \t Loss:2.981 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1868 \t Loss:2.980 \t error(train):77.1% \t error(val):77.3%\n",
      "iter:1869 \t Loss:2.979 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1870 \t Loss:2.979 \t error(train):77.1% \t error(val):77.3%\n",
      "iter:1871 \t Loss:2.978 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1872 \t Loss:2.978 \t error(train):77.1% \t error(val):77.4%\n",
      "iter:1873 \t Loss:2.977 \t error(train):77.2% \t error(val):77.3%\n",
      "iter:1874 \t Loss:2.975 \t error(train):77.2% \t error(val):77.6%\n",
      "iter:1875 \t Loss:2.969 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1876 \t Loss:2.967 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1877 \t Loss:2.967 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1878 \t Loss:2.966 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1879 \t Loss:2.964 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1880 \t Loss:2.964 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1881 \t Loss:2.963 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1882 \t Loss:2.962 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1883 \t Loss:2.962 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1884 \t Loss:2.961 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1885 \t Loss:2.961 \t error(train):77.3% \t error(val):77.4%\n",
      "iter:1886 \t Loss:2.958 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1887 \t Loss:2.951 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1888 \t Loss:2.951 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1889 \t Loss:2.950 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1890 \t Loss:2.949 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1891 \t Loss:2.948 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1892 \t Loss:2.948 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1893 \t Loss:2.947 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1894 \t Loss:2.947 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1895 \t Loss:2.946 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1896 \t Loss:2.945 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1897 \t Loss:2.945 \t error(train):77.2% \t error(val):77.4%\n",
      "iter:1898 \t Loss:2.944 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1899 \t Loss:2.943 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1900 \t Loss:2.942 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1901 \t Loss:2.942 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1902 \t Loss:2.941 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1903 \t Loss:2.940 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1904 \t Loss:2.940 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1905 \t Loss:2.939 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1906 \t Loss:2.938 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1907 \t Loss:2.938 \t error(train):77.2% \t error(val):77.5%\n",
      "iter:1908 \t Loss:2.937 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1909 \t Loss:2.936 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1910 \t Loss:2.936 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1911 \t Loss:2.935 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1912 \t Loss:2.935 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1913 \t Loss:2.934 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1914 \t Loss:2.933 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1915 \t Loss:2.932 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1916 \t Loss:2.932 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1917 \t Loss:2.931 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1918 \t Loss:2.930 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1919 \t Loss:2.930 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1920 \t Loss:2.929 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1921 \t Loss:2.929 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1922 \t Loss:2.928 \t error(train):77.3% \t error(val):77.5%\n",
      "iter:1923 \t Loss:2.927 \t error(train):77.3% \t error(val):77.6%\n",
      "iter:1924 \t Loss:2.926 \t error(train):77.4% \t error(val):77.7%\n",
      "iter:1925 \t Loss:2.925 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1926 \t Loss:2.925 \t error(train):77.4% \t error(val):77.7%\n",
      "iter:1927 \t Loss:2.924 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1928 \t Loss:2.924 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1929 \t Loss:2.923 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1930 \t Loss:2.922 \t error(train):77.4% \t error(val):77.7%\n",
      "iter:1931 \t Loss:2.921 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1932 \t Loss:2.920 \t error(train):77.4% \t error(val):77.7%\n",
      "iter:1933 \t Loss:2.920 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1934 \t Loss:2.919 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1935 \t Loss:2.918 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1936 \t Loss:2.918 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1937 \t Loss:2.916 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1938 \t Loss:2.915 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1939 \t Loss:2.915 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1940 \t Loss:2.914 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1941 \t Loss:2.914 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1942 \t Loss:2.913 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1943 \t Loss:2.912 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1944 \t Loss:2.912 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1945 \t Loss:2.911 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1946 \t Loss:2.910 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1947 \t Loss:2.910 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1948 \t Loss:2.909 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1949 \t Loss:2.908 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1950 \t Loss:2.908 \t error(train):77.5% \t error(val):77.7%\n",
      "iter:1951 \t Loss:2.907 \t error(train):77.4% \t error(val):77.5%\n",
      "iter:1952 \t Loss:2.906 \t error(train):77.4% \t error(val):77.6%\n",
      "iter:1953 \t Loss:2.905 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1954 \t Loss:2.905 \t error(train):77.5% \t error(val):77.5%\n",
      "iter:1955 \t Loss:2.904 \t error(train):77.5% \t error(val):77.8%\n",
      "iter:1956 \t Loss:2.904 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1957 \t Loss:2.903 \t error(train):77.6% \t error(val):77.8%\n",
      "iter:1958 \t Loss:2.902 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1959 \t Loss:2.902 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1960 \t Loss:2.901 \t error(train):77.6% \t error(val):77.8%\n",
      "iter:1961 \t Loss:2.899 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1962 \t Loss:2.899 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1963 \t Loss:2.898 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1964 \t Loss:2.898 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1965 \t Loss:2.897 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1966 \t Loss:2.897 \t error(train):77.5% \t error(val):77.6%\n",
      "iter:1967 \t Loss:2.896 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1968 \t Loss:2.894 \t error(train):77.5% \t error(val):77.5%\n",
      "iter:1969 \t Loss:2.893 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1970 \t Loss:2.892 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1971 \t Loss:2.891 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1972 \t Loss:2.891 \t error(train):77.5% \t error(val):77.5%\n",
      "iter:1973 \t Loss:2.890 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1974 \t Loss:2.889 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1975 \t Loss:2.889 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1976 \t Loss:2.888 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1977 \t Loss:2.888 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1978 \t Loss:2.887 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1979 \t Loss:2.886 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1980 \t Loss:2.886 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1981 \t Loss:2.885 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1982 \t Loss:2.884 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1983 \t Loss:2.884 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1984 \t Loss:2.883 \t error(train):77.6% \t error(val):77.5%\n",
      "iter:1985 \t Loss:2.881 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1986 \t Loss:2.881 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1987 \t Loss:2.880 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1988 \t Loss:2.879 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1989 \t Loss:2.878 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:1990 \t Loss:2.878 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1991 \t Loss:2.877 \t error(train):77.7% \t error(val):77.8%\n",
      "iter:1992 \t Loss:2.876 \t error(train):77.6% \t error(val):77.7%\n",
      "iter:1993 \t Loss:2.876 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1994 \t Loss:2.875 \t error(train):77.7% \t error(val):77.8%\n",
      "iter:1995 \t Loss:2.874 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:1996 \t Loss:2.873 \t error(train):77.6% \t error(val):77.6%\n",
      "iter:1997 \t Loss:2.873 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:1998 \t Loss:2.872 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:1999 \t Loss:2.872 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2000 \t Loss:2.871 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2001 \t Loss:2.870 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2002 \t Loss:2.869 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2003 \t Loss:2.868 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2004 \t Loss:2.868 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2005 \t Loss:2.867 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2006 \t Loss:2.866 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2007 \t Loss:2.866 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2008 \t Loss:2.865 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2009 \t Loss:2.864 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2010 \t Loss:2.864 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2011 \t Loss:2.863 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2012 \t Loss:2.862 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2013 \t Loss:2.862 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2014 \t Loss:2.861 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2015 \t Loss:2.861 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2016 \t Loss:2.860 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2017 \t Loss:2.859 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2018 \t Loss:2.859 \t error(train):77.7% \t error(val):77.6%\n",
      "iter:2019 \t Loss:2.858 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2020 \t Loss:2.858 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2021 \t Loss:2.857 \t error(train):77.7% \t error(val):77.7%\n",
      "iter:2022 \t Loss:2.856 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2023 \t Loss:2.856 \t error(train):77.8% \t error(val):77.6%\n",
      "iter:2024 \t Loss:2.855 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2025 \t Loss:2.855 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2026 \t Loss:2.854 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2027 \t Loss:2.853 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2028 \t Loss:2.853 \t error(train):77.8% \t error(val):77.6%\n",
      "iter:2029 \t Loss:2.852 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2030 \t Loss:2.852 \t error(train):77.8% \t error(val):77.6%\n",
      "iter:2031 \t Loss:2.851 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2032 \t Loss:2.850 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2033 \t Loss:2.850 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2034 \t Loss:2.849 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2035 \t Loss:2.849 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2036 \t Loss:2.848 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2037 \t Loss:2.847 \t error(train):77.8% \t error(val):77.6%\n",
      "iter:2038 \t Loss:2.845 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2039 \t Loss:2.845 \t error(train):77.8% \t error(val):77.6%\n",
      "iter:2040 \t Loss:2.844 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2041 \t Loss:2.844 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2042 \t Loss:2.843 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2043 \t Loss:2.843 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2044 \t Loss:2.842 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2045 \t Loss:2.841 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2046 \t Loss:2.841 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2047 \t Loss:2.840 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2048 \t Loss:2.839 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2049 \t Loss:2.839 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2050 \t Loss:2.838 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2051 \t Loss:2.838 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2052 \t Loss:2.837 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2053 \t Loss:2.836 \t error(train):77.8% \t error(val):77.7%\n",
      "iter:2054 \t Loss:2.836 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2055 \t Loss:2.835 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2056 \t Loss:2.835 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2057 \t Loss:2.834 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2058 \t Loss:2.834 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2059 \t Loss:2.833 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2060 \t Loss:2.833 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2061 \t Loss:2.832 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2062 \t Loss:2.830 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2063 \t Loss:2.829 \t error(train):77.8% \t error(val):77.9%\n",
      "iter:2064 \t Loss:2.829 \t error(train):77.9% \t error(val):77.7%\n",
      "iter:2065 \t Loss:2.828 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2066 \t Loss:2.828 \t error(train):77.8% \t error(val):77.8%\n",
      "iter:2067 \t Loss:2.827 \t error(train):77.8% \t error(val):77.9%\n",
      "iter:2068 \t Loss:2.826 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2069 \t Loss:2.824 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2070 \t Loss:2.824 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2071 \t Loss:2.823 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2072 \t Loss:2.823 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2073 \t Loss:2.822 \t error(train):77.9% \t error(val):78.0%\n",
      "iter:2074 \t Loss:2.822 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2075 \t Loss:2.821 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2076 \t Loss:2.821 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2077 \t Loss:2.820 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2078 \t Loss:2.819 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2079 \t Loss:2.818 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2080 \t Loss:2.818 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2081 \t Loss:2.817 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2082 \t Loss:2.816 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2083 \t Loss:2.816 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2084 \t Loss:2.815 \t error(train):77.9% \t error(val):77.8%\n",
      "iter:2085 \t Loss:2.814 \t error(train):77.9% \t error(val):78.0%\n",
      "iter:2086 \t Loss:2.813 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2087 \t Loss:2.813 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2088 \t Loss:2.812 \t error(train):77.9% \t error(val):78.0%\n",
      "iter:2089 \t Loss:2.812 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2090 \t Loss:2.811 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2091 \t Loss:2.809 \t error(train):77.9% \t error(val):78.0%\n",
      "iter:2092 \t Loss:2.809 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2093 \t Loss:2.808 \t error(train):77.9% \t error(val):78.0%\n",
      "iter:2094 \t Loss:2.807 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2095 \t Loss:2.807 \t error(train):77.9% \t error(val):78.0%\n",
      "iter:2096 \t Loss:2.806 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2097 \t Loss:2.806 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2098 \t Loss:2.805 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2099 \t Loss:2.805 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2100 \t Loss:2.804 \t error(train):77.9% \t error(val):77.9%\n",
      "iter:2101 \t Loss:2.804 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2102 \t Loss:2.803 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2103 \t Loss:2.803 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2104 \t Loss:2.802 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2105 \t Loss:2.802 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2106 \t Loss:2.801 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2107 \t Loss:2.801 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2108 \t Loss:2.800 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2109 \t Loss:2.799 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2110 \t Loss:2.799 \t error(train):78.0% \t error(val):77.9%\n",
      "iter:2111 \t Loss:2.799 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2112 \t Loss:2.798 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2113 \t Loss:2.798 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2114 \t Loss:2.797 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2115 \t Loss:2.796 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2116 \t Loss:2.796 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2117 \t Loss:2.795 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2118 \t Loss:2.795 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2119 \t Loss:2.794 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2120 \t Loss:2.793 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2121 \t Loss:2.792 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2122 \t Loss:2.792 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2123 \t Loss:2.791 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2124 \t Loss:2.791 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2125 \t Loss:2.790 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2126 \t Loss:2.790 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2127 \t Loss:2.789 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2128 \t Loss:2.789 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2129 \t Loss:2.788 \t error(train):78.0% \t error(val):78.1%\n",
      "iter:2130 \t Loss:2.787 \t error(train):78.0% \t error(val):78.0%\n",
      "iter:2131 \t Loss:2.787 \t error(train):78.0% \t error(val):78.1%\n",
      "iter:2132 \t Loss:2.786 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2133 \t Loss:2.786 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2134 \t Loss:2.785 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2135 \t Loss:2.785 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2136 \t Loss:2.784 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2137 \t Loss:2.783 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2138 \t Loss:2.783 \t error(train):78.1% \t error(val):78.2%\n",
      "iter:2139 \t Loss:2.782 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2140 \t Loss:2.782 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2141 \t Loss:2.781 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2142 \t Loss:2.780 \t error(train):78.1% \t error(val):78.0%\n",
      "iter:2143 \t Loss:2.780 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2144 \t Loss:2.779 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2145 \t Loss:2.779 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2146 \t Loss:2.778 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2147 \t Loss:2.778 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2148 \t Loss:2.777 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2149 \t Loss:2.776 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2150 \t Loss:2.776 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2151 \t Loss:2.775 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2152 \t Loss:2.775 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2153 \t Loss:2.774 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2154 \t Loss:2.774 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2155 \t Loss:2.774 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2156 \t Loss:2.773 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2157 \t Loss:2.773 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2158 \t Loss:2.772 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2159 \t Loss:2.771 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2160 \t Loss:2.770 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2161 \t Loss:2.770 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2162 \t Loss:2.769 \t error(train):78.1% \t error(val):78.2%\n",
      "iter:2163 \t Loss:2.769 \t error(train):78.1% \t error(val):78.1%\n",
      "iter:2164 \t Loss:2.768 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2165 \t Loss:2.768 \t error(train):78.1% \t error(val):78.2%\n",
      "iter:2166 \t Loss:2.766 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2167 \t Loss:2.766 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2168 \t Loss:2.765 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2169 \t Loss:2.765 \t error(train):78.1% \t error(val):78.2%\n",
      "iter:2170 \t Loss:2.764 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2171 \t Loss:2.764 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2172 \t Loss:2.763 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2173 \t Loss:2.761 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2174 \t Loss:2.761 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2175 \t Loss:2.760 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2176 \t Loss:2.760 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2177 \t Loss:2.759 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2178 \t Loss:2.759 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2179 \t Loss:2.758 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2180 \t Loss:2.758 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2181 \t Loss:2.757 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2182 \t Loss:2.756 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2183 \t Loss:2.756 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2184 \t Loss:2.755 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2185 \t Loss:2.755 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2186 \t Loss:2.754 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2187 \t Loss:2.754 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2188 \t Loss:2.753 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2189 \t Loss:2.753 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2190 \t Loss:2.752 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2191 \t Loss:2.751 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2192 \t Loss:2.751 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2193 \t Loss:2.751 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2194 \t Loss:2.750 \t error(train):78.3% \t error(val):78.1%\n",
      "iter:2195 \t Loss:2.749 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2196 \t Loss:2.749 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2197 \t Loss:2.747 \t error(train):78.2% \t error(val):78.1%\n",
      "iter:2198 \t Loss:2.747 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2199 \t Loss:2.746 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2200 \t Loss:2.745 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2201 \t Loss:2.744 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2202 \t Loss:2.744 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2203 \t Loss:2.744 \t error(train):78.2% \t error(val):78.2%\n",
      "iter:2204 \t Loss:2.743 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2205 \t Loss:2.742 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2206 \t Loss:2.742 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2207 \t Loss:2.741 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2208 \t Loss:2.740 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2209 \t Loss:2.740 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2210 \t Loss:2.739 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2211 \t Loss:2.738 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2212 \t Loss:2.738 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2213 \t Loss:2.737 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2214 \t Loss:2.736 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2215 \t Loss:2.735 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2216 \t Loss:2.735 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2217 \t Loss:2.734 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2218 \t Loss:2.734 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2219 \t Loss:2.733 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2220 \t Loss:2.733 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2221 \t Loss:2.732 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2222 \t Loss:2.732 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2223 \t Loss:2.731 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2224 \t Loss:2.731 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2225 \t Loss:2.730 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2226 \t Loss:2.729 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2227 \t Loss:2.729 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2228 \t Loss:2.729 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2229 \t Loss:2.728 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2230 \t Loss:2.728 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2231 \t Loss:2.727 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2232 \t Loss:2.727 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2233 \t Loss:2.726 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2234 \t Loss:2.726 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2235 \t Loss:2.725 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2236 \t Loss:2.724 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2237 \t Loss:2.723 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2238 \t Loss:2.723 \t error(train):78.3% \t error(val):78.3%\n",
      "iter:2239 \t Loss:2.723 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2240 \t Loss:2.722 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2241 \t Loss:2.721 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2242 \t Loss:2.721 \t error(train):78.4% \t error(val):78.4%\n",
      "iter:2243 \t Loss:2.720 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2244 \t Loss:2.719 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2245 \t Loss:2.719 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2246 \t Loss:2.718 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2247 \t Loss:2.718 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2248 \t Loss:2.717 \t error(train):78.3% \t error(val):78.2%\n",
      "iter:2249 \t Loss:2.717 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2250 \t Loss:2.716 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2251 \t Loss:2.716 \t error(train):78.4% \t error(val):78.4%\n",
      "iter:2252 \t Loss:2.714 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2253 \t Loss:2.713 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2254 \t Loss:2.713 \t error(train):78.4% \t error(val):78.4%\n",
      "iter:2255 \t Loss:2.712 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2256 \t Loss:2.711 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2257 \t Loss:2.711 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2258 \t Loss:2.710 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2259 \t Loss:2.710 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2260 \t Loss:2.709 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2261 \t Loss:2.708 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2262 \t Loss:2.708 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2263 \t Loss:2.707 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2264 \t Loss:2.707 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2265 \t Loss:2.706 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2266 \t Loss:2.706 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2267 \t Loss:2.705 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2268 \t Loss:2.705 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2269 \t Loss:2.704 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2270 \t Loss:2.704 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2271 \t Loss:2.703 \t error(train):78.4% \t error(val):78.2%\n",
      "iter:2272 \t Loss:2.703 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2273 \t Loss:2.703 \t error(train):78.4% \t error(val):78.2%\n",
      "iter:2274 \t Loss:2.702 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2275 \t Loss:2.701 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2276 \t Loss:2.701 \t error(train):78.4% \t error(val):78.2%\n",
      "iter:2277 \t Loss:2.700 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2278 \t Loss:2.699 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2279 \t Loss:2.699 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2280 \t Loss:2.699 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2281 \t Loss:2.698 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2282 \t Loss:2.697 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2283 \t Loss:2.697 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2284 \t Loss:2.696 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2285 \t Loss:2.695 \t error(train):78.4% \t error(val):78.3%\n",
      "iter:2286 \t Loss:2.695 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2287 \t Loss:2.694 \t error(train):78.4% \t error(val):78.2%\n",
      "iter:2288 \t Loss:2.694 \t error(train):78.4% \t error(val):78.4%\n",
      "iter:2289 \t Loss:2.693 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2290 \t Loss:2.692 \t error(train):78.5% \t error(val):78.2%\n",
      "iter:2291 \t Loss:2.691 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2292 \t Loss:2.691 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2293 \t Loss:2.690 \t error(train):78.5% \t error(val):78.2%\n",
      "iter:2294 \t Loss:2.689 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2295 \t Loss:2.689 \t error(train):78.5% \t error(val):78.2%\n",
      "iter:2296 \t Loss:2.688 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2297 \t Loss:2.688 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2298 \t Loss:2.687 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2299 \t Loss:2.687 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2300 \t Loss:2.687 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2301 \t Loss:2.686 \t error(train):78.5% \t error(val):78.2%\n",
      "iter:2302 \t Loss:2.686 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2303 \t Loss:2.685 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2304 \t Loss:2.685 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2305 \t Loss:2.683 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2306 \t Loss:2.683 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2307 \t Loss:2.682 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2308 \t Loss:2.681 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2309 \t Loss:2.680 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2310 \t Loss:2.680 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2311 \t Loss:2.679 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2312 \t Loss:2.679 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2313 \t Loss:2.678 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2314 \t Loss:2.678 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2315 \t Loss:2.677 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2316 \t Loss:2.677 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2317 \t Loss:2.676 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2318 \t Loss:2.676 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2319 \t Loss:2.675 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2320 \t Loss:2.674 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2321 \t Loss:2.674 \t error(train):78.5% \t error(val):78.4%\n",
      "iter:2322 \t Loss:2.674 \t error(train):78.5% \t error(val):78.3%\n",
      "iter:2323 \t Loss:2.673 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2324 \t Loss:2.673 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2325 \t Loss:2.672 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2326 \t Loss:2.672 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2327 \t Loss:2.671 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2328 \t Loss:2.671 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2329 \t Loss:2.670 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2330 \t Loss:2.669 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2331 \t Loss:2.669 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2332 \t Loss:2.668 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2333 \t Loss:2.668 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2334 \t Loss:2.667 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2335 \t Loss:2.667 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2336 \t Loss:2.666 \t error(train):78.6% \t error(val):78.5%\n",
      "iter:2337 \t Loss:2.665 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2338 \t Loss:2.665 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2339 \t Loss:2.664 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2340 \t Loss:2.664 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2341 \t Loss:2.663 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2342 \t Loss:2.663 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2343 \t Loss:2.662 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2344 \t Loss:2.661 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2345 \t Loss:2.660 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2346 \t Loss:2.660 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2347 \t Loss:2.659 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2348 \t Loss:2.659 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2349 \t Loss:2.658 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2350 \t Loss:2.658 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2351 \t Loss:2.657 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2352 \t Loss:2.657 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2353 \t Loss:2.656 \t error(train):78.6% \t error(val):78.3%\n",
      "iter:2354 \t Loss:2.656 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2355 \t Loss:2.655 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2356 \t Loss:2.654 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2357 \t Loss:2.653 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2358 \t Loss:2.653 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2359 \t Loss:2.652 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2360 \t Loss:2.652 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2361 \t Loss:2.651 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2362 \t Loss:2.651 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2363 \t Loss:2.650 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2364 \t Loss:2.650 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2365 \t Loss:2.650 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2366 \t Loss:2.649 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2367 \t Loss:2.649 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2368 \t Loss:2.648 \t error(train):78.6% \t error(val):78.4%\n",
      "iter:2369 \t Loss:2.648 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2370 \t Loss:2.646 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2371 \t Loss:2.646 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2372 \t Loss:2.645 \t error(train):78.7% \t error(val):78.6%\n",
      "iter:2373 \t Loss:2.644 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2374 \t Loss:2.643 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2375 \t Loss:2.643 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2376 \t Loss:2.642 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2377 \t Loss:2.642 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2378 \t Loss:2.642 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2379 \t Loss:2.641 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2380 \t Loss:2.641 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2381 \t Loss:2.640 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2382 \t Loss:2.640 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2383 \t Loss:2.639 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2384 \t Loss:2.639 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2385 \t Loss:2.637 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2386 \t Loss:2.637 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2387 \t Loss:2.637 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2388 \t Loss:2.636 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2389 \t Loss:2.636 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2390 \t Loss:2.635 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2391 \t Loss:2.635 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2392 \t Loss:2.633 \t error(train):78.7% \t error(val):78.4%\n",
      "iter:2393 \t Loss:2.632 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2394 \t Loss:2.632 \t error(train):78.8% \t error(val):78.4%\n",
      "iter:2395 \t Loss:2.631 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2396 \t Loss:2.631 \t error(train):78.8% \t error(val):78.4%\n",
      "iter:2397 \t Loss:2.630 \t error(train):78.7% \t error(val):78.5%\n",
      "iter:2398 \t Loss:2.630 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2399 \t Loss:2.629 \t error(train):78.8% \t error(val):78.4%\n",
      "iter:2400 \t Loss:2.628 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2401 \t Loss:2.628 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2402 \t Loss:2.627 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2403 \t Loss:2.627 \t error(train):78.7% \t error(val):78.6%\n",
      "iter:2404 \t Loss:2.626 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2405 \t Loss:2.626 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2406 \t Loss:2.625 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2407 \t Loss:2.624 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2408 \t Loss:2.624 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2409 \t Loss:2.623 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2410 \t Loss:2.623 \t error(train):78.8% \t error(val):78.4%\n",
      "iter:2411 \t Loss:2.622 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2412 \t Loss:2.622 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2413 \t Loss:2.622 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2414 \t Loss:2.620 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2415 \t Loss:2.620 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2416 \t Loss:2.619 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2417 \t Loss:2.619 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2418 \t Loss:2.618 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2419 \t Loss:2.618 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2420 \t Loss:2.617 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2421 \t Loss:2.617 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2422 \t Loss:2.616 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2423 \t Loss:2.616 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2424 \t Loss:2.615 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2425 \t Loss:2.615 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2426 \t Loss:2.614 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2427 \t Loss:2.614 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2428 \t Loss:2.614 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2429 \t Loss:2.613 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2430 \t Loss:2.613 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2431 \t Loss:2.612 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2432 \t Loss:2.612 \t error(train):78.8% \t error(val):78.5%\n",
      "iter:2433 \t Loss:2.611 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2434 \t Loss:2.611 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2435 \t Loss:2.610 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2436 \t Loss:2.609 \t error(train):78.8% \t error(val):78.6%\n",
      "iter:2437 \t Loss:2.609 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2438 \t Loss:2.608 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2439 \t Loss:2.608 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2440 \t Loss:2.607 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2441 \t Loss:2.607 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2442 \t Loss:2.606 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2443 \t Loss:2.605 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2444 \t Loss:2.605 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2445 \t Loss:2.604 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2446 \t Loss:2.604 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2447 \t Loss:2.603 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2448 \t Loss:2.603 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2449 \t Loss:2.602 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2450 \t Loss:2.601 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2451 \t Loss:2.601 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2452 \t Loss:2.600 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2453 \t Loss:2.600 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2454 \t Loss:2.599 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2455 \t Loss:2.599 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2456 \t Loss:2.598 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2457 \t Loss:2.598 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2458 \t Loss:2.598 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2459 \t Loss:2.597 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2460 \t Loss:2.596 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2461 \t Loss:2.596 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2462 \t Loss:2.594 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2463 \t Loss:2.594 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2464 \t Loss:2.594 \t error(train):78.9% \t error(val):78.6%\n",
      "iter:2465 \t Loss:2.593 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2466 \t Loss:2.592 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2467 \t Loss:2.592 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2468 \t Loss:2.592 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2469 \t Loss:2.591 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2470 \t Loss:2.591 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2471 \t Loss:2.590 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2472 \t Loss:2.589 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2473 \t Loss:2.589 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2474 \t Loss:2.588 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2475 \t Loss:2.588 \t error(train):78.9% \t error(val):78.7%\n",
      "iter:2476 \t Loss:2.587 \t error(train):78.9% \t error(val):78.8%\n",
      "iter:2477 \t Loss:2.587 \t error(train):78.9% \t error(val):78.8%\n",
      "iter:2478 \t Loss:2.586 \t error(train):78.9% \t error(val):78.8%\n",
      "iter:2479 \t Loss:2.585 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2480 \t Loss:2.585 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2481 \t Loss:2.584 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2482 \t Loss:2.584 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2483 \t Loss:2.583 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2484 \t Loss:2.583 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2485 \t Loss:2.582 \t error(train):79.0% \t error(val):78.7%\n",
      "iter:2486 \t Loss:2.582 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2487 \t Loss:2.582 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2488 \t Loss:2.581 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2489 \t Loss:2.580 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2490 \t Loss:2.580 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2491 \t Loss:2.579 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2492 \t Loss:2.578 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2493 \t Loss:2.578 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2494 \t Loss:2.577 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2495 \t Loss:2.577 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2496 \t Loss:2.576 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2497 \t Loss:2.576 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2498 \t Loss:2.575 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2499 \t Loss:2.575 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2500 \t Loss:2.575 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2501 \t Loss:2.574 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2502 \t Loss:2.574 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2503 \t Loss:2.573 \t error(train):79.0% \t error(val):78.9%\n",
      "iter:2504 \t Loss:2.573 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2505 \t Loss:2.572 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2506 \t Loss:2.572 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2507 \t Loss:2.571 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2508 \t Loss:2.571 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2509 \t Loss:2.570 \t error(train):79.0% \t error(val):78.9%\n",
      "iter:2510 \t Loss:2.570 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2511 \t Loss:2.570 \t error(train):79.0% \t error(val):78.9%\n",
      "iter:2512 \t Loss:2.569 \t error(train):79.0% \t error(val):78.8%\n",
      "iter:2513 \t Loss:2.569 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2514 \t Loss:2.568 \t error(train):79.0% \t error(val):78.9%\n",
      "iter:2515 \t Loss:2.568 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2516 \t Loss:2.568 \t error(train):79.1% \t error(val):78.8%\n",
      "iter:2517 \t Loss:2.566 \t error(train):79.0% \t error(val):78.9%\n",
      "iter:2518 \t Loss:2.566 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2519 \t Loss:2.565 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2520 \t Loss:2.564 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2521 \t Loss:2.564 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2522 \t Loss:2.563 \t error(train):79.1% \t error(val):78.8%\n",
      "iter:2523 \t Loss:2.563 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2524 \t Loss:2.562 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2525 \t Loss:2.562 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2526 \t Loss:2.561 \t error(train):79.1% \t error(val):78.8%\n",
      "iter:2527 \t Loss:2.561 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2528 \t Loss:2.560 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2529 \t Loss:2.560 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2530 \t Loss:2.559 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2531 \t Loss:2.559 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2532 \t Loss:2.558 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2533 \t Loss:2.558 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2534 \t Loss:2.558 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2535 \t Loss:2.557 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2536 \t Loss:2.557 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2537 \t Loss:2.556 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2538 \t Loss:2.556 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2539 \t Loss:2.555 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2540 \t Loss:2.555 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2541 \t Loss:2.555 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2542 \t Loss:2.554 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2543 \t Loss:2.553 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2544 \t Loss:2.553 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2545 \t Loss:2.552 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2546 \t Loss:2.552 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2547 \t Loss:2.551 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2548 \t Loss:2.551 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2549 \t Loss:2.550 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2550 \t Loss:2.549 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2551 \t Loss:2.549 \t error(train):79.1% \t error(val):78.9%\n",
      "iter:2552 \t Loss:2.549 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2553 \t Loss:2.548 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2554 \t Loss:2.548 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2555 \t Loss:2.547 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2556 \t Loss:2.546 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2557 \t Loss:2.546 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2558 \t Loss:2.545 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2559 \t Loss:2.545 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2560 \t Loss:2.544 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2561 \t Loss:2.544 \t error(train):79.1% \t error(val):79.0%\n",
      "iter:2562 \t Loss:2.543 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2563 \t Loss:2.543 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2564 \t Loss:2.543 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2565 \t Loss:2.542 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2566 \t Loss:2.542 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2567 \t Loss:2.542 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2568 \t Loss:2.541 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2569 \t Loss:2.541 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2570 \t Loss:2.540 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2571 \t Loss:2.540 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2572 \t Loss:2.539 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2573 \t Loss:2.539 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2574 \t Loss:2.539 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2575 \t Loss:2.537 \t error(train):79.2% \t error(val):78.9%\n",
      "iter:2576 \t Loss:2.536 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2577 \t Loss:2.536 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2578 \t Loss:2.535 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2579 \t Loss:2.535 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2580 \t Loss:2.535 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2581 \t Loss:2.534 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2582 \t Loss:2.533 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2583 \t Loss:2.532 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2584 \t Loss:2.532 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2585 \t Loss:2.531 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2586 \t Loss:2.530 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2587 \t Loss:2.530 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2588 \t Loss:2.529 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2589 \t Loss:2.529 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2590 \t Loss:2.529 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2591 \t Loss:2.528 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2592 \t Loss:2.528 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2593 \t Loss:2.527 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2594 \t Loss:2.527 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2595 \t Loss:2.527 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2596 \t Loss:2.526 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2597 \t Loss:2.525 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2598 \t Loss:2.525 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2599 \t Loss:2.524 \t error(train):79.2% \t error(val):79.0%\n",
      "iter:2600 \t Loss:2.524 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2601 \t Loss:2.523 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2602 \t Loss:2.523 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2603 \t Loss:2.523 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2604 \t Loss:2.521 \t error(train):79.2% \t error(val):79.1%\n",
      "iter:2605 \t Loss:2.518 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2606 \t Loss:2.517 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2607 \t Loss:2.516 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2608 \t Loss:2.516 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2609 \t Loss:2.514 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2610 \t Loss:2.514 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2611 \t Loss:2.514 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2612 \t Loss:2.513 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2613 \t Loss:2.512 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2614 \t Loss:2.512 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2615 \t Loss:2.512 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2616 \t Loss:2.511 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2617 \t Loss:2.511 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2618 \t Loss:2.510 \t error(train):79.4% \t error(val):79.2%\n",
      "iter:2619 \t Loss:2.510 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2620 \t Loss:2.509 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2621 \t Loss:2.509 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2622 \t Loss:2.508 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2623 \t Loss:2.508 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2624 \t Loss:2.507 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2625 \t Loss:2.507 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2626 \t Loss:2.506 \t error(train):79.3% \t error(val):79.0%\n",
      "iter:2627 \t Loss:2.505 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2628 \t Loss:2.505 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2629 \t Loss:2.505 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2630 \t Loss:2.504 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2631 \t Loss:2.504 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2632 \t Loss:2.503 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2633 \t Loss:2.503 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2634 \t Loss:2.502 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2635 \t Loss:2.502 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2636 \t Loss:2.502 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2637 \t Loss:2.501 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2638 \t Loss:2.501 \t error(train):79.3% \t error(val):79.1%\n",
      "iter:2639 \t Loss:2.500 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2640 \t Loss:2.500 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2641 \t Loss:2.499 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2642 \t Loss:2.499 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2643 \t Loss:2.499 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2644 \t Loss:2.498 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2645 \t Loss:2.498 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2646 \t Loss:2.497 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2647 \t Loss:2.497 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2648 \t Loss:2.496 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2649 \t Loss:2.496 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2650 \t Loss:2.496 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2651 \t Loss:2.495 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2652 \t Loss:2.495 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2653 \t Loss:2.494 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2654 \t Loss:2.494 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2655 \t Loss:2.493 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2656 \t Loss:2.493 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2657 \t Loss:2.493 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2658 \t Loss:2.492 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2659 \t Loss:2.492 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2660 \t Loss:2.491 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2661 \t Loss:2.491 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2662 \t Loss:2.490 \t error(train):79.4% \t error(val):79.2%\n",
      "iter:2663 \t Loss:2.490 \t error(train):79.4% \t error(val):79.2%\n",
      "iter:2664 \t Loss:2.490 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2665 \t Loss:2.489 \t error(train):79.4% \t error(val):79.2%\n",
      "iter:2666 \t Loss:2.489 \t error(train):79.4% \t error(val):79.2%\n",
      "iter:2667 \t Loss:2.488 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2668 \t Loss:2.488 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2669 \t Loss:2.488 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2670 \t Loss:2.487 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2671 \t Loss:2.487 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2672 \t Loss:2.487 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2673 \t Loss:2.486 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2674 \t Loss:2.486 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2675 \t Loss:2.485 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2676 \t Loss:2.485 \t error(train):79.4% \t error(val):79.1%\n",
      "iter:2677 \t Loss:2.485 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2678 \t Loss:2.484 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2679 \t Loss:2.484 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2680 \t Loss:2.484 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2681 \t Loss:2.482 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2682 \t Loss:2.482 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2683 \t Loss:2.481 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2684 \t Loss:2.481 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2685 \t Loss:2.480 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2686 \t Loss:2.480 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2687 \t Loss:2.480 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2688 \t Loss:2.479 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2689 \t Loss:2.478 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2690 \t Loss:2.478 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2691 \t Loss:2.477 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2692 \t Loss:2.477 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2693 \t Loss:2.477 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2694 \t Loss:2.476 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2695 \t Loss:2.476 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2696 \t Loss:2.475 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2697 \t Loss:2.474 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2698 \t Loss:2.474 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2699 \t Loss:2.474 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2700 \t Loss:2.473 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2701 \t Loss:2.473 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2702 \t Loss:2.472 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2703 \t Loss:2.471 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2704 \t Loss:2.471 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2705 \t Loss:2.471 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2706 \t Loss:2.470 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2707 \t Loss:2.470 \t error(train):79.5% \t error(val):79.3%\n",
      "iter:2708 \t Loss:2.469 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2709 \t Loss:2.469 \t error(train):79.5% \t error(val):79.2%\n",
      "iter:2710 \t Loss:2.469 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2711 \t Loss:2.468 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2712 \t Loss:2.468 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2713 \t Loss:2.467 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2714 \t Loss:2.467 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2715 \t Loss:2.466 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2716 \t Loss:2.465 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2717 \t Loss:2.465 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2718 \t Loss:2.464 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2719 \t Loss:2.464 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2720 \t Loss:2.464 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2721 \t Loss:2.463 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2722 \t Loss:2.463 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2723 \t Loss:2.463 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2724 \t Loss:2.462 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2725 \t Loss:2.462 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2726 \t Loss:2.462 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2727 \t Loss:2.461 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2728 \t Loss:2.461 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2729 \t Loss:2.460 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2730 \t Loss:2.460 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2731 \t Loss:2.460 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2732 \t Loss:2.459 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2733 \t Loss:2.459 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2734 \t Loss:2.458 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2735 \t Loss:2.458 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2736 \t Loss:2.458 \t error(train):79.6% \t error(val):79.3%\n",
      "iter:2737 \t Loss:2.457 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2738 \t Loss:2.457 \t error(train):79.7% \t error(val):79.4%\n",
      "iter:2739 \t Loss:2.456 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2740 \t Loss:2.456 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2741 \t Loss:2.455 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2742 \t Loss:2.455 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2743 \t Loss:2.455 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2744 \t Loss:2.454 \t error(train):79.6% \t error(val):79.5%\n",
      "iter:2745 \t Loss:2.454 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2746 \t Loss:2.454 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2747 \t Loss:2.453 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2748 \t Loss:2.453 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2749 \t Loss:2.452 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2750 \t Loss:2.452 \t error(train):79.6% \t error(val):79.5%\n",
      "iter:2751 \t Loss:2.451 \t error(train):79.6% \t error(val):79.5%\n",
      "iter:2752 \t Loss:2.451 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2753 \t Loss:2.451 \t error(train):79.7% \t error(val):79.4%\n",
      "iter:2754 \t Loss:2.450 \t error(train):79.6% \t error(val):79.4%\n",
      "iter:2755 \t Loss:2.450 \t error(train):79.6% \t error(val):79.5%\n",
      "iter:2756 \t Loss:2.449 \t error(train):79.6% \t error(val):79.5%\n",
      "iter:2757 \t Loss:2.449 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2758 \t Loss:2.449 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2759 \t Loss:2.448 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2760 \t Loss:2.448 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2761 \t Loss:2.447 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2762 \t Loss:2.447 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2763 \t Loss:2.447 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2764 \t Loss:2.446 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2765 \t Loss:2.446 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2766 \t Loss:2.446 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2767 \t Loss:2.445 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2768 \t Loss:2.445 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2769 \t Loss:2.445 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2770 \t Loss:2.443 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2771 \t Loss:2.443 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2772 \t Loss:2.443 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2773 \t Loss:2.442 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2774 \t Loss:2.441 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2775 \t Loss:2.441 \t error(train):79.7% \t error(val):79.5%\n",
      "iter:2776 \t Loss:2.440 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2777 \t Loss:2.440 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2778 \t Loss:2.440 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2779 \t Loss:2.439 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2780 \t Loss:2.439 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2781 \t Loss:2.438 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2782 \t Loss:2.438 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2783 \t Loss:2.438 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2784 \t Loss:2.437 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2785 \t Loss:2.437 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2786 \t Loss:2.436 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2787 \t Loss:2.436 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2788 \t Loss:2.436 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2789 \t Loss:2.435 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2790 \t Loss:2.435 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2791 \t Loss:2.435 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2792 \t Loss:2.434 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2793 \t Loss:2.434 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2794 \t Loss:2.433 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2795 \t Loss:2.433 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2796 \t Loss:2.432 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2797 \t Loss:2.432 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2798 \t Loss:2.432 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2799 \t Loss:2.431 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2800 \t Loss:2.431 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2801 \t Loss:2.430 \t error(train):79.7% \t error(val):79.6%\n",
      "iter:2802 \t Loss:2.429 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2803 \t Loss:2.429 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2804 \t Loss:2.429 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2805 \t Loss:2.428 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2806 \t Loss:2.428 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2807 \t Loss:2.427 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2808 \t Loss:2.427 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2809 \t Loss:2.426 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2810 \t Loss:2.426 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2811 \t Loss:2.425 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2812 \t Loss:2.425 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2813 \t Loss:2.424 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2814 \t Loss:2.424 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2815 \t Loss:2.424 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2816 \t Loss:2.423 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2817 \t Loss:2.423 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2818 \t Loss:2.423 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2819 \t Loss:2.422 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2820 \t Loss:2.422 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2821 \t Loss:2.421 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2822 \t Loss:2.421 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2823 \t Loss:2.421 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2824 \t Loss:2.421 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2825 \t Loss:2.420 \t error(train):79.7% \t error(val):79.7%\n",
      "iter:2826 \t Loss:2.420 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2827 \t Loss:2.419 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2828 \t Loss:2.418 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2829 \t Loss:2.417 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2830 \t Loss:2.417 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2831 \t Loss:2.417 \t error(train):79.7% \t error(val):79.8%\n",
      "iter:2832 \t Loss:2.416 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2833 \t Loss:2.416 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2834 \t Loss:2.416 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2835 \t Loss:2.415 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2836 \t Loss:2.415 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2837 \t Loss:2.415 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2838 \t Loss:2.414 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2839 \t Loss:2.414 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2840 \t Loss:2.414 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2841 \t Loss:2.413 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2842 \t Loss:2.413 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2843 \t Loss:2.413 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2844 \t Loss:2.412 \t error(train):79.8% \t error(val):79.7%\n",
      "iter:2845 \t Loss:2.412 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2846 \t Loss:2.412 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2847 \t Loss:2.411 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2848 \t Loss:2.410 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2849 \t Loss:2.410 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2850 \t Loss:2.410 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2851 \t Loss:2.409 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2852 \t Loss:2.409 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2853 \t Loss:2.409 \t error(train):79.8% \t error(val):79.9%\n",
      "iter:2854 \t Loss:2.408 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2855 \t Loss:2.407 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2856 \t Loss:2.407 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2857 \t Loss:2.407 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2858 \t Loss:2.406 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2859 \t Loss:2.406 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2860 \t Loss:2.405 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2861 \t Loss:2.405 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2862 \t Loss:2.404 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2863 \t Loss:2.404 \t error(train):79.8% \t error(val):79.8%\n",
      "iter:2864 \t Loss:2.403 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2865 \t Loss:2.403 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2866 \t Loss:2.402 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2867 \t Loss:2.402 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2868 \t Loss:2.401 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2869 \t Loss:2.401 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2870 \t Loss:2.401 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2871 \t Loss:2.400 \t error(train):79.9% \t error(val):79.8%\n",
      "iter:2872 \t Loss:2.400 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2873 \t Loss:2.399 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2874 \t Loss:2.399 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2875 \t Loss:2.399 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2876 \t Loss:2.398 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2877 \t Loss:2.398 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2878 \t Loss:2.397 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2879 \t Loss:2.396 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2880 \t Loss:2.396 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2881 \t Loss:2.396 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2882 \t Loss:2.395 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2883 \t Loss:2.395 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2884 \t Loss:2.394 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2885 \t Loss:2.394 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2886 \t Loss:2.394 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2887 \t Loss:2.394 \t error(train):79.9% \t error(val):79.9%\n",
      "iter:2888 \t Loss:2.393 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2889 \t Loss:2.393 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2890 \t Loss:2.392 \t error(train):80.0% \t error(val):79.9%\n",
      "iter:2891 \t Loss:2.391 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2892 \t Loss:2.391 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2893 \t Loss:2.391 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2894 \t Loss:2.390 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2895 \t Loss:2.390 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2896 \t Loss:2.389 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2897 \t Loss:2.389 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2898 \t Loss:2.389 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2899 \t Loss:2.389 \t error(train):80.0% \t error(val):79.9%\n",
      "iter:2900 \t Loss:2.388 \t error(train):79.9% \t error(val):80.1%\n",
      "iter:2901 \t Loss:2.388 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2902 \t Loss:2.387 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2903 \t Loss:2.386 \t error(train):79.9% \t error(val):80.0%\n",
      "iter:2904 \t Loss:2.386 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2905 \t Loss:2.386 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2906 \t Loss:2.385 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2907 \t Loss:2.385 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2908 \t Loss:2.384 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2909 \t Loss:2.384 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2910 \t Loss:2.384 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2911 \t Loss:2.384 \t error(train):80.0% \t error(val):79.9%\n",
      "iter:2912 \t Loss:2.383 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2913 \t Loss:2.383 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2914 \t Loss:2.382 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2915 \t Loss:2.381 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2916 \t Loss:2.381 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2917 \t Loss:2.381 \t error(train):80.0% \t error(val):79.9%\n",
      "iter:2918 \t Loss:2.380 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2919 \t Loss:2.379 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2920 \t Loss:2.379 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2921 \t Loss:2.379 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2922 \t Loss:2.378 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2923 \t Loss:2.378 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2924 \t Loss:2.378 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2925 \t Loss:2.377 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2926 \t Loss:2.377 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2927 \t Loss:2.376 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2928 \t Loss:2.376 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2929 \t Loss:2.375 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2930 \t Loss:2.375 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2931 \t Loss:2.375 \t error(train):80.0% \t error(val):80.0%\n",
      "iter:2932 \t Loss:2.374 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2933 \t Loss:2.374 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2934 \t Loss:2.373 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2935 \t Loss:2.373 \t error(train):80.0% \t error(val):80.1%\n",
      "iter:2936 \t Loss:2.372 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2937 \t Loss:2.372 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2938 \t Loss:2.372 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2939 \t Loss:2.371 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2940 \t Loss:2.371 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2941 \t Loss:2.371 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2942 \t Loss:2.370 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2943 \t Loss:2.370 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2944 \t Loss:2.369 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2945 \t Loss:2.369 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2946 \t Loss:2.369 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2947 \t Loss:2.368 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2948 \t Loss:2.368 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2949 \t Loss:2.368 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2950 \t Loss:2.367 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2951 \t Loss:2.367 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2952 \t Loss:2.367 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2953 \t Loss:2.366 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2954 \t Loss:2.366 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2955 \t Loss:2.366 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2956 \t Loss:2.365 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2957 \t Loss:2.365 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2958 \t Loss:2.365 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2959 \t Loss:2.364 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2960 \t Loss:2.364 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2961 \t Loss:2.363 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2962 \t Loss:2.363 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2963 \t Loss:2.363 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2964 \t Loss:2.363 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2965 \t Loss:2.362 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2966 \t Loss:2.362 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2967 \t Loss:2.362 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2968 \t Loss:2.361 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2969 \t Loss:2.361 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2970 \t Loss:2.361 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2971 \t Loss:2.360 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2972 \t Loss:2.360 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2973 \t Loss:2.360 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2974 \t Loss:2.359 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2975 \t Loss:2.358 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2976 \t Loss:2.357 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2977 \t Loss:2.357 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2978 \t Loss:2.357 \t error(train):80.1% \t error(val):80.1%\n",
      "iter:2979 \t Loss:2.356 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2980 \t Loss:2.356 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2981 \t Loss:2.356 \t error(train):80.1% \t error(val):80.0%\n",
      "iter:2982 \t Loss:2.355 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2983 \t Loss:2.354 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2984 \t Loss:2.354 \t error(train):80.2% \t error(val):80.0%\n",
      "iter:2985 \t Loss:2.353 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2986 \t Loss:2.353 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2987 \t Loss:2.352 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2988 \t Loss:2.352 \t error(train):80.2% \t error(val):80.0%\n",
      "iter:2989 \t Loss:2.352 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2990 \t Loss:2.351 \t error(train):80.2% \t error(val):80.2%\n",
      "iter:2991 \t Loss:2.351 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2992 \t Loss:2.350 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2993 \t Loss:2.349 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2994 \t Loss:2.349 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2995 \t Loss:2.348 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2996 \t Loss:2.348 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2997 \t Loss:2.347 \t error(train):80.2% \t error(val):80.2%\n",
      "iter:2998 \t Loss:2.347 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:2999 \t Loss:2.347 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3000 \t Loss:2.346 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3001 \t Loss:2.346 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3002 \t Loss:2.345 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3003 \t Loss:2.345 \t error(train):80.2% \t error(val):80.2%\n",
      "iter:3004 \t Loss:2.345 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3005 \t Loss:2.345 \t error(train):80.2% \t error(val):80.2%\n",
      "iter:3006 \t Loss:2.344 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3007 \t Loss:2.344 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3008 \t Loss:2.344 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3009 \t Loss:2.343 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3010 \t Loss:2.343 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3011 \t Loss:2.342 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3012 \t Loss:2.342 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3013 \t Loss:2.341 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3014 \t Loss:2.340 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3015 \t Loss:2.340 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3016 \t Loss:2.340 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3017 \t Loss:2.339 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3018 \t Loss:2.339 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3019 \t Loss:2.339 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3020 \t Loss:2.338 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3021 \t Loss:2.338 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3022 \t Loss:2.338 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3023 \t Loss:2.337 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3024 \t Loss:2.337 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3025 \t Loss:2.336 \t error(train):80.2% \t error(val):80.2%\n",
      "iter:3026 \t Loss:2.336 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3027 \t Loss:2.336 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3028 \t Loss:2.335 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3029 \t Loss:2.335 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3030 \t Loss:2.335 \t error(train):80.3% \t error(val):80.2%\n",
      "iter:3031 \t Loss:2.334 \t error(train):80.3% \t error(val):80.2%\n",
      "iter:3032 \t Loss:2.334 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3033 \t Loss:2.333 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3034 \t Loss:2.333 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3035 \t Loss:2.333 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3036 \t Loss:2.332 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3037 \t Loss:2.332 \t error(train):80.2% \t error(val):80.1%\n",
      "iter:3038 \t Loss:2.331 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3039 \t Loss:2.331 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3040 \t Loss:2.330 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3041 \t Loss:2.330 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3042 \t Loss:2.330 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3043 \t Loss:2.329 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3044 \t Loss:2.329 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3045 \t Loss:2.329 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3046 \t Loss:2.328 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3047 \t Loss:2.328 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3048 \t Loss:2.328 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3049 \t Loss:2.327 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3050 \t Loss:2.326 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3051 \t Loss:2.326 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3052 \t Loss:2.326 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3053 \t Loss:2.325 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3054 \t Loss:2.325 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3055 \t Loss:2.325 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3056 \t Loss:2.324 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3057 \t Loss:2.324 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3058 \t Loss:2.324 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3059 \t Loss:2.323 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3060 \t Loss:2.323 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3061 \t Loss:2.323 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3062 \t Loss:2.322 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3063 \t Loss:2.321 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3064 \t Loss:2.321 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3065 \t Loss:2.321 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3066 \t Loss:2.320 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3067 \t Loss:2.320 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3068 \t Loss:2.320 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3069 \t Loss:2.319 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3070 \t Loss:2.319 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3071 \t Loss:2.319 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3072 \t Loss:2.318 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3073 \t Loss:2.317 \t error(train):80.3% \t error(val):80.1%\n",
      "iter:3074 \t Loss:2.317 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3075 \t Loss:2.317 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3076 \t Loss:2.316 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3077 \t Loss:2.316 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3078 \t Loss:2.316 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3079 \t Loss:2.315 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3080 \t Loss:2.315 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3081 \t Loss:2.314 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3082 \t Loss:2.314 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3083 \t Loss:2.314 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3084 \t Loss:2.313 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3085 \t Loss:2.313 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3086 \t Loss:2.313 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3087 \t Loss:2.312 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3088 \t Loss:2.312 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3089 \t Loss:2.312 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3090 \t Loss:2.311 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3091 \t Loss:2.310 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3092 \t Loss:2.310 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3093 \t Loss:2.310 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3094 \t Loss:2.309 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3095 \t Loss:2.309 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3096 \t Loss:2.309 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3097 \t Loss:2.309 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3098 \t Loss:2.308 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3099 \t Loss:2.308 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3100 \t Loss:2.308 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3101 \t Loss:2.307 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3102 \t Loss:2.307 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3103 \t Loss:2.306 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3104 \t Loss:2.306 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3105 \t Loss:2.306 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3106 \t Loss:2.306 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3107 \t Loss:2.305 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3108 \t Loss:2.305 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3109 \t Loss:2.305 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3110 \t Loss:2.304 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3111 \t Loss:2.304 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3112 \t Loss:2.304 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3113 \t Loss:2.303 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3114 \t Loss:2.303 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3115 \t Loss:2.303 \t error(train):80.4% \t error(val):80.1%\n",
      "iter:3116 \t Loss:2.303 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3117 \t Loss:2.301 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3118 \t Loss:2.301 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3119 \t Loss:2.301 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3120 \t Loss:2.300 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3121 \t Loss:2.300 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3122 \t Loss:2.299 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3123 \t Loss:2.299 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3124 \t Loss:2.299 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3125 \t Loss:2.298 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3126 \t Loss:2.298 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3127 \t Loss:2.298 \t error(train):80.4% \t error(val):80.2%\n",
      "iter:3128 \t Loss:2.297 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3129 \t Loss:2.297 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3130 \t Loss:2.297 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3131 \t Loss:2.296 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3132 \t Loss:2.296 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3133 \t Loss:2.296 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3134 \t Loss:2.296 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3135 \t Loss:2.295 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3136 \t Loss:2.295 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3137 \t Loss:2.295 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3138 \t Loss:2.294 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3139 \t Loss:2.294 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3140 \t Loss:2.294 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3141 \t Loss:2.293 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3142 \t Loss:2.293 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3143 \t Loss:2.292 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3144 \t Loss:2.292 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3145 \t Loss:2.292 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3146 \t Loss:2.291 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3147 \t Loss:2.291 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3148 \t Loss:2.291 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3149 \t Loss:2.290 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3150 \t Loss:2.290 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3151 \t Loss:2.289 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3152 \t Loss:2.289 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3153 \t Loss:2.289 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3154 \t Loss:2.288 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3155 \t Loss:2.288 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3156 \t Loss:2.287 \t error(train):80.5% \t error(val):80.2%\n",
      "iter:3157 \t Loss:2.287 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3158 \t Loss:2.287 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3159 \t Loss:2.286 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3160 \t Loss:2.286 \t error(train):80.5% \t error(val):80.3%\n",
      "iter:3161 \t Loss:2.286 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3162 \t Loss:2.285 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3163 \t Loss:2.285 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3164 \t Loss:2.285 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3165 \t Loss:2.284 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3166 \t Loss:2.284 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3167 \t Loss:2.284 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3168 \t Loss:2.284 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3169 \t Loss:2.283 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3170 \t Loss:2.283 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3171 \t Loss:2.283 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3172 \t Loss:2.282 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3173 \t Loss:2.282 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3174 \t Loss:2.282 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3175 \t Loss:2.281 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3176 \t Loss:2.280 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3177 \t Loss:2.280 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3178 \t Loss:2.280 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3179 \t Loss:2.279 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3180 \t Loss:2.279 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3181 \t Loss:2.279 \t error(train):80.5% \t error(val):80.4%\n",
      "iter:3182 \t Loss:2.278 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3183 \t Loss:2.277 \t error(train):80.6% \t error(val):80.2%\n",
      "iter:3184 \t Loss:2.277 \t error(train):80.5% \t error(val):80.4%\n",
      "iter:3185 \t Loss:2.276 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3186 \t Loss:2.276 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3187 \t Loss:2.276 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3188 \t Loss:2.275 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3189 \t Loss:2.275 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3190 \t Loss:2.275 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3191 \t Loss:2.275 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3192 \t Loss:2.274 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3193 \t Loss:2.274 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3194 \t Loss:2.274 \t error(train):80.6% \t error(val):80.4%\n",
      "iter:3195 \t Loss:2.273 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3196 \t Loss:2.273 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3197 \t Loss:2.272 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3198 \t Loss:2.272 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3199 \t Loss:2.272 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3200 \t Loss:2.271 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3201 \t Loss:2.271 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3202 \t Loss:2.270 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3203 \t Loss:2.270 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3204 \t Loss:2.270 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3205 \t Loss:2.270 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3206 \t Loss:2.269 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3207 \t Loss:2.269 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3208 \t Loss:2.269 \t error(train):80.6% \t error(val):80.4%\n",
      "iter:3209 \t Loss:2.268 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3210 \t Loss:2.268 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3211 \t Loss:2.268 \t error(train):80.6% \t error(val):80.3%\n",
      "iter:3212 \t Loss:2.267 \t error(train):80.7% \t error(val):80.3%\n",
      "iter:3213 \t Loss:2.267 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3214 \t Loss:2.267 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3215 \t Loss:2.266 \t error(train):80.6% \t error(val):80.4%\n",
      "iter:3216 \t Loss:2.266 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3217 \t Loss:2.266 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3218 \t Loss:2.265 \t error(train):80.6% \t error(val):80.4%\n",
      "iter:3219 \t Loss:2.265 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3220 \t Loss:2.264 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3221 \t Loss:2.264 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3222 \t Loss:2.264 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3223 \t Loss:2.263 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3224 \t Loss:2.263 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3225 \t Loss:2.263 \t error(train):80.6% \t error(val):80.4%\n",
      "iter:3226 \t Loss:2.262 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3227 \t Loss:2.262 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3228 \t Loss:2.261 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3229 \t Loss:2.261 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3230 \t Loss:2.261 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3231 \t Loss:2.260 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3232 \t Loss:2.260 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3233 \t Loss:2.260 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3234 \t Loss:2.260 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3235 \t Loss:2.259 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3236 \t Loss:2.259 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3237 \t Loss:2.259 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3238 \t Loss:2.258 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3239 \t Loss:2.258 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3240 \t Loss:2.258 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3241 \t Loss:2.257 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3242 \t Loss:2.257 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3243 \t Loss:2.257 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3244 \t Loss:2.257 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3245 \t Loss:2.256 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3246 \t Loss:2.256 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3247 \t Loss:2.256 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3248 \t Loss:2.255 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3249 \t Loss:2.255 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3250 \t Loss:2.255 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3251 \t Loss:2.254 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3252 \t Loss:2.254 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3253 \t Loss:2.254 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3254 \t Loss:2.253 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3255 \t Loss:2.253 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3256 \t Loss:2.253 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3257 \t Loss:2.252 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3258 \t Loss:2.252 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3259 \t Loss:2.252 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3260 \t Loss:2.251 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3261 \t Loss:2.251 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3262 \t Loss:2.251 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3263 \t Loss:2.250 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3264 \t Loss:2.250 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3265 \t Loss:2.250 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3266 \t Loss:2.249 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3267 \t Loss:2.249 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3268 \t Loss:2.248 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3269 \t Loss:2.248 \t error(train):80.8% \t error(val):80.4%\n",
      "iter:3270 \t Loss:2.248 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3271 \t Loss:2.247 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3272 \t Loss:2.247 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3273 \t Loss:2.247 \t error(train):80.7% \t error(val):80.4%\n",
      "iter:3274 \t Loss:2.246 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3275 \t Loss:2.246 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3276 \t Loss:2.246 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3277 \t Loss:2.246 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3278 \t Loss:2.245 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3279 \t Loss:2.245 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3280 \t Loss:2.245 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3281 \t Loss:2.244 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3282 \t Loss:2.244 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3283 \t Loss:2.244 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3284 \t Loss:2.244 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3285 \t Loss:2.243 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3286 \t Loss:2.243 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3287 \t Loss:2.243 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3288 \t Loss:2.243 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3289 \t Loss:2.242 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3290 \t Loss:2.242 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3291 \t Loss:2.241 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3292 \t Loss:2.241 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3293 \t Loss:2.241 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3294 \t Loss:2.240 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3295 \t Loss:2.240 \t error(train):80.7% \t error(val):80.5%\n",
      "iter:3296 \t Loss:2.240 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3297 \t Loss:2.239 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3298 \t Loss:2.239 \t error(train):80.7% \t error(val):80.6%\n",
      "iter:3299 \t Loss:2.239 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3300 \t Loss:2.238 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3301 \t Loss:2.238 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3302 \t Loss:2.238 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3303 \t Loss:2.237 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3304 \t Loss:2.237 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3305 \t Loss:2.236 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3306 \t Loss:2.236 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3307 \t Loss:2.236 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3308 \t Loss:2.235 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3309 \t Loss:2.235 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3310 \t Loss:2.235 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3311 \t Loss:2.235 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3312 \t Loss:2.234 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3313 \t Loss:2.234 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3314 \t Loss:2.234 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3315 \t Loss:2.234 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3316 \t Loss:2.233 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3317 \t Loss:2.232 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3318 \t Loss:2.232 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3319 \t Loss:2.232 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3320 \t Loss:2.231 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3321 \t Loss:2.231 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3322 \t Loss:2.230 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3323 \t Loss:2.230 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3324 \t Loss:2.230 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3325 \t Loss:2.229 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3326 \t Loss:2.229 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3327 \t Loss:2.229 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3328 \t Loss:2.229 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3329 \t Loss:2.228 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3330 \t Loss:2.228 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3331 \t Loss:2.228 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3332 \t Loss:2.227 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3333 \t Loss:2.227 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3334 \t Loss:2.227 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3335 \t Loss:2.227 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3336 \t Loss:2.226 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3337 \t Loss:2.226 \t error(train):80.8% \t error(val):80.7%\n",
      "iter:3338 \t Loss:2.226 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3339 \t Loss:2.226 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3340 \t Loss:2.225 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3341 \t Loss:2.225 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3342 \t Loss:2.225 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3343 \t Loss:2.224 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3344 \t Loss:2.224 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3345 \t Loss:2.224 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3346 \t Loss:2.223 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3347 \t Loss:2.223 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3348 \t Loss:2.223 \t error(train):80.8% \t error(val):80.5%\n",
      "iter:3349 \t Loss:2.222 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3350 \t Loss:2.222 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3351 \t Loss:2.222 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3352 \t Loss:2.221 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3353 \t Loss:2.221 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3354 \t Loss:2.221 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3355 \t Loss:2.220 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3356 \t Loss:2.220 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3357 \t Loss:2.219 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3358 \t Loss:2.219 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3359 \t Loss:2.219 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3360 \t Loss:2.218 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3361 \t Loss:2.218 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3362 \t Loss:2.218 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3363 \t Loss:2.218 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3364 \t Loss:2.217 \t error(train):80.8% \t error(val):80.6%\n",
      "iter:3365 \t Loss:2.217 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3366 \t Loss:2.217 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3367 \t Loss:2.217 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3368 \t Loss:2.216 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3369 \t Loss:2.216 \t error(train):80.8% \t error(val):80.7%\n",
      "iter:3370 \t Loss:2.215 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3371 \t Loss:2.215 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3372 \t Loss:2.215 \t error(train):80.8% \t error(val):80.7%\n",
      "iter:3373 \t Loss:2.214 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3374 \t Loss:2.213 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3375 \t Loss:2.213 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3376 \t Loss:2.213 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3377 \t Loss:2.213 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3378 \t Loss:2.212 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3379 \t Loss:2.212 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3380 \t Loss:2.212 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3381 \t Loss:2.212 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3382 \t Loss:2.211 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3383 \t Loss:2.211 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3384 \t Loss:2.211 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3385 \t Loss:2.210 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3386 \t Loss:2.210 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3387 \t Loss:2.210 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3388 \t Loss:2.210 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3389 \t Loss:2.209 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3390 \t Loss:2.209 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3391 \t Loss:2.209 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3392 \t Loss:2.208 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3393 \t Loss:2.207 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3394 \t Loss:2.207 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3395 \t Loss:2.207 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3396 \t Loss:2.207 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3397 \t Loss:2.206 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3398 \t Loss:2.206 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3399 \t Loss:2.205 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3400 \t Loss:2.205 \t error(train):80.9% \t error(val):80.6%\n",
      "iter:3401 \t Loss:2.205 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3402 \t Loss:2.204 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3403 \t Loss:2.204 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3404 \t Loss:2.203 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3405 \t Loss:2.201 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3406 \t Loss:2.200 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3407 \t Loss:2.200 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3408 \t Loss:2.200 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3409 \t Loss:2.199 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3410 \t Loss:2.198 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3411 \t Loss:2.198 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3412 \t Loss:2.198 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3413 \t Loss:2.198 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3414 \t Loss:2.197 \t error(train):80.9% \t error(val):80.7%\n",
      "iter:3415 \t Loss:2.197 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3416 \t Loss:2.197 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3417 \t Loss:2.197 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3418 \t Loss:2.196 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3419 \t Loss:2.196 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3420 \t Loss:2.196 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3421 \t Loss:2.196 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3422 \t Loss:2.195 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3423 \t Loss:2.194 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3424 \t Loss:2.194 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3425 \t Loss:2.194 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3426 \t Loss:2.193 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3427 \t Loss:2.193 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3428 \t Loss:2.193 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3429 \t Loss:2.192 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3430 \t Loss:2.192 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3431 \t Loss:2.192 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3432 \t Loss:2.192 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3433 \t Loss:2.191 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3434 \t Loss:2.191 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3435 \t Loss:2.191 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3436 \t Loss:2.190 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3437 \t Loss:2.190 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3438 \t Loss:2.190 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3439 \t Loss:2.190 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3440 \t Loss:2.189 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3441 \t Loss:2.189 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3442 \t Loss:2.189 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3443 \t Loss:2.188 \t error(train):81.0% \t error(val):80.9%\n",
      "iter:3444 \t Loss:2.188 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3445 \t Loss:2.188 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3446 \t Loss:2.188 \t error(train):81.0% \t error(val):80.9%\n",
      "iter:3447 \t Loss:2.187 \t error(train):81.0% \t error(val):80.7%\n",
      "iter:3448 \t Loss:2.187 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3449 \t Loss:2.186 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3450 \t Loss:2.186 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3451 \t Loss:2.186 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3452 \t Loss:2.186 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3453 \t Loss:2.185 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3454 \t Loss:2.185 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3455 \t Loss:2.185 \t error(train):81.0% \t error(val):80.9%\n",
      "iter:3456 \t Loss:2.184 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3457 \t Loss:2.184 \t error(train):81.0% \t error(val):80.9%\n",
      "iter:3458 \t Loss:2.184 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3459 \t Loss:2.184 \t error(train):81.0% \t error(val):80.9%\n",
      "iter:3460 \t Loss:2.183 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3461 \t Loss:2.183 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3462 \t Loss:2.183 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3463 \t Loss:2.182 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3464 \t Loss:2.182 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3465 \t Loss:2.181 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3466 \t Loss:2.181 \t error(train):81.0% \t error(val):80.8%\n",
      "iter:3467 \t Loss:2.180 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3468 \t Loss:2.180 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3469 \t Loss:2.180 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3470 \t Loss:2.180 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3471 \t Loss:2.179 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3472 \t Loss:2.179 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3473 \t Loss:2.179 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3474 \t Loss:2.178 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3475 \t Loss:2.178 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3476 \t Loss:2.178 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3477 \t Loss:2.177 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3478 \t Loss:2.177 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3479 \t Loss:2.177 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3480 \t Loss:2.177 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3481 \t Loss:2.176 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3482 \t Loss:2.176 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3483 \t Loss:2.176 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3484 \t Loss:2.175 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3485 \t Loss:2.175 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3486 \t Loss:2.175 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3487 \t Loss:2.175 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3488 \t Loss:2.174 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3489 \t Loss:2.174 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3490 \t Loss:2.174 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3491 \t Loss:2.173 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3492 \t Loss:2.173 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3493 \t Loss:2.172 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3494 \t Loss:2.172 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3495 \t Loss:2.172 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3496 \t Loss:2.172 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3497 \t Loss:2.171 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3498 \t Loss:2.171 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3499 \t Loss:2.171 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3500 \t Loss:2.171 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3501 \t Loss:2.170 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3502 \t Loss:2.170 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3503 \t Loss:2.169 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3504 \t Loss:2.169 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3505 \t Loss:2.169 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3506 \t Loss:2.168 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3507 \t Loss:2.168 \t error(train):81.1% \t error(val):81.0%\n",
      "iter:3508 \t Loss:2.168 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3509 \t Loss:2.168 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3510 \t Loss:2.167 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3511 \t Loss:2.167 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3512 \t Loss:2.167 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3513 \t Loss:2.167 \t error(train):81.1% \t error(val):81.0%\n",
      "iter:3514 \t Loss:2.166 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3515 \t Loss:2.166 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3516 \t Loss:2.166 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3517 \t Loss:2.165 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3518 \t Loss:2.165 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3519 \t Loss:2.165 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3520 \t Loss:2.164 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3521 \t Loss:2.164 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3522 \t Loss:2.163 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3523 \t Loss:2.163 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3524 \t Loss:2.163 \t error(train):81.1% \t error(val):80.9%\n",
      "iter:3525 \t Loss:2.163 \t error(train):81.1% \t error(val):81.0%\n",
      "iter:3526 \t Loss:2.162 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3527 \t Loss:2.162 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3528 \t Loss:2.162 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3529 \t Loss:2.162 \t error(train):81.1% \t error(val):80.8%\n",
      "iter:3530 \t Loss:2.161 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3531 \t Loss:2.161 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3532 \t Loss:2.160 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3533 \t Loss:2.160 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3534 \t Loss:2.160 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3535 \t Loss:2.160 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3536 \t Loss:2.159 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3537 \t Loss:2.159 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3538 \t Loss:2.159 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3539 \t Loss:2.158 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3540 \t Loss:2.158 \t error(train):81.2% \t error(val):80.8%\n",
      "iter:3541 \t Loss:2.158 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3542 \t Loss:2.158 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3543 \t Loss:2.157 \t error(train):81.2% \t error(val):80.8%\n",
      "iter:3544 \t Loss:2.157 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3545 \t Loss:2.156 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3546 \t Loss:2.156 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3547 \t Loss:2.156 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3548 \t Loss:2.156 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3549 \t Loss:2.155 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3550 \t Loss:2.155 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3551 \t Loss:2.155 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3552 \t Loss:2.155 \t error(train):81.2% \t error(val):80.8%\n",
      "iter:3553 \t Loss:2.154 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3554 \t Loss:2.154 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3555 \t Loss:2.154 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3556 \t Loss:2.153 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3557 \t Loss:2.153 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3558 \t Loss:2.152 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3559 \t Loss:2.152 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3560 \t Loss:2.152 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3561 \t Loss:2.152 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3562 \t Loss:2.151 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3563 \t Loss:2.151 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3564 \t Loss:2.151 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3565 \t Loss:2.151 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3566 \t Loss:2.150 \t error(train):81.2% \t error(val):80.9%\n",
      "iter:3567 \t Loss:2.150 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3568 \t Loss:2.150 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3569 \t Loss:2.150 \t error(train):81.2% \t error(val):81.1%\n",
      "iter:3570 \t Loss:2.149 \t error(train):81.2% \t error(val):81.1%\n",
      "iter:3571 \t Loss:2.149 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3572 \t Loss:2.148 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3573 \t Loss:2.148 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3574 \t Loss:2.147 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3575 \t Loss:2.147 \t error(train):81.2% \t error(val):81.1%\n",
      "iter:3576 \t Loss:2.147 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3577 \t Loss:2.147 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3578 \t Loss:2.146 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3579 \t Loss:2.146 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3580 \t Loss:2.146 \t error(train):81.2% \t error(val):81.1%\n",
      "iter:3581 \t Loss:2.146 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3582 \t Loss:2.145 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3583 \t Loss:2.145 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3584 \t Loss:2.145 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3585 \t Loss:2.145 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3586 \t Loss:2.144 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3587 \t Loss:2.144 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3588 \t Loss:2.144 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3589 \t Loss:2.144 \t error(train):81.2% \t error(val):81.0%\n",
      "iter:3590 \t Loss:2.143 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3591 \t Loss:2.143 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3592 \t Loss:2.143 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3593 \t Loss:2.143 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3594 \t Loss:2.142 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3595 \t Loss:2.142 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3596 \t Loss:2.141 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3597 \t Loss:2.141 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3598 \t Loss:2.141 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3599 \t Loss:2.141 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3600 \t Loss:2.141 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3601 \t Loss:2.140 \t error(train):81.3% \t error(val):80.9%\n",
      "iter:3602 \t Loss:2.140 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3603 \t Loss:2.139 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3604 \t Loss:2.139 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3605 \t Loss:2.139 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3606 \t Loss:2.139 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3607 \t Loss:2.138 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3608 \t Loss:2.138 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3609 \t Loss:2.137 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3610 \t Loss:2.137 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3611 \t Loss:2.137 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3612 \t Loss:2.137 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3613 \t Loss:2.136 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3614 \t Loss:2.136 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3615 \t Loss:2.136 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3616 \t Loss:2.136 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3617 \t Loss:2.135 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3618 \t Loss:2.135 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3619 \t Loss:2.135 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3620 \t Loss:2.135 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3621 \t Loss:2.134 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3622 \t Loss:2.134 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3623 \t Loss:2.134 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3624 \t Loss:2.134 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3625 \t Loss:2.134 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3626 \t Loss:2.133 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3627 \t Loss:2.133 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3628 \t Loss:2.132 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3629 \t Loss:2.132 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3630 \t Loss:2.131 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3631 \t Loss:2.131 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3632 \t Loss:2.131 \t error(train):81.3% \t error(val):81.1%\n",
      "iter:3633 \t Loss:2.131 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3634 \t Loss:2.130 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3635 \t Loss:2.130 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3636 \t Loss:2.129 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3637 \t Loss:2.129 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3638 \t Loss:2.129 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3639 \t Loss:2.128 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3640 \t Loss:2.128 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3641 \t Loss:2.128 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3642 \t Loss:2.128 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3643 \t Loss:2.127 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3644 \t Loss:2.127 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3645 \t Loss:2.127 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3646 \t Loss:2.127 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3647 \t Loss:2.126 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3648 \t Loss:2.126 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3649 \t Loss:2.126 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3650 \t Loss:2.125 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3651 \t Loss:2.125 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3652 \t Loss:2.125 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3653 \t Loss:2.125 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3654 \t Loss:2.124 \t error(train):81.3% \t error(val):81.0%\n",
      "iter:3655 \t Loss:2.124 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3656 \t Loss:2.124 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3657 \t Loss:2.123 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3658 \t Loss:2.123 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3659 \t Loss:2.123 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3660 \t Loss:2.123 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3661 \t Loss:2.122 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3662 \t Loss:2.122 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3663 \t Loss:2.122 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3664 \t Loss:2.122 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3665 \t Loss:2.121 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3666 \t Loss:2.121 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3667 \t Loss:2.121 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3668 \t Loss:2.121 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3669 \t Loss:2.120 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3670 \t Loss:2.120 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3671 \t Loss:2.120 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3672 \t Loss:2.119 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3673 \t Loss:2.119 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3674 \t Loss:2.119 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3675 \t Loss:2.119 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3676 \t Loss:2.118 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3677 \t Loss:2.118 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3678 \t Loss:2.118 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3679 \t Loss:2.117 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3680 \t Loss:2.117 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3681 \t Loss:2.117 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3682 \t Loss:2.116 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3683 \t Loss:2.116 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3684 \t Loss:2.116 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3685 \t Loss:2.116 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3686 \t Loss:2.115 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3687 \t Loss:2.115 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3688 \t Loss:2.115 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3689 \t Loss:2.115 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3690 \t Loss:2.114 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3691 \t Loss:2.114 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3692 \t Loss:2.114 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3693 \t Loss:2.114 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3694 \t Loss:2.113 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3695 \t Loss:2.113 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3696 \t Loss:2.113 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3697 \t Loss:2.113 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3698 \t Loss:2.113 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3699 \t Loss:2.112 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3700 \t Loss:2.112 \t error(train):81.4% \t error(val):81.0%\n",
      "iter:3701 \t Loss:2.112 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3702 \t Loss:2.111 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3703 \t Loss:2.111 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3704 \t Loss:2.111 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3705 \t Loss:2.111 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3706 \t Loss:2.110 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3707 \t Loss:2.110 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3708 \t Loss:2.110 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3709 \t Loss:2.109 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3710 \t Loss:2.109 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3711 \t Loss:2.109 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3712 \t Loss:2.109 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3713 \t Loss:2.108 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3714 \t Loss:2.108 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3715 \t Loss:2.107 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3716 \t Loss:2.107 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3717 \t Loss:2.107 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3718 \t Loss:2.107 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3719 \t Loss:2.106 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3720 \t Loss:2.106 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3721 \t Loss:2.106 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3722 \t Loss:2.106 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3723 \t Loss:2.106 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3724 \t Loss:2.105 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3725 \t Loss:2.105 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3726 \t Loss:2.105 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3727 \t Loss:2.105 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3728 \t Loss:2.104 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3729 \t Loss:2.104 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3730 \t Loss:2.104 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3731 \t Loss:2.104 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3732 \t Loss:2.103 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3733 \t Loss:2.103 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3734 \t Loss:2.103 \t error(train):81.5% \t error(val):81.1%\n",
      "iter:3735 \t Loss:2.103 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3736 \t Loss:2.102 \t error(train):81.4% \t error(val):81.1%\n",
      "iter:3737 \t Loss:2.102 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3738 \t Loss:2.102 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3739 \t Loss:2.101 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3740 \t Loss:2.101 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3741 \t Loss:2.101 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3742 \t Loss:2.101 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3743 \t Loss:2.101 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3744 \t Loss:2.101 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3745 \t Loss:2.100 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3746 \t Loss:2.099 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3747 \t Loss:2.099 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3748 \t Loss:2.099 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3749 \t Loss:2.099 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3750 \t Loss:2.099 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3751 \t Loss:2.098 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3752 \t Loss:2.098 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3753 \t Loss:2.098 \t error(train):81.5% \t error(val):81.3%\n",
      "iter:3754 \t Loss:2.097 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3755 \t Loss:2.097 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3756 \t Loss:2.097 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3757 \t Loss:2.097 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3758 \t Loss:2.096 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3759 \t Loss:2.096 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3760 \t Loss:2.096 \t error(train):81.5% \t error(val):81.2%\n",
      "iter:3761 \t Loss:2.095 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3762 \t Loss:2.095 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3763 \t Loss:2.095 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3764 \t Loss:2.095 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3765 \t Loss:2.094 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3766 \t Loss:2.094 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3767 \t Loss:2.094 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3768 \t Loss:2.094 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3769 \t Loss:2.094 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3770 \t Loss:2.093 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3771 \t Loss:2.093 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3772 \t Loss:2.092 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3773 \t Loss:2.092 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3774 \t Loss:2.091 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3775 \t Loss:2.091 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3776 \t Loss:2.091 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3777 \t Loss:2.091 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3778 \t Loss:2.091 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3779 \t Loss:2.090 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3780 \t Loss:2.090 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3781 \t Loss:2.090 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3782 \t Loss:2.090 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3783 \t Loss:2.089 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3784 \t Loss:2.089 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3785 \t Loss:2.089 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3786 \t Loss:2.089 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3787 \t Loss:2.088 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3788 \t Loss:2.088 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3789 \t Loss:2.088 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3790 \t Loss:2.088 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3791 \t Loss:2.087 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3792 \t Loss:2.087 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3793 \t Loss:2.087 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3794 \t Loss:2.087 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3795 \t Loss:2.086 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3796 \t Loss:2.086 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3797 \t Loss:2.086 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3798 \t Loss:2.086 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3799 \t Loss:2.085 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3800 \t Loss:2.085 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3801 \t Loss:2.085 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3802 \t Loss:2.084 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3803 \t Loss:2.084 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3804 \t Loss:2.084 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3805 \t Loss:2.084 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3806 \t Loss:2.083 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3807 \t Loss:2.083 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3808 \t Loss:2.083 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3809 \t Loss:2.082 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3810 \t Loss:2.082 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3811 \t Loss:2.082 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3812 \t Loss:2.082 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3813 \t Loss:2.081 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3814 \t Loss:2.081 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3815 \t Loss:2.081 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3816 \t Loss:2.081 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3817 \t Loss:2.080 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3818 \t Loss:2.080 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3819 \t Loss:2.080 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3820 \t Loss:2.080 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3821 \t Loss:2.080 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3822 \t Loss:2.079 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3823 \t Loss:2.079 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3824 \t Loss:2.079 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3825 \t Loss:2.079 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3826 \t Loss:2.079 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3827 \t Loss:2.078 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3828 \t Loss:2.077 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3829 \t Loss:2.077 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3830 \t Loss:2.077 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3831 \t Loss:2.077 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3832 \t Loss:2.076 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3833 \t Loss:2.076 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3834 \t Loss:2.076 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3835 \t Loss:2.076 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3836 \t Loss:2.076 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3837 \t Loss:2.075 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3838 \t Loss:2.075 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3839 \t Loss:2.075 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3840 \t Loss:2.075 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3841 \t Loss:2.075 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3842 \t Loss:2.074 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3843 \t Loss:2.074 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3844 \t Loss:2.074 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3845 \t Loss:2.074 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3846 \t Loss:2.073 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3847 \t Loss:2.073 \t error(train):81.6% \t error(val):81.3%\n",
      "iter:3848 \t Loss:2.073 \t error(train):81.6% \t error(val):81.2%\n",
      "iter:3849 \t Loss:2.073 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3850 \t Loss:2.072 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3851 \t Loss:2.072 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3852 \t Loss:2.072 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3853 \t Loss:2.072 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3854 \t Loss:2.071 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3855 \t Loss:2.071 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3856 \t Loss:2.071 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3857 \t Loss:2.070 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3858 \t Loss:2.070 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3859 \t Loss:2.070 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3860 \t Loss:2.070 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3861 \t Loss:2.069 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3862 \t Loss:2.069 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3863 \t Loss:2.069 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3864 \t Loss:2.068 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3865 \t Loss:2.068 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3866 \t Loss:2.068 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3867 \t Loss:2.067 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3868 \t Loss:2.067 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3869 \t Loss:2.067 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3870 \t Loss:2.067 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3871 \t Loss:2.067 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3872 \t Loss:2.066 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3873 \t Loss:2.066 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3874 \t Loss:2.066 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3875 \t Loss:2.066 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3876 \t Loss:2.065 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3877 \t Loss:2.065 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3878 \t Loss:2.065 \t error(train):81.7% \t error(val):81.2%\n",
      "iter:3879 \t Loss:2.064 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3880 \t Loss:2.064 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3881 \t Loss:2.064 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3882 \t Loss:2.063 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3883 \t Loss:2.063 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3884 \t Loss:2.063 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3885 \t Loss:2.063 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3886 \t Loss:2.063 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3887 \t Loss:2.062 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3888 \t Loss:2.062 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3889 \t Loss:2.062 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3890 \t Loss:2.062 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3891 \t Loss:2.061 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3892 \t Loss:2.061 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3893 \t Loss:2.061 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3894 \t Loss:2.060 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3895 \t Loss:2.060 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3896 \t Loss:2.060 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3897 \t Loss:2.060 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3898 \t Loss:2.060 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3899 \t Loss:2.059 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3900 \t Loss:2.059 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3901 \t Loss:2.059 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3902 \t Loss:2.059 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3903 \t Loss:2.058 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3904 \t Loss:2.058 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3905 \t Loss:2.058 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3906 \t Loss:2.057 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3907 \t Loss:2.057 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3908 \t Loss:2.057 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3909 \t Loss:2.057 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3910 \t Loss:2.056 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3911 \t Loss:2.056 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3912 \t Loss:2.056 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3913 \t Loss:2.056 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3914 \t Loss:2.055 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3915 \t Loss:2.055 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3916 \t Loss:2.055 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3917 \t Loss:2.054 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3918 \t Loss:2.054 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3919 \t Loss:2.054 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3920 \t Loss:2.054 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3921 \t Loss:2.053 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3922 \t Loss:2.053 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3923 \t Loss:2.053 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3924 \t Loss:2.053 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3925 \t Loss:2.052 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3926 \t Loss:2.052 \t error(train):81.7% \t error(val):81.3%\n",
      "iter:3927 \t Loss:2.052 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3928 \t Loss:2.052 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3929 \t Loss:2.051 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3930 \t Loss:2.051 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3931 \t Loss:2.051 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3932 \t Loss:2.050 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3933 \t Loss:2.050 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3934 \t Loss:2.050 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3935 \t Loss:2.050 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3936 \t Loss:2.049 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3937 \t Loss:2.049 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3938 \t Loss:2.049 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3939 \t Loss:2.049 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3940 \t Loss:2.049 \t error(train):81.7% \t error(val):81.4%\n",
      "iter:3941 \t Loss:2.048 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3942 \t Loss:2.048 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3943 \t Loss:2.048 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3944 \t Loss:2.047 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3945 \t Loss:2.047 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3946 \t Loss:2.047 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3947 \t Loss:2.047 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3948 \t Loss:2.046 \t error(train):81.8% \t error(val):81.3%\n",
      "iter:3949 \t Loss:2.046 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3950 \t Loss:2.046 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3951 \t Loss:2.046 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3952 \t Loss:2.046 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3953 \t Loss:2.045 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3954 \t Loss:2.045 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3955 \t Loss:2.045 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3956 \t Loss:2.044 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3957 \t Loss:2.044 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3958 \t Loss:2.044 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3959 \t Loss:2.044 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3960 \t Loss:2.043 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3961 \t Loss:2.043 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3962 \t Loss:2.043 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3963 \t Loss:2.043 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3964 \t Loss:2.043 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3965 \t Loss:2.042 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3966 \t Loss:2.042 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3967 \t Loss:2.042 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3968 \t Loss:2.042 \t error(train):81.8% \t error(val):81.4%\n",
      "iter:3969 \t Loss:2.042 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3970 \t Loss:2.041 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3971 \t Loss:2.041 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3972 \t Loss:2.040 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3973 \t Loss:2.040 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3974 \t Loss:2.040 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3975 \t Loss:2.039 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3976 \t Loss:2.039 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3977 \t Loss:2.039 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3978 \t Loss:2.039 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3979 \t Loss:2.039 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3980 \t Loss:2.038 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3981 \t Loss:2.038 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3982 \t Loss:2.038 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3983 \t Loss:2.038 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3984 \t Loss:2.037 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3985 \t Loss:2.037 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3986 \t Loss:2.037 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3987 \t Loss:2.037 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3988 \t Loss:2.037 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3989 \t Loss:2.036 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3990 \t Loss:2.036 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3991 \t Loss:2.036 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3992 \t Loss:2.036 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3993 \t Loss:2.036 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3994 \t Loss:2.035 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:3995 \t Loss:2.035 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3996 \t Loss:2.035 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3997 \t Loss:2.034 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:3998 \t Loss:2.034 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:3999 \t Loss:2.034 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4000 \t Loss:2.034 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4001 \t Loss:2.034 \t error(train):81.9% \t error(val):81.4%\n",
      "iter:4002 \t Loss:2.033 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4003 \t Loss:2.033 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4004 \t Loss:2.033 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4005 \t Loss:2.032 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4006 \t Loss:2.032 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4007 \t Loss:2.032 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4008 \t Loss:2.032 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4009 \t Loss:2.031 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4010 \t Loss:2.031 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4011 \t Loss:2.031 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4012 \t Loss:2.030 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4013 \t Loss:2.030 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4014 \t Loss:2.030 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4015 \t Loss:2.030 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4016 \t Loss:2.030 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4017 \t Loss:2.030 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4018 \t Loss:2.029 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4019 \t Loss:2.029 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4020 \t Loss:2.029 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4021 \t Loss:2.029 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4022 \t Loss:2.029 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4023 \t Loss:2.028 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4024 \t Loss:2.028 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4025 \t Loss:2.027 \t error(train):81.9% \t error(val):81.5%\n",
      "iter:4026 \t Loss:2.027 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4027 \t Loss:2.027 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4028 \t Loss:2.026 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4029 \t Loss:2.026 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4030 \t Loss:2.026 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4031 \t Loss:2.026 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4032 \t Loss:2.025 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4033 \t Loss:2.025 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4034 \t Loss:2.025 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4035 \t Loss:2.024 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4036 \t Loss:2.024 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4037 \t Loss:2.024 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4038 \t Loss:2.024 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4039 \t Loss:2.024 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4040 \t Loss:2.023 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4041 \t Loss:2.023 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4042 \t Loss:2.023 \t error(train):82.0% \t error(val):81.4%\n",
      "iter:4043 \t Loss:2.023 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4044 \t Loss:2.022 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4045 \t Loss:2.022 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4046 \t Loss:2.022 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4047 \t Loss:2.022 \t error(train):82.0% \t error(val):81.5%\n",
      "iter:4048 \t Loss:2.022 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4049 \t Loss:2.021 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4050 \t Loss:2.021 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4051 \t Loss:2.021 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4052 \t Loss:2.020 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4053 \t Loss:2.020 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4054 \t Loss:2.020 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4055 \t Loss:2.020 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4056 \t Loss:2.019 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4057 \t Loss:2.019 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4058 \t Loss:2.017 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4059 \t Loss:2.016 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4060 \t Loss:2.016 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4061 \t Loss:2.016 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4062 \t Loss:2.015 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4063 \t Loss:2.015 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4064 \t Loss:2.015 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4065 \t Loss:2.015 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4066 \t Loss:2.014 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4067 \t Loss:2.014 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4068 \t Loss:2.014 \t error(train):82.0% \t error(val):81.6%\n",
      "iter:4069 \t Loss:2.014 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4070 \t Loss:2.014 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4071 \t Loss:2.013 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4072 \t Loss:2.013 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4073 \t Loss:2.013 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4074 \t Loss:2.013 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4075 \t Loss:2.012 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4076 \t Loss:2.012 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4077 \t Loss:2.012 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4078 \t Loss:2.012 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4079 \t Loss:2.011 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4080 \t Loss:2.011 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4081 \t Loss:2.011 \t error(train):82.2% \t error(val):81.6%\n",
      "iter:4082 \t Loss:2.011 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4083 \t Loss:2.010 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4084 \t Loss:2.010 \t error(train):82.1% \t error(val):81.6%\n",
      "iter:4085 \t Loss:2.010 \t error(train):82.2% \t error(val):81.6%\n",
      "iter:4086 \t Loss:2.010 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4087 \t Loss:2.010 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4088 \t Loss:2.009 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4089 \t Loss:2.009 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4090 \t Loss:2.009 \t error(train):82.2% \t error(val):81.6%\n",
      "iter:4091 \t Loss:2.009 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4092 \t Loss:2.009 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4093 \t Loss:2.008 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4094 \t Loss:2.008 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4095 \t Loss:2.008 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4096 \t Loss:2.008 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4097 \t Loss:2.007 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4098 \t Loss:2.007 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4099 \t Loss:2.007 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4100 \t Loss:2.007 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4101 \t Loss:2.007 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4102 \t Loss:2.006 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4103 \t Loss:2.006 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4104 \t Loss:2.006 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4105 \t Loss:2.006 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4106 \t Loss:2.006 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4107 \t Loss:2.005 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4108 \t Loss:2.005 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4109 \t Loss:2.005 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4110 \t Loss:2.005 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4111 \t Loss:2.005 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4112 \t Loss:2.004 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4113 \t Loss:2.004 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4114 \t Loss:2.004 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4115 \t Loss:2.004 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4116 \t Loss:2.003 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4117 \t Loss:2.003 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4118 \t Loss:2.003 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4119 \t Loss:2.003 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4120 \t Loss:2.003 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4121 \t Loss:2.002 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4122 \t Loss:2.002 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4123 \t Loss:2.002 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4124 \t Loss:2.002 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4125 \t Loss:2.002 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4126 \t Loss:2.002 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4127 \t Loss:2.001 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4128 \t Loss:2.001 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4129 \t Loss:2.001 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4130 \t Loss:2.001 \t error(train):82.1% \t error(val):81.7%\n",
      "iter:4131 \t Loss:2.001 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4132 \t Loss:2.000 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4133 \t Loss:2.000 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4134 \t Loss:1.999 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4135 \t Loss:1.999 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4136 \t Loss:1.999 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4137 \t Loss:1.999 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4138 \t Loss:1.999 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4139 \t Loss:1.998 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4140 \t Loss:1.998 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4141 \t Loss:1.998 \t error(train):82.2% \t error(val):81.6%\n",
      "iter:4142 \t Loss:1.998 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4143 \t Loss:1.997 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4144 \t Loss:1.997 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4145 \t Loss:1.997 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4146 \t Loss:1.997 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4147 \t Loss:1.997 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4148 \t Loss:1.996 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4149 \t Loss:1.996 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4150 \t Loss:1.996 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4151 \t Loss:1.996 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4152 \t Loss:1.995 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4153 \t Loss:1.995 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4154 \t Loss:1.995 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4155 \t Loss:1.995 \t error(train):82.2% \t error(val):81.7%\n",
      "iter:4156 \t Loss:1.994 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4157 \t Loss:1.994 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4158 \t Loss:1.994 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4159 \t Loss:1.993 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4160 \t Loss:1.993 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4161 \t Loss:1.993 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4162 \t Loss:1.993 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4163 \t Loss:1.993 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4164 \t Loss:1.993 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4165 \t Loss:1.992 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4166 \t Loss:1.992 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4167 \t Loss:1.992 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4168 \t Loss:1.992 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4169 \t Loss:1.992 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4170 \t Loss:1.991 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4171 \t Loss:1.991 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4172 \t Loss:1.991 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4173 \t Loss:1.990 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4174 \t Loss:1.990 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4175 \t Loss:1.990 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4176 \t Loss:1.989 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4177 \t Loss:1.989 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4178 \t Loss:1.989 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4179 \t Loss:1.989 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4180 \t Loss:1.989 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4181 \t Loss:1.988 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4182 \t Loss:1.988 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4183 \t Loss:1.988 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4184 \t Loss:1.988 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4185 \t Loss:1.988 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4186 \t Loss:1.987 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4187 \t Loss:1.987 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4188 \t Loss:1.987 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4189 \t Loss:1.987 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4190 \t Loss:1.987 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4191 \t Loss:1.987 \t error(train):82.2% \t error(val):81.8%\n",
      "iter:4192 \t Loss:1.986 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4193 \t Loss:1.986 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4194 \t Loss:1.986 \t error(train):82.3% \t error(val):81.7%\n",
      "iter:4195 \t Loss:1.986 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4196 \t Loss:1.985 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4197 \t Loss:1.985 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4198 \t Loss:1.985 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4199 \t Loss:1.985 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4200 \t Loss:1.985 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4201 \t Loss:1.984 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4202 \t Loss:1.984 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4203 \t Loss:1.984 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4204 \t Loss:1.984 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4205 \t Loss:1.983 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4206 \t Loss:1.983 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4207 \t Loss:1.983 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4208 \t Loss:1.983 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4209 \t Loss:1.982 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4210 \t Loss:1.982 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4211 \t Loss:1.982 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4212 \t Loss:1.982 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4213 \t Loss:1.981 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4214 \t Loss:1.981 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4215 \t Loss:1.981 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4216 \t Loss:1.981 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4217 \t Loss:1.981 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4218 \t Loss:1.980 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4219 \t Loss:1.980 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4220 \t Loss:1.980 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4221 \t Loss:1.980 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4222 \t Loss:1.980 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4223 \t Loss:1.979 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4224 \t Loss:1.979 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4225 \t Loss:1.979 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4226 \t Loss:1.978 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4227 \t Loss:1.978 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4228 \t Loss:1.978 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4229 \t Loss:1.978 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4230 \t Loss:1.977 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4231 \t Loss:1.977 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4232 \t Loss:1.977 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4233 \t Loss:1.977 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4234 \t Loss:1.977 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4235 \t Loss:1.976 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4236 \t Loss:1.976 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4237 \t Loss:1.976 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4238 \t Loss:1.976 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4239 \t Loss:1.976 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4240 \t Loss:1.975 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4241 \t Loss:1.975 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4242 \t Loss:1.975 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4243 \t Loss:1.975 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4244 \t Loss:1.975 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4245 \t Loss:1.974 \t error(train):82.4% \t error(val):81.8%\n",
      "iter:4246 \t Loss:1.974 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4247 \t Loss:1.974 \t error(train):82.3% \t error(val):81.8%\n",
      "iter:4248 \t Loss:1.974 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4249 \t Loss:1.973 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4250 \t Loss:1.973 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4251 \t Loss:1.973 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4252 \t Loss:1.973 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4253 \t Loss:1.973 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4254 \t Loss:1.972 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4255 \t Loss:1.972 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4256 \t Loss:1.972 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4257 \t Loss:1.972 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4258 \t Loss:1.971 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4259 \t Loss:1.971 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4260 \t Loss:1.971 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4261 \t Loss:1.971 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4262 \t Loss:1.970 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4263 \t Loss:1.970 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4264 \t Loss:1.970 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4265 \t Loss:1.970 \t error(train):82.3% \t error(val):81.9%\n",
      "iter:4266 \t Loss:1.970 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4267 \t Loss:1.969 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4268 \t Loss:1.969 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4269 \t Loss:1.969 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4270 \t Loss:1.969 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4271 \t Loss:1.969 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4272 \t Loss:1.968 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4273 \t Loss:1.968 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4274 \t Loss:1.967 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4275 \t Loss:1.967 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4276 \t Loss:1.967 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4277 \t Loss:1.967 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4278 \t Loss:1.967 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4279 \t Loss:1.966 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4280 \t Loss:1.966 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4281 \t Loss:1.966 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4282 \t Loss:1.966 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4283 \t Loss:1.966 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4284 \t Loss:1.965 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4285 \t Loss:1.965 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4286 \t Loss:1.965 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4287 \t Loss:1.965 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4288 \t Loss:1.964 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4289 \t Loss:1.964 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4290 \t Loss:1.964 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4291 \t Loss:1.964 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4292 \t Loss:1.963 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4293 \t Loss:1.963 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4294 \t Loss:1.963 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4295 \t Loss:1.963 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4296 \t Loss:1.963 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4297 \t Loss:1.962 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4298 \t Loss:1.962 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4299 \t Loss:1.962 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4300 \t Loss:1.962 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4301 \t Loss:1.962 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4302 \t Loss:1.961 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4303 \t Loss:1.961 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4304 \t Loss:1.961 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4305 \t Loss:1.961 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4306 \t Loss:1.960 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4307 \t Loss:1.960 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4308 \t Loss:1.960 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4309 \t Loss:1.960 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4310 \t Loss:1.960 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4311 \t Loss:1.959 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4312 \t Loss:1.959 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4313 \t Loss:1.959 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4314 \t Loss:1.959 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4315 \t Loss:1.958 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4316 \t Loss:1.958 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4317 \t Loss:1.958 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4318 \t Loss:1.958 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4319 \t Loss:1.957 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4320 \t Loss:1.957 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4321 \t Loss:1.957 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4322 \t Loss:1.957 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4323 \t Loss:1.957 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4324 \t Loss:1.957 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4325 \t Loss:1.956 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4326 \t Loss:1.956 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4327 \t Loss:1.956 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4328 \t Loss:1.956 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4329 \t Loss:1.955 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4330 \t Loss:1.955 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4331 \t Loss:1.955 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4332 \t Loss:1.954 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4333 \t Loss:1.954 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4334 \t Loss:1.954 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4335 \t Loss:1.954 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4336 \t Loss:1.954 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4337 \t Loss:1.953 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4338 \t Loss:1.953 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4339 \t Loss:1.953 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4340 \t Loss:1.953 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4341 \t Loss:1.953 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4342 \t Loss:1.952 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4343 \t Loss:1.952 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4344 \t Loss:1.952 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4345 \t Loss:1.952 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4346 \t Loss:1.952 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4347 \t Loss:1.952 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4348 \t Loss:1.951 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4349 \t Loss:1.951 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4350 \t Loss:1.951 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4351 \t Loss:1.951 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4352 \t Loss:1.951 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4353 \t Loss:1.951 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4354 \t Loss:1.950 \t error(train):82.4% \t error(val):81.9%\n",
      "iter:4355 \t Loss:1.950 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4356 \t Loss:1.950 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4357 \t Loss:1.950 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4358 \t Loss:1.949 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4359 \t Loss:1.949 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4360 \t Loss:1.949 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4361 \t Loss:1.949 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4362 \t Loss:1.948 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4363 \t Loss:1.948 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4364 \t Loss:1.948 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4365 \t Loss:1.948 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4366 \t Loss:1.948 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4367 \t Loss:1.947 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4368 \t Loss:1.947 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4369 \t Loss:1.947 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4370 \t Loss:1.947 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4371 \t Loss:1.947 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4372 \t Loss:1.947 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4373 \t Loss:1.946 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4374 \t Loss:1.946 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4375 \t Loss:1.946 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4376 \t Loss:1.946 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4377 \t Loss:1.946 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4378 \t Loss:1.945 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4379 \t Loss:1.945 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4380 \t Loss:1.945 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4381 \t Loss:1.944 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4382 \t Loss:1.944 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4383 \t Loss:1.944 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4384 \t Loss:1.944 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4385 \t Loss:1.944 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4386 \t Loss:1.944 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4387 \t Loss:1.943 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4388 \t Loss:1.943 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4389 \t Loss:1.943 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4390 \t Loss:1.943 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4391 \t Loss:1.943 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4392 \t Loss:1.942 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4393 \t Loss:1.942 \t error(train):82.5% \t error(val):82.0%\n",
      "iter:4394 \t Loss:1.942 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4395 \t Loss:1.942 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4396 \t Loss:1.942 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4397 \t Loss:1.941 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4398 \t Loss:1.941 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4399 \t Loss:1.941 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4400 \t Loss:1.941 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4401 \t Loss:1.941 \t error(train):82.4% \t error(val):82.0%\n",
      "iter:4402 \t Loss:1.940 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4403 \t Loss:1.940 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4404 \t Loss:1.940 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4405 \t Loss:1.940 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4406 \t Loss:1.940 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4407 \t Loss:1.939 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4408 \t Loss:1.939 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4409 \t Loss:1.939 \t error(train):82.4% \t error(val):82.1%\n",
      "iter:4410 \t Loss:1.939 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4411 \t Loss:1.939 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4412 \t Loss:1.939 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4413 \t Loss:1.938 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4414 \t Loss:1.938 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4415 \t Loss:1.938 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4416 \t Loss:1.938 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4417 \t Loss:1.938 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4418 \t Loss:1.937 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4419 \t Loss:1.937 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4420 \t Loss:1.937 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4421 \t Loss:1.937 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4422 \t Loss:1.937 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4423 \t Loss:1.936 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4424 \t Loss:1.936 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4425 \t Loss:1.936 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4426 \t Loss:1.936 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4427 \t Loss:1.936 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4428 \t Loss:1.936 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4429 \t Loss:1.935 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4430 \t Loss:1.935 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4431 \t Loss:1.935 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4432 \t Loss:1.935 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4433 \t Loss:1.935 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4434 \t Loss:1.935 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4435 \t Loss:1.934 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4436 \t Loss:1.934 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4437 \t Loss:1.934 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4438 \t Loss:1.934 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4439 \t Loss:1.934 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4440 \t Loss:1.933 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4441 \t Loss:1.933 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4442 \t Loss:1.933 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4443 \t Loss:1.933 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4444 \t Loss:1.933 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4445 \t Loss:1.932 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4446 \t Loss:1.932 \t error(train):82.6% \t error(val):82.1%\n",
      "iter:4447 \t Loss:1.932 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4448 \t Loss:1.932 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4449 \t Loss:1.932 \t error(train):82.6% \t error(val):82.1%\n",
      "iter:4450 \t Loss:1.931 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4451 \t Loss:1.931 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4452 \t Loss:1.931 \t error(train):82.6% \t error(val):82.1%\n",
      "iter:4453 \t Loss:1.931 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4454 \t Loss:1.930 \t error(train):82.6% \t error(val):82.1%\n",
      "iter:4455 \t Loss:1.930 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4456 \t Loss:1.930 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4457 \t Loss:1.930 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4458 \t Loss:1.930 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4459 \t Loss:1.930 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4460 \t Loss:1.929 \t error(train):82.6% \t error(val):82.1%\n",
      "iter:4461 \t Loss:1.929 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4462 \t Loss:1.929 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4463 \t Loss:1.929 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4464 \t Loss:1.928 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4465 \t Loss:1.928 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4466 \t Loss:1.928 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4467 \t Loss:1.928 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4468 \t Loss:1.928 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4469 \t Loss:1.927 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4470 \t Loss:1.927 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4471 \t Loss:1.927 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4472 \t Loss:1.927 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4473 \t Loss:1.926 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4474 \t Loss:1.926 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4475 \t Loss:1.926 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4476 \t Loss:1.926 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4477 \t Loss:1.926 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4478 \t Loss:1.925 \t error(train):82.5% \t error(val):82.1%\n",
      "iter:4479 \t Loss:1.925 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4480 \t Loss:1.925 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4481 \t Loss:1.925 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4482 \t Loss:1.924 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4483 \t Loss:1.924 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4484 \t Loss:1.924 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4485 \t Loss:1.924 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4486 \t Loss:1.924 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4487 \t Loss:1.924 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4488 \t Loss:1.923 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4489 \t Loss:1.923 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4490 \t Loss:1.923 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4491 \t Loss:1.923 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4492 \t Loss:1.923 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4493 \t Loss:1.923 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4494 \t Loss:1.922 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4495 \t Loss:1.922 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4496 \t Loss:1.922 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4497 \t Loss:1.922 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4498 \t Loss:1.922 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4499 \t Loss:1.921 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4500 \t Loss:1.921 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4501 \t Loss:1.921 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4502 \t Loss:1.921 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4503 \t Loss:1.920 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4504 \t Loss:1.920 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4505 \t Loss:1.920 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4506 \t Loss:1.920 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4507 \t Loss:1.920 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4508 \t Loss:1.919 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4509 \t Loss:1.919 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4510 \t Loss:1.919 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4511 \t Loss:1.919 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4512 \t Loss:1.919 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4513 \t Loss:1.918 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4514 \t Loss:1.918 \t error(train):82.5% \t error(val):82.2%\n",
      "iter:4515 \t Loss:1.918 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4516 \t Loss:1.918 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4517 \t Loss:1.917 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4518 \t Loss:1.917 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4519 \t Loss:1.917 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4520 \t Loss:1.917 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4521 \t Loss:1.917 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4522 \t Loss:1.917 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4523 \t Loss:1.916 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4524 \t Loss:1.916 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4525 \t Loss:1.916 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4526 \t Loss:1.916 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4527 \t Loss:1.915 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4528 \t Loss:1.915 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4529 \t Loss:1.915 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4530 \t Loss:1.915 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4531 \t Loss:1.915 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4532 \t Loss:1.914 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4533 \t Loss:1.914 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4534 \t Loss:1.914 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4535 \t Loss:1.914 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4536 \t Loss:1.914 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4537 \t Loss:1.914 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4538 \t Loss:1.913 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4539 \t Loss:1.913 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4540 \t Loss:1.913 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4541 \t Loss:1.913 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4542 \t Loss:1.913 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4543 \t Loss:1.913 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4544 \t Loss:1.912 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4545 \t Loss:1.912 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4546 \t Loss:1.912 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4547 \t Loss:1.912 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4548 \t Loss:1.912 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4549 \t Loss:1.911 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4550 \t Loss:1.911 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4551 \t Loss:1.911 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4552 \t Loss:1.911 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4553 \t Loss:1.911 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4554 \t Loss:1.910 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4555 \t Loss:1.910 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4556 \t Loss:1.910 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4557 \t Loss:1.910 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4558 \t Loss:1.910 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4559 \t Loss:1.910 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4560 \t Loss:1.909 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4561 \t Loss:1.909 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4562 \t Loss:1.909 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4563 \t Loss:1.909 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4564 \t Loss:1.909 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4565 \t Loss:1.909 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4566 \t Loss:1.908 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4567 \t Loss:1.908 \t error(train):82.6% \t error(val):82.2%\n",
      "iter:4568 \t Loss:1.908 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4569 \t Loss:1.908 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4570 \t Loss:1.908 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4571 \t Loss:1.907 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4572 \t Loss:1.907 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4573 \t Loss:1.907 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4574 \t Loss:1.907 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4575 \t Loss:1.907 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4576 \t Loss:1.907 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4577 \t Loss:1.906 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4578 \t Loss:1.906 \t error(train):82.6% \t error(val):82.3%\n",
      "iter:4579 \t Loss:1.906 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4580 \t Loss:1.906 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4581 \t Loss:1.906 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4582 \t Loss:1.905 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4583 \t Loss:1.905 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4584 \t Loss:1.905 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4585 \t Loss:1.904 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4586 \t Loss:1.904 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4587 \t Loss:1.904 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4588 \t Loss:1.904 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4589 \t Loss:1.904 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4590 \t Loss:1.904 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4591 \t Loss:1.903 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4592 \t Loss:1.903 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4593 \t Loss:1.903 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4594 \t Loss:1.903 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4595 \t Loss:1.903 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4596 \t Loss:1.902 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4597 \t Loss:1.902 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4598 \t Loss:1.902 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4599 \t Loss:1.902 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4600 \t Loss:1.902 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4601 \t Loss:1.902 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4602 \t Loss:1.901 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4603 \t Loss:1.901 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4604 \t Loss:1.901 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4605 \t Loss:1.901 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4606 \t Loss:1.901 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4607 \t Loss:1.900 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4608 \t Loss:1.900 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4609 \t Loss:1.900 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4610 \t Loss:1.900 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4611 \t Loss:1.900 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4612 \t Loss:1.899 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4613 \t Loss:1.899 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4614 \t Loss:1.899 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4615 \t Loss:1.899 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4616 \t Loss:1.899 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4617 \t Loss:1.898 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4618 \t Loss:1.898 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4619 \t Loss:1.898 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4620 \t Loss:1.898 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4621 \t Loss:1.897 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4622 \t Loss:1.897 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4623 \t Loss:1.897 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4624 \t Loss:1.897 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4625 \t Loss:1.897 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4626 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4627 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4628 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4629 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4630 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4631 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4632 \t Loss:1.896 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4633 \t Loss:1.895 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4634 \t Loss:1.895 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4635 \t Loss:1.895 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4636 \t Loss:1.895 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4637 \t Loss:1.895 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4638 \t Loss:1.895 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4639 \t Loss:1.894 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4640 \t Loss:1.894 \t error(train):82.7% \t error(val):82.2%\n",
      "iter:4641 \t Loss:1.893 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4642 \t Loss:1.893 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4643 \t Loss:1.893 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4644 \t Loss:1.893 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4645 \t Loss:1.893 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4646 \t Loss:1.893 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4647 \t Loss:1.892 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4648 \t Loss:1.892 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4649 \t Loss:1.892 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4650 \t Loss:1.891 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4651 \t Loss:1.891 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4652 \t Loss:1.891 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4653 \t Loss:1.891 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4654 \t Loss:1.891 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4655 \t Loss:1.890 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4656 \t Loss:1.890 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4657 \t Loss:1.890 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4658 \t Loss:1.890 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4659 \t Loss:1.890 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4660 \t Loss:1.889 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4661 \t Loss:1.889 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4662 \t Loss:1.889 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4663 \t Loss:1.889 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4664 \t Loss:1.889 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4665 \t Loss:1.889 \t error(train):82.7% \t error(val):82.3%\n",
      "iter:4666 \t Loss:1.888 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4667 \t Loss:1.888 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4668 \t Loss:1.888 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4669 \t Loss:1.888 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4670 \t Loss:1.886 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4671 \t Loss:1.886 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4672 \t Loss:1.886 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4673 \t Loss:1.885 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4674 \t Loss:1.885 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4675 \t Loss:1.885 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4676 \t Loss:1.885 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4677 \t Loss:1.884 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4678 \t Loss:1.884 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4679 \t Loss:1.884 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4680 \t Loss:1.884 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4681 \t Loss:1.883 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4682 \t Loss:1.882 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4683 \t Loss:1.881 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4684 \t Loss:1.881 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4685 \t Loss:1.881 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4686 \t Loss:1.881 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4687 \t Loss:1.881 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4688 \t Loss:1.881 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4689 \t Loss:1.880 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4690 \t Loss:1.880 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4691 \t Loss:1.880 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4692 \t Loss:1.880 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4693 \t Loss:1.880 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4694 \t Loss:1.880 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4695 \t Loss:1.879 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4696 \t Loss:1.879 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4697 \t Loss:1.879 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4698 \t Loss:1.879 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4699 \t Loss:1.879 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4700 \t Loss:1.878 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4701 \t Loss:1.878 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4702 \t Loss:1.878 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4703 \t Loss:1.877 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4704 \t Loss:1.877 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4705 \t Loss:1.877 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4706 \t Loss:1.877 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4707 \t Loss:1.877 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4708 \t Loss:1.877 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4709 \t Loss:1.876 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4710 \t Loss:1.876 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4711 \t Loss:1.876 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4712 \t Loss:1.876 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4713 \t Loss:1.876 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4714 \t Loss:1.876 \t error(train):82.8% \t error(val):82.3%\n",
      "iter:4715 \t Loss:1.875 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4716 \t Loss:1.875 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4717 \t Loss:1.875 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4718 \t Loss:1.875 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4719 \t Loss:1.875 \t error(train):82.8% \t error(val):82.4%\n",
      "iter:4720 \t Loss:1.874 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4721 \t Loss:1.874 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4722 \t Loss:1.874 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4723 \t Loss:1.874 \t error(train):82.9% \t error(val):82.3%\n",
      "iter:4724 \t Loss:1.874 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4725 \t Loss:1.873 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4726 \t Loss:1.873 \t error(train):82.9% \t error(val):82.3%\n",
      "iter:4727 \t Loss:1.873 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4728 \t Loss:1.873 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4729 \t Loss:1.873 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4730 \t Loss:1.872 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4731 \t Loss:1.872 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4732 \t Loss:1.872 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4733 \t Loss:1.872 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4734 \t Loss:1.872 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4735 \t Loss:1.872 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4736 \t Loss:1.871 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4737 \t Loss:1.871 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4738 \t Loss:1.871 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4739 \t Loss:1.871 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4740 \t Loss:1.871 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4741 \t Loss:1.870 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4742 \t Loss:1.870 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4743 \t Loss:1.870 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4744 \t Loss:1.870 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4745 \t Loss:1.869 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4746 \t Loss:1.869 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4747 \t Loss:1.869 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4748 \t Loss:1.869 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4749 \t Loss:1.869 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4750 \t Loss:1.869 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4751 \t Loss:1.868 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4752 \t Loss:1.868 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4753 \t Loss:1.868 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4754 \t Loss:1.868 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4755 \t Loss:1.868 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4756 \t Loss:1.868 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4757 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4758 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4759 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4760 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4761 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4762 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4763 \t Loss:1.867 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4764 \t Loss:1.866 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4765 \t Loss:1.866 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4766 \t Loss:1.866 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4767 \t Loss:1.866 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4768 \t Loss:1.866 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4769 \t Loss:1.865 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4770 \t Loss:1.865 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4771 \t Loss:1.865 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4772 \t Loss:1.865 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4773 \t Loss:1.865 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4774 \t Loss:1.864 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4775 \t Loss:1.864 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4776 \t Loss:1.864 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4777 \t Loss:1.864 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4778 \t Loss:1.864 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4779 \t Loss:1.864 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4780 \t Loss:1.864 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4781 \t Loss:1.863 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4782 \t Loss:1.863 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4783 \t Loss:1.863 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4784 \t Loss:1.862 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4785 \t Loss:1.862 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4786 \t Loss:1.862 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4787 \t Loss:1.862 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4788 \t Loss:1.862 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4789 \t Loss:1.861 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4790 \t Loss:1.861 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4791 \t Loss:1.861 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4792 \t Loss:1.861 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4793 \t Loss:1.861 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4794 \t Loss:1.861 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4795 \t Loss:1.860 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4796 \t Loss:1.860 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4797 \t Loss:1.860 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4798 \t Loss:1.860 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4799 \t Loss:1.860 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4800 \t Loss:1.860 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4801 \t Loss:1.859 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4802 \t Loss:1.859 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4803 \t Loss:1.859 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4804 \t Loss:1.859 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4805 \t Loss:1.858 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4806 \t Loss:1.858 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4807 \t Loss:1.858 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4808 \t Loss:1.858 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4809 \t Loss:1.858 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4810 \t Loss:1.858 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4811 \t Loss:1.857 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4812 \t Loss:1.857 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4813 \t Loss:1.857 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4814 \t Loss:1.857 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4815 \t Loss:1.856 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4816 \t Loss:1.856 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4817 \t Loss:1.856 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4818 \t Loss:1.856 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4819 \t Loss:1.856 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4820 \t Loss:1.855 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4821 \t Loss:1.855 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4822 \t Loss:1.855 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4823 \t Loss:1.855 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4824 \t Loss:1.855 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4825 \t Loss:1.855 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4826 \t Loss:1.854 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4827 \t Loss:1.854 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4828 \t Loss:1.854 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4829 \t Loss:1.854 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4830 \t Loss:1.854 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4831 \t Loss:1.854 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4832 \t Loss:1.853 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4833 \t Loss:1.853 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4834 \t Loss:1.853 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4835 \t Loss:1.853 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4836 \t Loss:1.852 \t error(train):82.9% \t error(val):82.4%\n",
      "iter:4837 \t Loss:1.852 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4838 \t Loss:1.852 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4839 \t Loss:1.852 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4840 \t Loss:1.851 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4841 \t Loss:1.851 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4842 \t Loss:1.851 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4843 \t Loss:1.851 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4844 \t Loss:1.851 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4845 \t Loss:1.851 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4846 \t Loss:1.850 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4847 \t Loss:1.850 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4848 \t Loss:1.850 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4849 \t Loss:1.850 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4850 \t Loss:1.850 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4851 \t Loss:1.850 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4852 \t Loss:1.850 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4853 \t Loss:1.849 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4854 \t Loss:1.849 \t error(train):82.9% \t error(val):82.5%\n",
      "iter:4855 \t Loss:1.849 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4856 \t Loss:1.849 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4857 \t Loss:1.849 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4858 \t Loss:1.849 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4859 \t Loss:1.848 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4860 \t Loss:1.848 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4861 \t Loss:1.848 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4862 \t Loss:1.848 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4863 \t Loss:1.848 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4864 \t Loss:1.847 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4865 \t Loss:1.847 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4866 \t Loss:1.847 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4867 \t Loss:1.847 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4868 \t Loss:1.847 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4869 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4870 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4871 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4872 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4873 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4874 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4875 \t Loss:1.846 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4876 \t Loss:1.845 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4877 \t Loss:1.845 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4878 \t Loss:1.845 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4879 \t Loss:1.844 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4880 \t Loss:1.844 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4881 \t Loss:1.844 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4882 \t Loss:1.844 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4883 \t Loss:1.844 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4884 \t Loss:1.843 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4885 \t Loss:1.843 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4886 \t Loss:1.843 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4887 \t Loss:1.843 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4888 \t Loss:1.843 \t error(train):83.0% \t error(val):82.4%\n",
      "iter:4889 \t Loss:1.843 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4890 \t Loss:1.842 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4891 \t Loss:1.842 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4892 \t Loss:1.842 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4893 \t Loss:1.842 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4894 \t Loss:1.842 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4895 \t Loss:1.842 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4896 \t Loss:1.841 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4897 \t Loss:1.841 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4898 \t Loss:1.841 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4899 \t Loss:1.841 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4900 \t Loss:1.841 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4901 \t Loss:1.840 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4902 \t Loss:1.840 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4903 \t Loss:1.840 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4904 \t Loss:1.840 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4905 \t Loss:1.840 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4906 \t Loss:1.839 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4907 \t Loss:1.839 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4908 \t Loss:1.839 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4909 \t Loss:1.839 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4910 \t Loss:1.839 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4911 \t Loss:1.839 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4912 \t Loss:1.838 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4913 \t Loss:1.838 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4914 \t Loss:1.838 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4915 \t Loss:1.838 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4916 \t Loss:1.838 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4917 \t Loss:1.837 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4918 \t Loss:1.837 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4919 \t Loss:1.837 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4920 \t Loss:1.837 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4921 \t Loss:1.837 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4922 \t Loss:1.837 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4923 \t Loss:1.837 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4924 \t Loss:1.836 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4925 \t Loss:1.836 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4926 \t Loss:1.836 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4927 \t Loss:1.835 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4928 \t Loss:1.835 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4929 \t Loss:1.835 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4930 \t Loss:1.835 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4931 \t Loss:1.835 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4932 \t Loss:1.835 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4933 \t Loss:1.835 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4934 \t Loss:1.834 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4935 \t Loss:1.834 \t error(train):83.0% \t error(val):82.6%\n",
      "iter:4936 \t Loss:1.834 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4937 \t Loss:1.834 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4938 \t Loss:1.834 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4939 \t Loss:1.834 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4940 \t Loss:1.834 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4941 \t Loss:1.833 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4942 \t Loss:1.833 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4943 \t Loss:1.833 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4944 \t Loss:1.832 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4945 \t Loss:1.832 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4946 \t Loss:1.832 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4947 \t Loss:1.832 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4948 \t Loss:1.832 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4949 \t Loss:1.832 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4950 \t Loss:1.831 \t error(train):83.0% \t error(val):82.5%\n",
      "iter:4951 \t Loss:1.831 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4952 \t Loss:1.831 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4953 \t Loss:1.831 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4954 \t Loss:1.830 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4955 \t Loss:1.830 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4956 \t Loss:1.830 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4957 \t Loss:1.830 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4958 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4959 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4960 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4961 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4962 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4963 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4964 \t Loss:1.829 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4965 \t Loss:1.828 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4966 \t Loss:1.828 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4967 \t Loss:1.828 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4968 \t Loss:1.828 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4969 \t Loss:1.828 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4970 \t Loss:1.828 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4971 \t Loss:1.827 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4972 \t Loss:1.827 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4973 \t Loss:1.827 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4974 \t Loss:1.827 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4975 \t Loss:1.827 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4976 \t Loss:1.826 \t error(train):83.1% \t error(val):82.5%\n",
      "iter:4977 \t Loss:1.826 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4978 \t Loss:1.826 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4979 \t Loss:1.826 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4980 \t Loss:1.825 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4981 \t Loss:1.825 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4982 \t Loss:1.825 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4983 \t Loss:1.825 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4984 \t Loss:1.825 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4985 \t Loss:1.825 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4986 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4987 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4988 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4989 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4990 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4991 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4992 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4993 \t Loss:1.824 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4994 \t Loss:1.823 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4995 \t Loss:1.823 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4996 \t Loss:1.823 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4997 \t Loss:1.823 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4998 \t Loss:1.823 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:4999 \t Loss:1.823 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5000 \t Loss:1.822 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5001 \t Loss:1.822 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5002 \t Loss:1.822 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5003 \t Loss:1.822 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5004 \t Loss:1.822 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5005 \t Loss:1.822 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5006 \t Loss:1.821 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5007 \t Loss:1.821 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5008 \t Loss:1.821 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5009 \t Loss:1.821 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5010 \t Loss:1.821 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5011 \t Loss:1.820 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5012 \t Loss:1.820 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5013 \t Loss:1.820 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5014 \t Loss:1.820 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5015 \t Loss:1.820 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5016 \t Loss:1.820 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5017 \t Loss:1.819 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5018 \t Loss:1.819 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5019 \t Loss:1.819 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5020 \t Loss:1.819 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5021 \t Loss:1.819 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5022 \t Loss:1.819 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5023 \t Loss:1.818 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5024 \t Loss:1.818 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5025 \t Loss:1.818 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5026 \t Loss:1.818 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5027 \t Loss:1.818 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5028 \t Loss:1.817 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5029 \t Loss:1.817 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5030 \t Loss:1.817 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5031 \t Loss:1.817 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5032 \t Loss:1.817 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5033 \t Loss:1.817 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5034 \t Loss:1.817 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5035 \t Loss:1.816 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5036 \t Loss:1.816 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5037 \t Loss:1.816 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5038 \t Loss:1.815 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5039 \t Loss:1.815 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5040 \t Loss:1.815 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5041 \t Loss:1.815 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5042 \t Loss:1.815 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5043 \t Loss:1.815 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5044 \t Loss:1.814 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5045 \t Loss:1.814 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5046 \t Loss:1.814 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5047 \t Loss:1.814 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5048 \t Loss:1.814 \t error(train):83.1% \t error(val):82.6%\n",
      "iter:5049 \t Loss:1.814 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5050 \t Loss:1.814 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5051 \t Loss:1.813 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5052 \t Loss:1.813 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5053 \t Loss:1.813 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5054 \t Loss:1.813 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5055 \t Loss:1.813 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5056 \t Loss:1.813 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5057 \t Loss:1.812 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5058 \t Loss:1.812 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5059 \t Loss:1.812 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5060 \t Loss:1.812 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5061 \t Loss:1.812 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5062 \t Loss:1.812 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5063 \t Loss:1.811 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5064 \t Loss:1.811 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5065 \t Loss:1.811 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5066 \t Loss:1.811 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5067 \t Loss:1.811 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5068 \t Loss:1.810 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5069 \t Loss:1.810 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5070 \t Loss:1.810 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5071 \t Loss:1.810 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5072 \t Loss:1.810 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5073 \t Loss:1.810 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5074 \t Loss:1.809 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5075 \t Loss:1.809 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5076 \t Loss:1.809 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5077 \t Loss:1.809 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5078 \t Loss:1.809 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5079 \t Loss:1.809 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5080 \t Loss:1.808 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5081 \t Loss:1.808 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5082 \t Loss:1.808 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5083 \t Loss:1.808 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5084 \t Loss:1.808 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5085 \t Loss:1.808 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5086 \t Loss:1.808 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5087 \t Loss:1.807 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5088 \t Loss:1.807 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5089 \t Loss:1.807 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5090 \t Loss:1.807 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5091 \t Loss:1.807 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5092 \t Loss:1.807 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5093 \t Loss:1.806 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5094 \t Loss:1.806 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5095 \t Loss:1.806 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5096 \t Loss:1.806 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5097 \t Loss:1.806 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5098 \t Loss:1.805 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5099 \t Loss:1.805 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5100 \t Loss:1.805 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5101 \t Loss:1.805 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5102 \t Loss:1.804 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5103 \t Loss:1.804 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5104 \t Loss:1.804 \t error(train):83.3% \t error(val):82.6%\n",
      "iter:5105 \t Loss:1.804 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5106 \t Loss:1.804 \t error(train):83.3% \t error(val):82.6%\n",
      "iter:5107 \t Loss:1.803 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5108 \t Loss:1.803 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5109 \t Loss:1.803 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5110 \t Loss:1.803 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5111 \t Loss:1.803 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5112 \t Loss:1.803 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5113 \t Loss:1.802 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5114 \t Loss:1.802 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5115 \t Loss:1.802 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5116 \t Loss:1.802 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5117 \t Loss:1.802 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5118 \t Loss:1.802 \t error(train):83.2% \t error(val):82.7%\n",
      "iter:5119 \t Loss:1.802 \t error(train):83.2% \t error(val):82.6%\n",
      "iter:5120 \t Loss:1.801 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5121 \t Loss:1.801 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5122 \t Loss:1.801 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5123 \t Loss:1.801 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5124 \t Loss:1.801 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5125 \t Loss:1.800 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5126 \t Loss:1.800 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5127 \t Loss:1.800 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5128 \t Loss:1.800 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5129 \t Loss:1.800 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5130 \t Loss:1.799 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5131 \t Loss:1.799 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5132 \t Loss:1.799 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5133 \t Loss:1.799 \t error(train):83.3% \t error(val):82.6%\n",
      "iter:5134 \t Loss:1.799 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5135 \t Loss:1.799 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5136 \t Loss:1.798 \t error(train):83.3% \t error(val):82.6%\n",
      "iter:5137 \t Loss:1.798 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5138 \t Loss:1.798 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5139 \t Loss:1.798 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5140 \t Loss:1.798 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5141 \t Loss:1.798 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5142 \t Loss:1.797 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5143 \t Loss:1.797 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5144 \t Loss:1.797 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5145 \t Loss:1.797 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5146 \t Loss:1.797 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5147 \t Loss:1.796 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5148 \t Loss:1.796 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5149 \t Loss:1.796 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5150 \t Loss:1.796 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5151 \t Loss:1.796 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5152 \t Loss:1.796 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5153 \t Loss:1.796 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5154 \t Loss:1.795 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5155 \t Loss:1.795 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5156 \t Loss:1.795 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5157 \t Loss:1.795 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5158 \t Loss:1.795 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5159 \t Loss:1.794 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5160 \t Loss:1.794 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5161 \t Loss:1.794 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5162 \t Loss:1.794 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5163 \t Loss:1.794 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5164 \t Loss:1.794 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5165 \t Loss:1.794 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5166 \t Loss:1.793 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5167 \t Loss:1.793 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5168 \t Loss:1.793 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5169 \t Loss:1.793 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5170 \t Loss:1.793 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5171 \t Loss:1.792 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5172 \t Loss:1.792 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5173 \t Loss:1.792 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5174 \t Loss:1.792 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5175 \t Loss:1.792 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5176 \t Loss:1.792 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5177 \t Loss:1.792 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5178 \t Loss:1.791 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5179 \t Loss:1.791 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5180 \t Loss:1.791 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5181 \t Loss:1.791 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5182 \t Loss:1.791 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5183 \t Loss:1.790 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5184 \t Loss:1.790 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5185 \t Loss:1.790 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5186 \t Loss:1.790 \t error(train):83.3% \t error(val):82.7%\n",
      "iter:5187 \t Loss:1.790 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5188 \t Loss:1.790 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5189 \t Loss:1.789 \t error(train):83.3% \t error(val):82.6%\n",
      "iter:5190 \t Loss:1.789 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5191 \t Loss:1.789 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5192 \t Loss:1.789 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5193 \t Loss:1.789 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5194 \t Loss:1.788 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5195 \t Loss:1.788 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5196 \t Loss:1.788 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5197 \t Loss:1.788 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5198 \t Loss:1.788 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5199 \t Loss:1.788 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5200 \t Loss:1.787 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5201 \t Loss:1.787 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5202 \t Loss:1.787 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5203 \t Loss:1.787 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5204 \t Loss:1.787 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5205 \t Loss:1.787 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5206 \t Loss:1.787 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5207 \t Loss:1.786 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5208 \t Loss:1.786 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5209 \t Loss:1.786 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5210 \t Loss:1.786 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5211 \t Loss:1.786 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5212 \t Loss:1.785 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5213 \t Loss:1.785 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5214 \t Loss:1.785 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5215 \t Loss:1.785 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5216 \t Loss:1.785 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5217 \t Loss:1.785 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5218 \t Loss:1.785 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5219 \t Loss:1.784 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5220 \t Loss:1.784 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5221 \t Loss:1.784 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5222 \t Loss:1.784 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5223 \t Loss:1.784 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5224 \t Loss:1.783 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5225 \t Loss:1.783 \t error(train):83.3% \t error(val):82.8%\n",
      "iter:5226 \t Loss:1.783 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5227 \t Loss:1.783 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5228 \t Loss:1.783 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5229 \t Loss:1.783 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5230 \t Loss:1.783 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5231 \t Loss:1.782 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5232 \t Loss:1.782 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5233 \t Loss:1.782 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5234 \t Loss:1.782 \t error(train):83.4% \t error(val):82.7%\n",
      "iter:5235 \t Loss:1.782 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5236 \t Loss:1.781 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5237 \t Loss:1.781 \t error(train):83.4% \t error(val):82.7%\n",
      "iter:5238 \t Loss:1.781 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5239 \t Loss:1.781 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5240 \t Loss:1.781 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5241 \t Loss:1.781 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5242 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5243 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5244 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5245 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5246 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5247 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5248 \t Loss:1.780 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5249 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5250 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5251 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5252 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5253 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5254 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5255 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5256 \t Loss:1.779 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5257 \t Loss:1.778 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5258 \t Loss:1.778 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5259 \t Loss:1.778 \t error(train):83.4% \t error(val):82.7%\n",
      "iter:5260 \t Loss:1.778 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5261 \t Loss:1.778 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5262 \t Loss:1.778 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5263 \t Loss:1.777 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5264 \t Loss:1.777 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5265 \t Loss:1.777 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5266 \t Loss:1.777 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5267 \t Loss:1.777 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5268 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5269 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5270 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5271 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5272 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5273 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5274 \t Loss:1.776 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5275 \t Loss:1.775 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5276 \t Loss:1.775 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5277 \t Loss:1.775 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5278 \t Loss:1.775 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5279 \t Loss:1.775 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5280 \t Loss:1.775 \t error(train):83.4% \t error(val):82.7%\n",
      "iter:5281 \t Loss:1.774 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5282 \t Loss:1.774 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5283 \t Loss:1.774 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5284 \t Loss:1.774 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5285 \t Loss:1.774 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5286 \t Loss:1.774 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5287 \t Loss:1.774 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5288 \t Loss:1.773 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5289 \t Loss:1.773 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5290 \t Loss:1.773 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5291 \t Loss:1.773 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5292 \t Loss:1.773 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5293 \t Loss:1.772 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5294 \t Loss:1.772 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5295 \t Loss:1.772 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5296 \t Loss:1.772 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5297 \t Loss:1.772 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5298 \t Loss:1.772 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5299 \t Loss:1.772 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5300 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5301 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5302 \t Loss:1.771 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5303 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5304 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5305 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5306 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5307 \t Loss:1.771 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5308 \t Loss:1.770 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5309 \t Loss:1.770 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5310 \t Loss:1.770 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5311 \t Loss:1.770 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5312 \t Loss:1.770 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5313 \t Loss:1.770 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5314 \t Loss:1.769 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5315 \t Loss:1.769 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5316 \t Loss:1.769 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5317 \t Loss:1.769 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5318 \t Loss:1.769 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5319 \t Loss:1.769 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5320 \t Loss:1.768 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5321 \t Loss:1.768 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5322 \t Loss:1.768 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5323 \t Loss:1.768 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5324 \t Loss:1.768 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5325 \t Loss:1.768 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5326 \t Loss:1.768 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5327 \t Loss:1.767 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5328 \t Loss:1.767 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5329 \t Loss:1.767 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5330 \t Loss:1.767 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5331 \t Loss:1.767 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5332 \t Loss:1.766 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5333 \t Loss:1.766 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5334 \t Loss:1.766 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5335 \t Loss:1.766 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5336 \t Loss:1.766 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5337 \t Loss:1.766 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5338 \t Loss:1.766 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5339 \t Loss:1.766 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5340 \t Loss:1.765 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5341 \t Loss:1.765 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5342 \t Loss:1.765 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5343 \t Loss:1.765 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5344 \t Loss:1.764 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5345 \t Loss:1.764 \t error(train):83.4% \t error(val):82.8%\n",
      "iter:5346 \t Loss:1.764 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5347 \t Loss:1.764 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5348 \t Loss:1.764 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5349 \t Loss:1.764 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5350 \t Loss:1.764 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5351 \t Loss:1.763 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5352 \t Loss:1.763 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5353 \t Loss:1.763 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5354 \t Loss:1.763 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5355 \t Loss:1.763 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5356 \t Loss:1.763 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5357 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5358 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5359 \t Loss:1.762 \t error(train):83.5% \t error(val):82.7%\n",
      "iter:5360 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5361 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5362 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5363 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5364 \t Loss:1.762 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5365 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5366 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5367 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5368 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5369 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5370 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5371 \t Loss:1.761 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5372 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5373 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5374 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5375 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5376 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5377 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5378 \t Loss:1.760 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5379 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5380 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5381 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5382 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5383 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5384 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5385 \t Loss:1.759 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5386 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5387 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5388 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5389 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5390 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5391 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5392 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5393 \t Loss:1.758 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5394 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5395 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5396 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5397 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5398 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5399 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5400 \t Loss:1.757 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5401 \t Loss:1.756 \t error(train):83.5% \t error(val):82.9%\n",
      "iter:5402 \t Loss:1.756 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5403 \t Loss:1.756 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5404 \t Loss:1.756 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5405 \t Loss:1.756 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5406 \t Loss:1.755 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5407 \t Loss:1.755 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5408 \t Loss:1.755 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5409 \t Loss:1.755 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5410 \t Loss:1.755 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5411 \t Loss:1.755 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5412 \t Loss:1.754 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5413 \t Loss:1.754 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5414 \t Loss:1.754 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5415 \t Loss:1.754 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5416 \t Loss:1.754 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5417 \t Loss:1.754 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5418 \t Loss:1.754 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5419 \t Loss:1.753 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5420 \t Loss:1.753 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5421 \t Loss:1.753 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5422 \t Loss:1.753 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5423 \t Loss:1.753 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5424 \t Loss:1.753 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5425 \t Loss:1.752 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5426 \t Loss:1.752 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5427 \t Loss:1.752 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5428 \t Loss:1.752 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5429 \t Loss:1.752 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5430 \t Loss:1.752 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5431 \t Loss:1.752 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5432 \t Loss:1.752 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5433 \t Loss:1.751 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5434 \t Loss:1.751 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5435 \t Loss:1.751 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5436 \t Loss:1.751 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5437 \t Loss:1.751 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5438 \t Loss:1.750 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5439 \t Loss:1.750 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5440 \t Loss:1.750 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5441 \t Loss:1.750 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5442 \t Loss:1.750 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5443 \t Loss:1.750 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5444 \t Loss:1.749 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5445 \t Loss:1.749 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5446 \t Loss:1.749 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5447 \t Loss:1.749 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5448 \t Loss:1.749 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5449 \t Loss:1.749 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5450 \t Loss:1.749 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5451 \t Loss:1.748 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5452 \t Loss:1.748 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5453 \t Loss:1.748 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5454 \t Loss:1.748 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5455 \t Loss:1.748 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5456 \t Loss:1.748 \t error(train):83.5% \t error(val):82.8%\n",
      "iter:5457 \t Loss:1.748 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5458 \t Loss:1.748 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5459 \t Loss:1.747 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5460 \t Loss:1.747 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5461 \t Loss:1.747 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5462 \t Loss:1.747 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5463 \t Loss:1.747 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5464 \t Loss:1.747 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5465 \t Loss:1.747 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5466 \t Loss:1.746 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5467 \t Loss:1.746 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5468 \t Loss:1.746 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5469 \t Loss:1.746 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5470 \t Loss:1.746 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5471 \t Loss:1.746 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5472 \t Loss:1.745 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5473 \t Loss:1.745 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5474 \t Loss:1.745 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5475 \t Loss:1.745 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5476 \t Loss:1.745 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5477 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5478 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5479 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5480 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5481 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5482 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5483 \t Loss:1.744 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5484 \t Loss:1.743 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5485 \t Loss:1.743 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5486 \t Loss:1.743 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5487 \t Loss:1.743 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5488 \t Loss:1.743 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5489 \t Loss:1.743 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5490 \t Loss:1.742 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5491 \t Loss:1.742 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5492 \t Loss:1.742 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5493 \t Loss:1.742 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5494 \t Loss:1.742 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5495 \t Loss:1.742 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5496 \t Loss:1.741 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5497 \t Loss:1.741 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5498 \t Loss:1.741 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5499 \t Loss:1.741 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5500 \t Loss:1.741 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5501 \t Loss:1.741 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5502 \t Loss:1.741 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5503 \t Loss:1.740 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5504 \t Loss:1.740 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5505 \t Loss:1.740 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5506 \t Loss:1.740 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5507 \t Loss:1.740 \t error(train):83.6% \t error(val):82.8%\n",
      "iter:5508 \t Loss:1.740 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5509 \t Loss:1.740 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5510 \t Loss:1.739 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5511 \t Loss:1.739 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5512 \t Loss:1.739 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5513 \t Loss:1.739 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5514 \t Loss:1.739 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5515 \t Loss:1.738 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5516 \t Loss:1.738 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5517 \t Loss:1.738 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5518 \t Loss:1.738 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5519 \t Loss:1.738 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5520 \t Loss:1.738 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5521 \t Loss:1.738 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5522 \t Loss:1.738 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5523 \t Loss:1.737 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5524 \t Loss:1.737 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5525 \t Loss:1.737 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5526 \t Loss:1.737 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5527 \t Loss:1.737 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5528 \t Loss:1.737 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5529 \t Loss:1.736 \t error(train):83.6% \t error(val):82.9%\n",
      "iter:5530 \t Loss:1.736 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5531 \t Loss:1.736 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5532 \t Loss:1.736 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5533 \t Loss:1.736 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5534 \t Loss:1.736 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5535 \t Loss:1.736 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5536 \t Loss:1.735 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5537 \t Loss:1.735 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5538 \t Loss:1.735 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5539 \t Loss:1.735 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5540 \t Loss:1.735 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5541 \t Loss:1.735 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5542 \t Loss:1.734 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5543 \t Loss:1.734 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5544 \t Loss:1.734 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5545 \t Loss:1.734 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5546 \t Loss:1.734 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5547 \t Loss:1.734 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5548 \t Loss:1.733 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5549 \t Loss:1.733 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5550 \t Loss:1.733 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5551 \t Loss:1.733 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5552 \t Loss:1.733 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5553 \t Loss:1.733 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5554 \t Loss:1.733 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5555 \t Loss:1.732 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5556 \t Loss:1.732 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5557 \t Loss:1.732 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5558 \t Loss:1.732 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5559 \t Loss:1.732 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5560 \t Loss:1.732 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5561 \t Loss:1.731 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5562 \t Loss:1.731 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5563 \t Loss:1.731 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5564 \t Loss:1.731 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5565 \t Loss:1.731 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5566 \t Loss:1.731 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5567 \t Loss:1.731 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5568 \t Loss:1.730 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5569 \t Loss:1.730 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5570 \t Loss:1.730 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5571 \t Loss:1.730 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5572 \t Loss:1.730 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5573 \t Loss:1.730 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5574 \t Loss:1.730 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5575 \t Loss:1.729 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5576 \t Loss:1.729 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5577 \t Loss:1.729 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5578 \t Loss:1.729 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5579 \t Loss:1.729 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5580 \t Loss:1.728 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5581 \t Loss:1.728 \t error(train):83.7% \t error(val):82.9%\n",
      "iter:5582 \t Loss:1.728 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5583 \t Loss:1.728 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5584 \t Loss:1.728 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5585 \t Loss:1.728 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5586 \t Loss:1.728 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5587 \t Loss:1.727 \t error(train):83.8% \t error(val):82.9%\n",
      "iter:5588 \t Loss:1.727 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5589 \t Loss:1.727 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5590 \t Loss:1.727 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5591 \t Loss:1.727 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5592 \t Loss:1.727 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5593 \t Loss:1.727 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5594 \t Loss:1.726 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5595 \t Loss:1.726 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5596 \t Loss:1.726 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5597 \t Loss:1.726 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5598 \t Loss:1.726 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5599 \t Loss:1.726 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5600 \t Loss:1.725 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5601 \t Loss:1.725 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5602 \t Loss:1.725 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5603 \t Loss:1.725 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5604 \t Loss:1.725 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5605 \t Loss:1.725 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5606 \t Loss:1.725 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5607 \t Loss:1.725 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5608 \t Loss:1.724 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5609 \t Loss:1.724 \t error(train):83.7% \t error(val):83.1%\n",
      "iter:5610 \t Loss:1.724 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5611 \t Loss:1.724 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5612 \t Loss:1.724 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5613 \t Loss:1.724 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5614 \t Loss:1.723 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5615 \t Loss:1.723 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5616 \t Loss:1.723 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5617 \t Loss:1.723 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5618 \t Loss:1.723 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5619 \t Loss:1.723 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5620 \t Loss:1.723 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5621 \t Loss:1.722 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5622 \t Loss:1.722 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5623 \t Loss:1.722 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5624 \t Loss:1.722 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5625 \t Loss:1.722 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5626 \t Loss:1.722 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5627 \t Loss:1.721 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5628 \t Loss:1.721 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5629 \t Loss:1.721 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5630 \t Loss:1.721 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5631 \t Loss:1.721 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5632 \t Loss:1.721 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5633 \t Loss:1.721 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5634 \t Loss:1.721 \t error(train):83.7% \t error(val):83.1%\n",
      "iter:5635 \t Loss:1.720 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5636 \t Loss:1.720 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5637 \t Loss:1.720 \t error(train):83.7% \t error(val):83.0%\n",
      "iter:5638 \t Loss:1.720 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5639 \t Loss:1.720 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5640 \t Loss:1.719 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5641 \t Loss:1.719 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5642 \t Loss:1.719 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5643 \t Loss:1.719 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5644 \t Loss:1.719 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5645 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5646 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5647 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5648 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5649 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5650 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5651 \t Loss:1.718 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5652 \t Loss:1.717 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5653 \t Loss:1.717 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5654 \t Loss:1.717 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5655 \t Loss:1.717 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5656 \t Loss:1.717 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5657 \t Loss:1.717 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5658 \t Loss:1.717 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5659 \t Loss:1.716 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5660 \t Loss:1.716 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5661 \t Loss:1.716 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5662 \t Loss:1.716 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5663 \t Loss:1.716 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5664 \t Loss:1.716 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5665 \t Loss:1.716 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5666 \t Loss:1.715 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5667 \t Loss:1.715 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5668 \t Loss:1.715 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5669 \t Loss:1.715 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5670 \t Loss:1.715 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5671 \t Loss:1.715 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5672 \t Loss:1.715 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5673 \t Loss:1.714 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5674 \t Loss:1.714 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5675 \t Loss:1.714 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5676 \t Loss:1.714 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5677 \t Loss:1.714 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5678 \t Loss:1.713 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5679 \t Loss:1.713 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5680 \t Loss:1.713 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5681 \t Loss:1.713 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5682 \t Loss:1.713 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5683 \t Loss:1.713 \t error(train):83.8% \t error(val):83.0%\n",
      "iter:5684 \t Loss:1.713 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5685 \t Loss:1.712 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5686 \t Loss:1.712 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5687 \t Loss:1.712 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5688 \t Loss:1.712 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5689 \t Loss:1.712 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5690 \t Loss:1.712 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5691 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5692 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5693 \t Loss:1.711 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5694 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5695 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5696 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5697 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5698 \t Loss:1.711 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5699 \t Loss:1.710 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5700 \t Loss:1.710 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5701 \t Loss:1.710 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5702 \t Loss:1.710 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5703 \t Loss:1.710 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5704 \t Loss:1.710 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5705 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5706 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5707 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5708 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5709 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5710 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5711 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5712 \t Loss:1.709 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5713 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5714 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5715 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5716 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5717 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5718 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5719 \t Loss:1.708 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5720 \t Loss:1.707 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5721 \t Loss:1.707 \t error(train):83.8% \t error(val):83.3%\n",
      "iter:5722 \t Loss:1.707 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5723 \t Loss:1.707 \t error(train):83.9% \t error(val):83.1%\n",
      "iter:5724 \t Loss:1.707 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5725 \t Loss:1.707 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5726 \t Loss:1.707 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5727 \t Loss:1.706 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5728 \t Loss:1.706 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5729 \t Loss:1.706 \t error(train):83.9% \t error(val):83.1%\n",
      "iter:5730 \t Loss:1.706 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5731 \t Loss:1.706 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5732 \t Loss:1.706 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5733 \t Loss:1.705 \t error(train):83.9% \t error(val):83.1%\n",
      "iter:5734 \t Loss:1.705 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5735 \t Loss:1.705 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5736 \t Loss:1.705 \t error(train):83.8% \t error(val):83.1%\n",
      "iter:5737 \t Loss:1.705 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5738 \t Loss:1.705 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5739 \t Loss:1.705 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5740 \t Loss:1.704 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5741 \t Loss:1.704 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5742 \t Loss:1.704 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5743 \t Loss:1.704 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5744 \t Loss:1.704 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5745 \t Loss:1.704 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5746 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5747 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5748 \t Loss:1.703 \t error(train):83.8% \t error(val):83.2%\n",
      "iter:5749 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5750 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5751 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5752 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5753 \t Loss:1.703 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5754 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5755 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5756 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5757 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5758 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5759 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5760 \t Loss:1.702 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5761 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5762 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5763 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5764 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5765 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5766 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5767 \t Loss:1.701 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5768 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5769 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5770 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5771 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5772 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5773 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5774 \t Loss:1.700 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5775 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5776 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5777 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5778 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5779 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5780 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5781 \t Loss:1.699 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5782 \t Loss:1.698 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5783 \t Loss:1.698 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5784 \t Loss:1.698 \t error(train):83.9% \t error(val):83.1%\n",
      "iter:5785 \t Loss:1.698 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5786 \t Loss:1.698 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5787 \t Loss:1.698 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5788 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5789 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5790 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5791 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5792 \t Loss:1.697 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5793 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5794 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5795 \t Loss:1.697 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5796 \t Loss:1.696 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5797 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5798 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5799 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5800 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5801 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5802 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5803 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5804 \t Loss:1.696 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5805 \t Loss:1.695 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5806 \t Loss:1.695 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5807 \t Loss:1.695 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5808 \t Loss:1.695 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5809 \t Loss:1.695 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5810 \t Loss:1.695 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5811 \t Loss:1.695 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5812 \t Loss:1.694 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5813 \t Loss:1.694 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5814 \t Loss:1.694 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5815 \t Loss:1.694 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5816 \t Loss:1.694 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5817 \t Loss:1.694 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5818 \t Loss:1.694 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5819 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5820 \t Loss:1.693 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5821 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5822 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5823 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5824 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5825 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5826 \t Loss:1.693 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5827 \t Loss:1.692 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5828 \t Loss:1.692 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5829 \t Loss:1.692 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5830 \t Loss:1.692 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5831 \t Loss:1.692 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5832 \t Loss:1.692 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5833 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5834 \t Loss:1.691 \t error(train):83.9% \t error(val):83.3%\n",
      "iter:5835 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5836 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5837 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5838 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5839 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5840 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5841 \t Loss:1.691 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5842 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5843 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5844 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5845 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5846 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5847 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5848 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5849 \t Loss:1.690 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5850 \t Loss:1.689 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5851 \t Loss:1.689 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5852 \t Loss:1.689 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5853 \t Loss:1.689 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5854 \t Loss:1.689 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5855 \t Loss:1.689 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5856 \t Loss:1.689 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5857 \t Loss:1.689 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5858 \t Loss:1.688 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5859 \t Loss:1.688 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5860 \t Loss:1.688 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5861 \t Loss:1.688 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5862 \t Loss:1.688 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5863 \t Loss:1.688 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5864 \t Loss:1.688 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5865 \t Loss:1.688 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5866 \t Loss:1.687 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5867 \t Loss:1.687 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5868 \t Loss:1.687 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5869 \t Loss:1.687 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5870 \t Loss:1.687 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5871 \t Loss:1.687 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5872 \t Loss:1.687 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5873 \t Loss:1.687 \t error(train):83.9% \t error(val):83.2%\n",
      "iter:5874 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5875 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5876 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5877 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5878 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5879 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5880 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5881 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5882 \t Loss:1.686 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5883 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5884 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5885 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5886 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5887 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5888 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5889 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5890 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5891 \t Loss:1.685 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5892 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5893 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5894 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5895 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5896 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5897 \t Loss:1.684 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5898 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5899 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5900 \t Loss:1.684 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5901 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5902 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5903 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5904 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5905 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5906 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5907 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5908 \t Loss:1.683 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5909 \t Loss:1.683 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5910 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5911 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5912 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5913 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5914 \t Loss:1.682 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5915 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5916 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5917 \t Loss:1.682 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5918 \t Loss:1.681 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5919 \t Loss:1.681 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5920 \t Loss:1.681 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5921 \t Loss:1.681 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5922 \t Loss:1.681 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5923 \t Loss:1.681 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5924 \t Loss:1.681 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5925 \t Loss:1.681 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5926 \t Loss:1.681 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5927 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5928 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5929 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5930 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5931 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5932 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5933 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5934 \t Loss:1.680 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5935 \t Loss:1.679 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5936 \t Loss:1.679 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5937 \t Loss:1.679 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5938 \t Loss:1.679 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5939 \t Loss:1.679 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5940 \t Loss:1.679 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5941 \t Loss:1.679 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5942 \t Loss:1.679 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5943 \t Loss:1.678 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5944 \t Loss:1.678 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5945 \t Loss:1.678 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5946 \t Loss:1.678 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5947 \t Loss:1.678 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5948 \t Loss:1.678 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5949 \t Loss:1.678 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5950 \t Loss:1.677 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5951 \t Loss:1.677 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5952 \t Loss:1.677 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5953 \t Loss:1.677 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5954 \t Loss:1.677 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5955 \t Loss:1.677 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5956 \t Loss:1.677 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5957 \t Loss:1.676 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5958 \t Loss:1.676 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5959 \t Loss:1.676 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5960 \t Loss:1.676 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5961 \t Loss:1.676 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5962 \t Loss:1.676 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5963 \t Loss:1.676 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5964 \t Loss:1.676 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5965 \t Loss:1.676 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5966 \t Loss:1.675 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5967 \t Loss:1.675 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5968 \t Loss:1.675 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5969 \t Loss:1.675 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5970 \t Loss:1.675 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5971 \t Loss:1.675 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5972 \t Loss:1.675 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5973 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5974 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5975 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5976 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5977 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5978 \t Loss:1.674 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5979 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5980 \t Loss:1.674 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5981 \t Loss:1.674 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5982 \t Loss:1.673 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5983 \t Loss:1.673 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5984 \t Loss:1.673 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:5985 \t Loss:1.673 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5986 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5987 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5988 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5989 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5990 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5991 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5992 \t Loss:1.672 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:5993 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5994 \t Loss:1.672 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5995 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5996 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5997 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5998 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:5999 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6000 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6001 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6002 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6003 \t Loss:1.671 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6004 \t Loss:1.670 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6005 \t Loss:1.670 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6006 \t Loss:1.670 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:6007 \t Loss:1.670 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6008 \t Loss:1.670 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6009 \t Loss:1.670 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6010 \t Loss:1.670 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6011 \t Loss:1.670 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6012 \t Loss:1.669 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6013 \t Loss:1.669 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6014 \t Loss:1.669 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6015 \t Loss:1.669 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6016 \t Loss:1.669 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6017 \t Loss:1.669 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6018 \t Loss:1.669 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6019 \t Loss:1.668 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6020 \t Loss:1.668 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6021 \t Loss:1.668 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6022 \t Loss:1.668 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6023 \t Loss:1.668 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6024 \t Loss:1.668 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6025 \t Loss:1.668 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6026 \t Loss:1.668 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6027 \t Loss:1.668 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6028 \t Loss:1.667 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6029 \t Loss:1.667 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6030 \t Loss:1.667 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6031 \t Loss:1.667 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6032 \t Loss:1.667 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6033 \t Loss:1.667 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6034 \t Loss:1.666 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6035 \t Loss:1.666 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6036 \t Loss:1.666 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6037 \t Loss:1.666 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6038 \t Loss:1.666 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6039 \t Loss:1.666 \t error(train):84.0% \t error(val):83.3%\n",
      "iter:6040 \t Loss:1.666 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6041 \t Loss:1.666 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6042 \t Loss:1.665 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6043 \t Loss:1.665 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6044 \t Loss:1.665 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6045 \t Loss:1.665 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6046 \t Loss:1.665 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6047 \t Loss:1.665 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6048 \t Loss:1.665 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6049 \t Loss:1.664 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6050 \t Loss:1.664 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6051 \t Loss:1.664 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6052 \t Loss:1.664 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6053 \t Loss:1.664 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6054 \t Loss:1.664 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6055 \t Loss:1.664 \t error(train):84.0% \t error(val):83.2%\n",
      "iter:6056 \t Loss:1.664 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6057 \t Loss:1.663 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6058 \t Loss:1.663 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6059 \t Loss:1.663 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6060 \t Loss:1.663 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6061 \t Loss:1.663 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6062 \t Loss:1.663 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6063 \t Loss:1.663 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6064 \t Loss:1.662 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6065 \t Loss:1.662 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6066 \t Loss:1.662 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6067 \t Loss:1.662 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6068 \t Loss:1.662 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6069 \t Loss:1.662 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6070 \t Loss:1.662 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6071 \t Loss:1.662 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6072 \t Loss:1.661 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6073 \t Loss:1.661 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6074 \t Loss:1.661 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6075 \t Loss:1.661 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6076 \t Loss:1.661 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6077 \t Loss:1.661 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6078 \t Loss:1.661 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6079 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6080 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6081 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6082 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6083 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6084 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6085 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6086 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6087 \t Loss:1.660 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6088 \t Loss:1.659 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6089 \t Loss:1.659 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6090 \t Loss:1.659 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6091 \t Loss:1.659 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6092 \t Loss:1.659 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6093 \t Loss:1.659 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6094 \t Loss:1.659 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6095 \t Loss:1.659 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6096 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6097 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6098 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6099 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6100 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6101 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6102 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6103 \t Loss:1.658 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6104 \t Loss:1.658 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6105 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6106 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6107 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6108 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6109 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6110 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6111 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6112 \t Loss:1.657 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6113 \t Loss:1.656 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6114 \t Loss:1.656 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6115 \t Loss:1.656 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6116 \t Loss:1.656 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6117 \t Loss:1.656 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6118 \t Loss:1.656 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6119 \t Loss:1.656 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6120 \t Loss:1.655 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6121 \t Loss:1.655 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6122 \t Loss:1.655 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6123 \t Loss:1.655 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6124 \t Loss:1.655 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6125 \t Loss:1.655 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6126 \t Loss:1.655 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6127 \t Loss:1.654 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6128 \t Loss:1.654 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6129 \t Loss:1.654 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6130 \t Loss:1.654 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6131 \t Loss:1.654 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6132 \t Loss:1.654 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6133 \t Loss:1.654 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6134 \t Loss:1.653 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6135 \t Loss:1.653 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6136 \t Loss:1.653 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6137 \t Loss:1.653 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6138 \t Loss:1.653 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6139 \t Loss:1.653 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6140 \t Loss:1.653 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6141 \t Loss:1.652 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6142 \t Loss:1.652 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6143 \t Loss:1.652 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6144 \t Loss:1.652 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6145 \t Loss:1.652 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6146 \t Loss:1.652 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6147 \t Loss:1.652 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6148 \t Loss:1.652 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6149 \t Loss:1.651 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6150 \t Loss:1.651 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6151 \t Loss:1.651 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6152 \t Loss:1.651 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6153 \t Loss:1.651 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6154 \t Loss:1.651 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6155 \t Loss:1.651 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6156 \t Loss:1.650 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6157 \t Loss:1.650 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6158 \t Loss:1.650 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6159 \t Loss:1.650 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6160 \t Loss:1.650 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6161 \t Loss:1.650 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6162 \t Loss:1.650 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6163 \t Loss:1.650 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6164 \t Loss:1.650 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6165 \t Loss:1.649 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6166 \t Loss:1.649 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6167 \t Loss:1.649 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6168 \t Loss:1.649 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6169 \t Loss:1.649 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6170 \t Loss:1.649 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6171 \t Loss:1.649 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6172 \t Loss:1.648 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6173 \t Loss:1.648 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6174 \t Loss:1.648 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6175 \t Loss:1.648 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6176 \t Loss:1.648 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6177 \t Loss:1.648 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6178 \t Loss:1.648 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6179 \t Loss:1.648 \t error(train):84.1% \t error(val):83.3%\n",
      "iter:6180 \t Loss:1.647 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6181 \t Loss:1.647 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6182 \t Loss:1.647 \t error(train):84.1% \t error(val):83.2%\n",
      "iter:6183 \t Loss:1.647 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6184 \t Loss:1.647 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6185 \t Loss:1.647 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6186 \t Loss:1.647 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6187 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6188 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6189 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6190 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6191 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6192 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6193 \t Loss:1.646 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6194 \t Loss:1.646 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6195 \t Loss:1.645 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6196 \t Loss:1.645 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6197 \t Loss:1.645 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6198 \t Loss:1.645 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6199 \t Loss:1.645 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6200 \t Loss:1.645 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6201 \t Loss:1.645 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6202 \t Loss:1.644 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6203 \t Loss:1.644 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6204 \t Loss:1.644 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6205 \t Loss:1.644 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6206 \t Loss:1.644 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6207 \t Loss:1.644 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6208 \t Loss:1.644 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6209 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6210 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6211 \t Loss:1.643 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6212 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6213 \t Loss:1.643 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6214 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6215 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6216 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6217 \t Loss:1.643 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6218 \t Loss:1.643 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6219 \t Loss:1.642 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6220 \t Loss:1.642 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6221 \t Loss:1.642 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6222 \t Loss:1.642 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6223 \t Loss:1.642 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6224 \t Loss:1.642 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6225 \t Loss:1.642 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6226 \t Loss:1.641 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6227 \t Loss:1.641 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6228 \t Loss:1.641 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6229 \t Loss:1.641 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6230 \t Loss:1.641 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6231 \t Loss:1.641 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6232 \t Loss:1.641 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6233 \t Loss:1.641 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6234 \t Loss:1.641 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6235 \t Loss:1.640 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6236 \t Loss:1.640 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6237 \t Loss:1.640 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6238 \t Loss:1.640 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6239 \t Loss:1.640 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6240 \t Loss:1.640 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6241 \t Loss:1.639 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6242 \t Loss:1.639 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6243 \t Loss:1.639 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6244 \t Loss:1.639 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6245 \t Loss:1.639 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6246 \t Loss:1.639 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6247 \t Loss:1.639 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6248 \t Loss:1.638 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6249 \t Loss:1.638 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6250 \t Loss:1.638 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6251 \t Loss:1.638 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6252 \t Loss:1.638 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6253 \t Loss:1.638 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6254 \t Loss:1.638 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6255 \t Loss:1.637 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6256 \t Loss:1.637 \t error(train):84.2% \t error(val):83.3%\n",
      "iter:6257 \t Loss:1.637 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6258 \t Loss:1.637 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6259 \t Loss:1.637 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6260 \t Loss:1.637 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6261 \t Loss:1.637 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6262 \t Loss:1.637 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6263 \t Loss:1.637 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6264 \t Loss:1.636 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6265 \t Loss:1.636 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6266 \t Loss:1.636 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6267 \t Loss:1.636 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6268 \t Loss:1.636 \t error(train):84.3% \t error(val):83.3%\n",
      "iter:6269 \t Loss:1.636 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6270 \t Loss:1.636 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6271 \t Loss:1.635 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6272 \t Loss:1.635 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6273 \t Loss:1.635 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6274 \t Loss:1.635 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6275 \t Loss:1.635 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6276 \t Loss:1.635 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6277 \t Loss:1.635 \t error(train):84.3% \t error(val):83.3%\n",
      "iter:6278 \t Loss:1.634 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6279 \t Loss:1.634 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6280 \t Loss:1.634 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6281 \t Loss:1.634 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6282 \t Loss:1.634 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6283 \t Loss:1.634 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6284 \t Loss:1.634 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6285 \t Loss:1.633 \t error(train):84.3% \t error(val):83.3%\n",
      "iter:6286 \t Loss:1.633 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6287 \t Loss:1.633 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6288 \t Loss:1.633 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6289 \t Loss:1.633 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6290 \t Loss:1.633 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6291 \t Loss:1.633 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6292 \t Loss:1.633 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6293 \t Loss:1.632 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6294 \t Loss:1.632 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6295 \t Loss:1.632 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6296 \t Loss:1.632 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6297 \t Loss:1.632 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6298 \t Loss:1.632 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6299 \t Loss:1.632 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6300 \t Loss:1.632 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6301 \t Loss:1.632 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6302 \t Loss:1.631 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6303 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6304 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6305 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6306 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6307 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6308 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6309 \t Loss:1.631 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6310 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6311 \t Loss:1.630 \t error(train):84.2% \t error(val):83.4%\n",
      "iter:6312 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6313 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6314 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6315 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6316 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6317 \t Loss:1.630 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6318 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6319 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6320 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6321 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6322 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6323 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6324 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6325 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6326 \t Loss:1.629 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6327 \t Loss:1.628 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6328 \t Loss:1.628 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6329 \t Loss:1.628 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6330 \t Loss:1.628 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6331 \t Loss:1.628 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6332 \t Loss:1.628 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6333 \t Loss:1.628 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6334 \t Loss:1.627 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6335 \t Loss:1.627 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6336 \t Loss:1.627 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6337 \t Loss:1.627 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6338 \t Loss:1.627 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6339 \t Loss:1.627 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6340 \t Loss:1.627 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6341 \t Loss:1.627 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6342 \t Loss:1.626 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6343 \t Loss:1.626 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6344 \t Loss:1.626 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6345 \t Loss:1.626 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6346 \t Loss:1.626 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6347 \t Loss:1.626 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6348 \t Loss:1.626 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6349 \t Loss:1.625 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6350 \t Loss:1.625 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6351 \t Loss:1.625 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6352 \t Loss:1.625 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6353 \t Loss:1.625 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6354 \t Loss:1.625 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6355 \t Loss:1.625 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6356 \t Loss:1.625 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6357 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6358 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6359 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6360 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6361 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6362 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6363 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6364 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6365 \t Loss:1.624 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6366 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6367 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6368 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6369 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6370 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6371 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6372 \t Loss:1.623 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6373 \t Loss:1.623 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6374 \t Loss:1.622 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6375 \t Loss:1.622 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6376 \t Loss:1.622 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6377 \t Loss:1.622 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6378 \t Loss:1.622 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6379 \t Loss:1.622 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6380 \t Loss:1.622 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6381 \t Loss:1.621 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6382 \t Loss:1.621 \t error(train):84.3% \t error(val):83.4%\n",
      "iter:6383 \t Loss:1.621 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6384 \t Loss:1.621 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6385 \t Loss:1.621 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6386 \t Loss:1.621 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6387 \t Loss:1.621 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6388 \t Loss:1.621 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6389 \t Loss:1.621 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6390 \t Loss:1.620 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6391 \t Loss:1.620 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6392 \t Loss:1.620 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6393 \t Loss:1.620 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6394 \t Loss:1.620 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6395 \t Loss:1.620 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6396 \t Loss:1.620 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6397 \t Loss:1.619 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6398 \t Loss:1.619 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6399 \t Loss:1.619 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6400 \t Loss:1.619 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6401 \t Loss:1.619 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6402 \t Loss:1.619 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6403 \t Loss:1.619 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6404 \t Loss:1.619 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6405 \t Loss:1.619 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6406 \t Loss:1.618 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6407 \t Loss:1.618 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6408 \t Loss:1.618 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6409 \t Loss:1.618 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6410 \t Loss:1.618 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6411 \t Loss:1.618 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6412 \t Loss:1.618 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6413 \t Loss:1.618 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6414 \t Loss:1.617 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6415 \t Loss:1.617 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6416 \t Loss:1.617 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6417 \t Loss:1.617 \t error(train):84.3% \t error(val):83.5%\n",
      "iter:6418 \t Loss:1.617 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6419 \t Loss:1.617 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6420 \t Loss:1.617 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6421 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6422 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6423 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6424 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6425 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6426 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6427 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6428 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6429 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6430 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6431 \t Loss:1.616 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6432 \t Loss:1.615 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6433 \t Loss:1.615 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6434 \t Loss:1.615 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6435 \t Loss:1.615 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6436 \t Loss:1.615 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6437 \t Loss:1.615 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6438 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6439 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6440 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6441 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6442 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6443 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6444 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6445 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6446 \t Loss:1.614 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6447 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6448 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6449 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6450 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6451 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6452 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6453 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6454 \t Loss:1.613 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6455 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6456 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6457 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6458 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6459 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6460 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6461 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6462 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6463 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6464 \t Loss:1.612 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6465 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6466 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6467 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6468 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6469 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6470 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6471 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6472 \t Loss:1.611 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6473 \t Loss:1.611 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6474 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6475 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6476 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6477 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6478 \t Loss:1.610 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6479 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6480 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6481 \t Loss:1.610 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6482 \t Loss:1.609 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6483 \t Loss:1.609 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6484 \t Loss:1.609 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6485 \t Loss:1.609 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6486 \t Loss:1.609 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6487 \t Loss:1.609 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6488 \t Loss:1.609 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6489 \t Loss:1.609 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6490 \t Loss:1.608 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6491 \t Loss:1.608 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6492 \t Loss:1.608 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6493 \t Loss:1.608 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6494 \t Loss:1.608 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6495 \t Loss:1.608 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6496 \t Loss:1.608 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6497 \t Loss:1.608 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6498 \t Loss:1.607 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6499 \t Loss:1.607 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6500 \t Loss:1.607 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6501 \t Loss:1.607 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6502 \t Loss:1.607 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6503 \t Loss:1.607 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6504 \t Loss:1.607 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6505 \t Loss:1.606 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6506 \t Loss:1.606 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6507 \t Loss:1.606 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6508 \t Loss:1.606 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6509 \t Loss:1.606 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6510 \t Loss:1.606 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6511 \t Loss:1.606 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6512 \t Loss:1.606 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6513 \t Loss:1.605 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6514 \t Loss:1.605 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6515 \t Loss:1.605 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6516 \t Loss:1.605 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6517 \t Loss:1.605 \t error(train):84.4% \t error(val):83.5%\n",
      "iter:6518 \t Loss:1.605 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6519 \t Loss:1.605 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6520 \t Loss:1.605 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6521 \t Loss:1.604 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6522 \t Loss:1.604 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6523 \t Loss:1.604 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6524 \t Loss:1.604 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6525 \t Loss:1.604 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6526 \t Loss:1.604 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6527 \t Loss:1.604 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6528 \t Loss:1.604 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6529 \t Loss:1.604 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6530 \t Loss:1.604 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6531 \t Loss:1.603 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6532 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6533 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6534 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6535 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6536 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6537 \t Loss:1.603 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6538 \t Loss:1.603 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6539 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6540 \t Loss:1.603 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6541 \t Loss:1.602 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6542 \t Loss:1.602 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6543 \t Loss:1.602 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6544 \t Loss:1.602 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6545 \t Loss:1.602 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6546 \t Loss:1.602 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6547 \t Loss:1.602 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6548 \t Loss:1.602 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6549 \t Loss:1.601 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6550 \t Loss:1.601 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6551 \t Loss:1.601 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6552 \t Loss:1.601 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6553 \t Loss:1.601 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6554 \t Loss:1.601 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6555 \t Loss:1.601 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6556 \t Loss:1.601 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6557 \t Loss:1.601 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6558 \t Loss:1.600 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6559 \t Loss:1.600 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6560 \t Loss:1.600 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6561 \t Loss:1.600 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6562 \t Loss:1.600 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6563 \t Loss:1.600 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6564 \t Loss:1.600 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6565 \t Loss:1.600 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6566 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6567 \t Loss:1.599 \t error(train):84.5% \t error(val):83.5%\n",
      "iter:6568 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6569 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6570 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6571 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6572 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6573 \t Loss:1.599 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6574 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6575 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6576 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6577 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6578 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6579 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6580 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6581 \t Loss:1.598 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6582 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6583 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6584 \t Loss:1.597 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6585 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6586 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6587 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6588 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6589 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6590 \t Loss:1.597 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6591 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6592 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6593 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6594 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6595 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6596 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6597 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6598 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6599 \t Loss:1.596 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6600 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6601 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6602 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6603 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6604 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6605 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6606 \t Loss:1.595 \t error(train):84.4% \t error(val):83.6%\n",
      "iter:6607 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6608 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6609 \t Loss:1.595 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6610 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6611 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6612 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6613 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6614 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6615 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6616 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6617 \t Loss:1.594 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6618 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6619 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6620 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6621 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6622 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6623 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6624 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6625 \t Loss:1.593 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6626 \t Loss:1.592 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6627 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6628 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6629 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6630 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6631 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6632 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6633 \t Loss:1.592 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6634 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6635 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6636 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6637 \t Loss:1.591 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6638 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6639 \t Loss:1.591 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6640 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6641 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6642 \t Loss:1.591 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6643 \t Loss:1.590 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6644 \t Loss:1.590 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6645 \t Loss:1.590 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6646 \t Loss:1.590 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6647 \t Loss:1.590 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6648 \t Loss:1.590 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6649 \t Loss:1.590 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6650 \t Loss:1.590 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6651 \t Loss:1.589 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6652 \t Loss:1.589 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6653 \t Loss:1.589 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6654 \t Loss:1.589 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6655 \t Loss:1.589 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6656 \t Loss:1.589 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6657 \t Loss:1.589 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6658 \t Loss:1.589 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6659 \t Loss:1.589 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6660 \t Loss:1.589 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6661 \t Loss:1.588 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6662 \t Loss:1.588 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6663 \t Loss:1.588 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6664 \t Loss:1.588 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6665 \t Loss:1.588 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6666 \t Loss:1.588 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6667 \t Loss:1.588 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6668 \t Loss:1.588 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6669 \t Loss:1.587 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6670 \t Loss:1.587 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6671 \t Loss:1.587 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6672 \t Loss:1.587 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6673 \t Loss:1.587 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6674 \t Loss:1.587 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6675 \t Loss:1.587 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6676 \t Loss:1.587 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6677 \t Loss:1.586 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6678 \t Loss:1.586 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6679 \t Loss:1.586 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6680 \t Loss:1.586 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6681 \t Loss:1.586 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6682 \t Loss:1.586 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6683 \t Loss:1.586 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6684 \t Loss:1.586 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6685 \t Loss:1.586 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6686 \t Loss:1.586 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6687 \t Loss:1.586 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6688 \t Loss:1.585 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6689 \t Loss:1.585 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6690 \t Loss:1.585 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6691 \t Loss:1.585 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6692 \t Loss:1.585 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6693 \t Loss:1.585 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6694 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6695 \t Loss:1.584 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6696 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6697 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6698 \t Loss:1.584 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6699 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6700 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6701 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6702 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6703 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6704 \t Loss:1.584 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6705 \t Loss:1.583 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6706 \t Loss:1.583 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6707 \t Loss:1.583 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6708 \t Loss:1.583 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6709 \t Loss:1.583 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6710 \t Loss:1.583 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6711 \t Loss:1.583 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6712 \t Loss:1.583 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6713 \t Loss:1.583 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6714 \t Loss:1.582 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6715 \t Loss:1.582 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6716 \t Loss:1.582 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6717 \t Loss:1.582 \t error(train):84.6% \t error(val):83.6%\n",
      "iter:6718 \t Loss:1.582 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6719 \t Loss:1.582 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6720 \t Loss:1.582 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6721 \t Loss:1.582 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6722 \t Loss:1.582 \t error(train):84.5% \t error(val):83.7%\n",
      "iter:6723 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6724 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6725 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6726 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6727 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6728 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6729 \t Loss:1.581 \t error(train):84.5% \t error(val):83.6%\n",
      "iter:6730 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6731 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6732 \t Loss:1.581 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6733 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6734 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6735 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6736 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6737 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6738 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6739 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6740 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6741 \t Loss:1.580 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6742 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6743 \t Loss:1.579 \t error(train):84.5% \t error(val):83.7%\n",
      "iter:6744 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6745 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6746 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6747 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6748 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6749 \t Loss:1.579 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6750 \t Loss:1.579 \t error(train):84.5% \t error(val):83.7%\n",
      "iter:6751 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6752 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6753 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6754 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6755 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6756 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6757 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6758 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6759 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6760 \t Loss:1.578 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6761 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6762 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6763 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6764 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6765 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6766 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6767 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6768 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6769 \t Loss:1.577 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6770 \t Loss:1.577 \t error(train):84.5% \t error(val):83.7%\n",
      "iter:6771 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6772 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6773 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6774 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6775 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6776 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6777 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6778 \t Loss:1.576 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6779 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6780 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6781 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6782 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6783 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6784 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6785 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6786 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6787 \t Loss:1.575 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6788 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6789 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6790 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6791 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6792 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6793 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6794 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6795 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6796 \t Loss:1.574 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6797 \t Loss:1.574 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6798 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6799 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6800 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6801 \t Loss:1.573 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6802 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6803 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6804 \t Loss:1.573 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6805 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6806 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6807 \t Loss:1.573 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6808 \t Loss:1.573 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6809 \t Loss:1.572 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6810 \t Loss:1.572 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6811 \t Loss:1.572 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6812 \t Loss:1.572 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6813 \t Loss:1.572 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6814 \t Loss:1.572 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6815 \t Loss:1.572 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6816 \t Loss:1.572 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6817 \t Loss:1.572 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6818 \t Loss:1.571 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6819 \t Loss:1.571 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6820 \t Loss:1.571 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6821 \t Loss:1.571 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6822 \t Loss:1.571 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6823 \t Loss:1.571 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6824 \t Loss:1.571 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6825 \t Loss:1.571 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6826 \t Loss:1.570 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6827 \t Loss:1.570 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6828 \t Loss:1.570 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6829 \t Loss:1.570 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6830 \t Loss:1.570 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6831 \t Loss:1.570 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6832 \t Loss:1.570 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6833 \t Loss:1.570 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6834 \t Loss:1.570 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6835 \t Loss:1.569 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6836 \t Loss:1.569 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6837 \t Loss:1.569 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6838 \t Loss:1.569 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6839 \t Loss:1.569 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6840 \t Loss:1.569 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6841 \t Loss:1.569 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6842 \t Loss:1.569 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6843 \t Loss:1.569 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6844 \t Loss:1.568 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6845 \t Loss:1.568 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6846 \t Loss:1.568 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6847 \t Loss:1.568 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6848 \t Loss:1.568 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6849 \t Loss:1.568 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6850 \t Loss:1.568 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6851 \t Loss:1.568 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6852 \t Loss:1.568 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6853 \t Loss:1.568 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6854 \t Loss:1.568 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6855 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6856 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6857 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6858 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6859 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6860 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6861 \t Loss:1.567 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6862 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6863 \t Loss:1.567 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6864 \t Loss:1.567 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6865 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6866 \t Loss:1.566 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6867 \t Loss:1.566 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6868 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6869 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6870 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6871 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6872 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6873 \t Loss:1.566 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6874 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6875 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6876 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6877 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6878 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6879 \t Loss:1.565 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6880 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6881 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6882 \t Loss:1.565 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6883 \t Loss:1.564 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6884 \t Loss:1.564 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6885 \t Loss:1.564 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6886 \t Loss:1.564 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6887 \t Loss:1.564 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6888 \t Loss:1.564 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6889 \t Loss:1.564 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6890 \t Loss:1.564 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6891 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6892 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6893 \t Loss:1.563 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6894 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6895 \t Loss:1.563 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6896 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6897 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6898 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6899 \t Loss:1.563 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6900 \t Loss:1.562 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6901 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6902 \t Loss:1.562 \t error(train):84.6% \t error(val):83.7%\n",
      "iter:6903 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6904 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6905 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6906 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6907 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6908 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6909 \t Loss:1.562 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6910 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6911 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6912 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6913 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6914 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6915 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6916 \t Loss:1.561 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6917 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6918 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6919 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6920 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6921 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6922 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6923 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6924 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6925 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6926 \t Loss:1.560 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6927 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6928 \t Loss:1.559 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:6929 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6930 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6931 \t Loss:1.559 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:6932 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6933 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6934 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6935 \t Loss:1.559 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6936 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6937 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6938 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6939 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6940 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6941 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6942 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6943 \t Loss:1.558 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6944 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6945 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6946 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6947 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6948 \t Loss:1.557 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:6949 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6950 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6951 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6952 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6953 \t Loss:1.557 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6954 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6955 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6956 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6957 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6958 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6959 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6960 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6961 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6962 \t Loss:1.556 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6963 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6964 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6965 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6966 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6967 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6968 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6969 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6970 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6971 \t Loss:1.555 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6972 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6973 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6974 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6975 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6976 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6977 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6978 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6979 \t Loss:1.554 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6980 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6981 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6982 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6983 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6984 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6985 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6986 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6987 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6988 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6989 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6990 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6991 \t Loss:1.553 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6992 \t Loss:1.552 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6993 \t Loss:1.552 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:6994 \t Loss:1.552 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6995 \t Loss:1.552 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6996 \t Loss:1.552 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:6997 \t Loss:1.552 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6998 \t Loss:1.552 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:6999 \t Loss:1.551 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7000 \t Loss:1.551 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7001 \t Loss:1.551 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7002 \t Loss:1.551 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7003 \t Loss:1.551 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7004 \t Loss:1.551 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7005 \t Loss:1.551 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7006 \t Loss:1.551 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7007 \t Loss:1.551 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7008 \t Loss:1.551 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7009 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7010 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7011 \t Loss:1.550 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7012 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7013 \t Loss:1.550 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7014 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7015 \t Loss:1.550 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7016 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7017 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7018 \t Loss:1.550 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7019 \t Loss:1.550 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7020 \t Loss:1.549 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7021 \t Loss:1.549 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7022 \t Loss:1.549 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7023 \t Loss:1.549 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7024 \t Loss:1.549 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7025 \t Loss:1.549 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7026 \t Loss:1.549 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7027 \t Loss:1.549 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7028 \t Loss:1.549 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7029 \t Loss:1.548 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7030 \t Loss:1.548 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7031 \t Loss:1.548 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7032 \t Loss:1.548 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7033 \t Loss:1.548 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7034 \t Loss:1.548 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7035 \t Loss:1.548 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7036 \t Loss:1.548 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7037 \t Loss:1.547 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7038 \t Loss:1.547 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7039 \t Loss:1.547 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7040 \t Loss:1.547 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7041 \t Loss:1.546 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7042 \t Loss:1.546 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7043 \t Loss:1.546 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7044 \t Loss:1.546 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7045 \t Loss:1.546 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7046 \t Loss:1.546 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7047 \t Loss:1.545 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7048 \t Loss:1.545 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7049 \t Loss:1.545 \t error(train):84.7% \t error(val):83.8%\n",
      "iter:7050 \t Loss:1.545 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7051 \t Loss:1.545 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7052 \t Loss:1.545 \t error(train):84.7% \t error(val):83.7%\n",
      "iter:7053 \t Loss:1.545 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7054 \t Loss:1.545 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7055 \t Loss:1.545 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7056 \t Loss:1.545 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7057 \t Loss:1.544 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7058 \t Loss:1.544 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7059 \t Loss:1.544 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7060 \t Loss:1.544 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7061 \t Loss:1.544 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7062 \t Loss:1.544 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7063 \t Loss:1.544 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7064 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7065 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7066 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7067 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7068 \t Loss:1.543 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7069 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7070 \t Loss:1.543 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7071 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7072 \t Loss:1.543 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7073 \t Loss:1.543 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7074 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7075 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7076 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7077 \t Loss:1.542 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7078 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7079 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7080 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7081 \t Loss:1.542 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7082 \t Loss:1.541 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7083 \t Loss:1.541 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7084 \t Loss:1.541 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7085 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7086 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7087 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7088 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7089 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7090 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7091 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7092 \t Loss:1.540 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7093 \t Loss:1.539 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7094 \t Loss:1.539 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7095 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7096 \t Loss:1.538 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7097 \t Loss:1.538 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7098 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7099 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7100 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7101 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7102 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7103 \t Loss:1.538 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7104 \t Loss:1.538 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7105 \t Loss:1.538 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7106 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7107 \t Loss:1.537 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7108 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7109 \t Loss:1.537 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7110 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7111 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7112 \t Loss:1.537 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7113 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7114 \t Loss:1.537 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7115 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7116 \t Loss:1.537 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7117 \t Loss:1.536 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7118 \t Loss:1.536 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7119 \t Loss:1.536 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7120 \t Loss:1.536 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7121 \t Loss:1.536 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7122 \t Loss:1.536 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7123 \t Loss:1.536 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7124 \t Loss:1.536 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7125 \t Loss:1.536 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7126 \t Loss:1.536 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7127 \t Loss:1.535 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7128 \t Loss:1.535 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7129 \t Loss:1.535 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7130 \t Loss:1.535 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7131 \t Loss:1.535 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7132 \t Loss:1.535 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7133 \t Loss:1.535 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7134 \t Loss:1.535 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7135 \t Loss:1.535 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7136 \t Loss:1.535 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7137 \t Loss:1.534 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7138 \t Loss:1.534 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7139 \t Loss:1.534 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7140 \t Loss:1.534 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7141 \t Loss:1.534 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7142 \t Loss:1.534 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7143 \t Loss:1.534 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7144 \t Loss:1.534 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7145 \t Loss:1.534 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7146 \t Loss:1.534 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7147 \t Loss:1.533 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7148 \t Loss:1.533 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7149 \t Loss:1.533 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7150 \t Loss:1.533 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7151 \t Loss:1.533 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7152 \t Loss:1.533 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7153 \t Loss:1.533 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7154 \t Loss:1.533 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7155 \t Loss:1.533 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7156 \t Loss:1.533 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7157 \t Loss:1.533 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7158 \t Loss:1.532 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7159 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7160 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7161 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7162 \t Loss:1.532 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7163 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7164 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7165 \t Loss:1.532 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7166 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7167 \t Loss:1.532 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7168 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7169 \t Loss:1.531 \t error(train):84.8% \t error(val):83.9%\n",
      "iter:7170 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7171 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7172 \t Loss:1.531 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7173 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7174 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7175 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7176 \t Loss:1.531 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7177 \t Loss:1.531 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7178 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7179 \t Loss:1.530 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7180 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7181 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7182 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7183 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7184 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7185 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7186 \t Loss:1.530 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7187 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7188 \t Loss:1.529 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7189 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7190 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7191 \t Loss:1.529 \t error(train):84.8% \t error(val):83.7%\n",
      "iter:7192 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7193 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7194 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7195 \t Loss:1.529 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7196 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7197 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7198 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7199 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7200 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7201 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7202 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7203 \t Loss:1.528 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7204 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7205 \t Loss:1.528 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7206 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7207 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7208 \t Loss:1.528 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7209 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7210 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7211 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7212 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7213 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7214 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7215 \t Loss:1.527 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7216 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7217 \t Loss:1.527 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7218 \t Loss:1.527 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7219 \t Loss:1.526 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7220 \t Loss:1.526 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7221 \t Loss:1.526 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7222 \t Loss:1.526 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7223 \t Loss:1.526 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7224 \t Loss:1.526 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7225 \t Loss:1.526 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7226 \t Loss:1.526 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7227 \t Loss:1.526 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7228 \t Loss:1.525 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7229 \t Loss:1.525 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7230 \t Loss:1.525 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7231 \t Loss:1.525 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7232 \t Loss:1.525 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7233 \t Loss:1.525 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7234 \t Loss:1.525 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7235 \t Loss:1.525 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7236 \t Loss:1.525 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7237 \t Loss:1.525 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7238 \t Loss:1.524 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7239 \t Loss:1.524 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7240 \t Loss:1.524 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7241 \t Loss:1.524 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7242 \t Loss:1.524 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7243 \t Loss:1.524 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7244 \t Loss:1.524 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7245 \t Loss:1.524 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7246 \t Loss:1.524 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7247 \t Loss:1.523 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7248 \t Loss:1.523 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7249 \t Loss:1.523 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7250 \t Loss:1.523 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7251 \t Loss:1.523 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7252 \t Loss:1.523 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7253 \t Loss:1.523 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7254 \t Loss:1.523 \t error(train):84.8% \t error(val):83.8%\n",
      "iter:7255 \t Loss:1.523 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7256 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7257 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7258 \t Loss:1.522 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7259 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7260 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7261 \t Loss:1.522 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7262 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7263 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7264 \t Loss:1.522 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7265 \t Loss:1.522 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7266 \t Loss:1.521 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7267 \t Loss:1.521 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7268 \t Loss:1.521 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7269 \t Loss:1.521 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7270 \t Loss:1.521 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7271 \t Loss:1.521 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7272 \t Loss:1.521 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7273 \t Loss:1.521 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7274 \t Loss:1.521 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7275 \t Loss:1.521 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7276 \t Loss:1.520 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7277 \t Loss:1.520 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7278 \t Loss:1.520 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7279 \t Loss:1.520 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7280 \t Loss:1.520 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7281 \t Loss:1.520 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7282 \t Loss:1.520 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7283 \t Loss:1.520 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7284 \t Loss:1.520 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7285 \t Loss:1.520 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7286 \t Loss:1.519 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7287 \t Loss:1.519 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7288 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7289 \t Loss:1.519 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7290 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7291 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7292 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7293 \t Loss:1.519 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7294 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7295 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7296 \t Loss:1.519 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7297 \t Loss:1.518 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7298 \t Loss:1.518 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7299 \t Loss:1.518 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7300 \t Loss:1.518 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7301 \t Loss:1.518 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7302 \t Loss:1.518 \t error(train):84.8% \t error(val):83.9%\n",
      "iter:7303 \t Loss:1.518 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7304 \t Loss:1.518 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7305 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7306 \t Loss:1.517 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7307 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7308 \t Loss:1.517 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7309 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7310 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7311 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7312 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7313 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7314 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7315 \t Loss:1.517 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7316 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7317 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7318 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7319 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7320 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7321 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7322 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7323 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7324 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7325 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7326 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7327 \t Loss:1.516 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7328 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7329 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7330 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7331 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7332 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7333 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7334 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7335 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7336 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7337 \t Loss:1.515 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7338 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7339 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7340 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7341 \t Loss:1.514 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7342 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7343 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7344 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7345 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7346 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7347 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7348 \t Loss:1.514 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7349 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7350 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7351 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7352 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7353 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7354 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7355 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7356 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7357 \t Loss:1.513 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7358 \t Loss:1.512 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7359 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7360 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7361 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7362 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7363 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7364 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7365 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7366 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7367 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7368 \t Loss:1.512 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7369 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7370 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7371 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7372 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7373 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7374 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7375 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7376 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7377 \t Loss:1.511 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7378 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7379 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7380 \t Loss:1.511 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7381 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7382 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7383 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7384 \t Loss:1.510 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7385 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7386 \t Loss:1.510 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7387 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7388 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7389 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7390 \t Loss:1.510 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7391 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7392 \t Loss:1.509 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7393 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7394 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7395 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7396 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7397 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7398 \t Loss:1.509 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7399 \t Loss:1.509 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7400 \t Loss:1.509 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7401 \t Loss:1.508 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7402 \t Loss:1.508 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7403 \t Loss:1.508 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7404 \t Loss:1.508 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7405 \t Loss:1.508 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7406 \t Loss:1.508 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7407 \t Loss:1.508 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7408 \t Loss:1.508 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7409 \t Loss:1.508 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7410 \t Loss:1.508 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7411 \t Loss:1.507 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7412 \t Loss:1.507 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7413 \t Loss:1.507 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7414 \t Loss:1.507 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7415 \t Loss:1.507 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7416 \t Loss:1.507 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7417 \t Loss:1.507 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7418 \t Loss:1.507 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7419 \t Loss:1.507 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7420 \t Loss:1.507 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7421 \t Loss:1.507 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7422 \t Loss:1.506 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7423 \t Loss:1.506 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7424 \t Loss:1.506 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7425 \t Loss:1.506 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7426 \t Loss:1.506 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7427 \t Loss:1.506 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7428 \t Loss:1.506 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7429 \t Loss:1.506 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7430 \t Loss:1.506 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7431 \t Loss:1.506 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7432 \t Loss:1.506 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7433 \t Loss:1.505 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7434 \t Loss:1.505 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7435 \t Loss:1.505 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7436 \t Loss:1.505 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7437 \t Loss:1.505 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7438 \t Loss:1.505 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7439 \t Loss:1.505 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7440 \t Loss:1.505 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7441 \t Loss:1.505 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7442 \t Loss:1.505 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7443 \t Loss:1.505 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7444 \t Loss:1.505 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7445 \t Loss:1.504 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7446 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7447 \t Loss:1.504 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7448 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7449 \t Loss:1.504 \t error(train):84.9% \t error(val):83.8%\n",
      "iter:7450 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7451 \t Loss:1.504 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7452 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7453 \t Loss:1.504 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7454 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7455 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7456 \t Loss:1.504 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7457 \t Loss:1.503 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7458 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7459 \t Loss:1.503 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7460 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7461 \t Loss:1.503 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7462 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7463 \t Loss:1.503 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7464 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7465 \t Loss:1.503 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7466 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7467 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7468 \t Loss:1.503 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7469 \t Loss:1.503 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7470 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7471 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7472 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7473 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7474 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7475 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7476 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7477 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7478 \t Loss:1.502 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7479 \t Loss:1.502 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7480 \t Loss:1.502 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7481 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7482 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7483 \t Loss:1.501 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7484 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7485 \t Loss:1.501 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7486 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7487 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7488 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7489 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7490 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7491 \t Loss:1.501 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7492 \t Loss:1.501 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7493 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7494 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7495 \t Loss:1.500 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7496 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7497 \t Loss:1.500 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7498 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7499 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7500 \t Loss:1.500 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7501 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7502 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7503 \t Loss:1.500 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7504 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7505 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7506 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7507 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7508 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7509 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7510 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7511 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7512 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7513 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7514 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7515 \t Loss:1.499 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7516 \t Loss:1.499 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7517 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7518 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7519 \t Loss:1.498 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7520 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7521 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7522 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7523 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7524 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7525 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7526 \t Loss:1.498 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7527 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7528 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7529 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7530 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7531 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7532 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7533 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7534 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7535 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7536 \t Loss:1.497 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7537 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7538 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7539 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7540 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7541 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7542 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7543 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7544 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7545 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7546 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7547 \t Loss:1.496 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7548 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7549 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7550 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7551 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7552 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7553 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7554 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7555 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7556 \t Loss:1.495 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7557 \t Loss:1.494 \t error(train):84.9% \t error(val):83.9%\n",
      "iter:7558 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7559 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7560 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7561 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7562 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7563 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7564 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7565 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7566 \t Loss:1.494 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7567 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7568 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7569 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7570 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7571 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7572 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7573 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7574 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7575 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7576 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7577 \t Loss:1.493 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7578 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7579 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7580 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7581 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7582 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7583 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7584 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7585 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7586 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7587 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7588 \t Loss:1.492 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7589 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7590 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7591 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7592 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7593 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7594 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7595 \t Loss:1.491 \t error(train):85.0% \t error(val):84.0%\n",
      "iter:7596 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7597 \t Loss:1.491 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7598 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7599 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7600 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7601 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7602 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7603 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7604 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7605 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7606 \t Loss:1.490 \t error(train):85.0% \t error(val):84.0%\n",
      "iter:7607 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7608 \t Loss:1.490 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7609 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7610 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7611 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7612 \t Loss:1.489 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7613 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7614 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7615 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7616 \t Loss:1.489 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7617 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7618 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7619 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7620 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7621 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7622 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7623 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7624 \t Loss:1.488 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7625 \t Loss:1.488 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7626 \t Loss:1.488 \t error(train):85.0% \t error(val):84.0%\n",
      "iter:7627 \t Loss:1.488 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7628 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7629 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7630 \t Loss:1.487 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7631 \t Loss:1.487 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7632 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7633 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7634 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7635 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7636 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7637 \t Loss:1.487 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7638 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7639 \t Loss:1.486 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7640 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7641 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7642 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7643 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7644 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7645 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7646 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7647 \t Loss:1.486 \t error(train):85.0% \t error(val):84.0%\n",
      "iter:7648 \t Loss:1.486 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7649 \t Loss:1.485 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7650 \t Loss:1.485 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7651 \t Loss:1.485 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7652 \t Loss:1.485 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7653 \t Loss:1.485 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7654 \t Loss:1.485 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7655 \t Loss:1.485 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7656 \t Loss:1.485 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7657 \t Loss:1.485 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7658 \t Loss:1.485 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7659 \t Loss:1.485 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7660 \t Loss:1.484 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7661 \t Loss:1.484 \t error(train):85.0% \t error(val):84.0%\n",
      "iter:7662 \t Loss:1.484 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7663 \t Loss:1.484 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7664 \t Loss:1.484 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7665 \t Loss:1.484 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7666 \t Loss:1.484 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7667 \t Loss:1.484 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7668 \t Loss:1.484 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7669 \t Loss:1.484 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7670 \t Loss:1.484 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7671 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7672 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7673 \t Loss:1.483 \t error(train):85.1% \t error(val):84.0%\n",
      "iter:7674 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7675 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7676 \t Loss:1.483 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7677 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7678 \t Loss:1.483 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7679 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7680 \t Loss:1.483 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7681 \t Loss:1.483 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7682 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7683 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7684 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7685 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7686 \t Loss:1.482 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7687 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7688 \t Loss:1.482 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7689 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7690 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7691 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7692 \t Loss:1.482 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7693 \t Loss:1.481 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7694 \t Loss:1.481 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7695 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7696 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7697 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7698 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7699 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7700 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7701 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7702 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7703 \t Loss:1.480 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7704 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7705 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7706 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7707 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7708 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7709 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7710 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7711 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7712 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7713 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7714 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7715 \t Loss:1.479 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7716 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7717 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7718 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7719 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7720 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7721 \t Loss:1.478 \t error(train):85.1% \t error(val):84.0%\n",
      "iter:7722 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7723 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7724 \t Loss:1.478 \t error(train):85.0% \t error(val):83.9%\n",
      "iter:7725 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7726 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7727 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7728 \t Loss:1.478 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7729 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7730 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7731 \t Loss:1.477 \t error(train):85.1% \t error(val):83.8%\n",
      "iter:7732 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7733 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7734 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7735 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7736 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7737 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7738 \t Loss:1.477 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7739 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7740 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7741 \t Loss:1.476 \t error(train):85.1% \t error(val):84.0%\n",
      "iter:7742 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7743 \t Loss:1.476 \t error(train):85.1% \t error(val):84.0%\n",
      "iter:7744 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7745 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7746 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7747 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7748 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7749 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7750 \t Loss:1.476 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7751 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7752 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7753 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7754 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7755 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7756 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7757 \t Loss:1.475 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7758 \t Loss:1.475 \t error(train):85.2% \t error(val):83.8%\n",
      "iter:7759 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7760 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7761 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7762 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7763 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7764 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7765 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7766 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7767 \t Loss:1.474 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7768 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7769 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7770 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7771 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7772 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7773 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7774 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7775 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7776 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7777 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7778 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7779 \t Loss:1.473 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7780 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7781 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7782 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7783 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7784 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7785 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7786 \t Loss:1.472 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7787 \t Loss:1.472 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7788 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7789 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7790 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7791 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7792 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7793 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7794 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7795 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7796 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7797 \t Loss:1.471 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7798 \t Loss:1.470 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7799 \t Loss:1.470 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7800 \t Loss:1.469 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7801 \t Loss:1.469 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7802 \t Loss:1.469 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7803 \t Loss:1.469 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7804 \t Loss:1.469 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7805 \t Loss:1.469 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7806 \t Loss:1.469 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7807 \t Loss:1.469 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7808 \t Loss:1.469 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7809 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7810 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7811 \t Loss:1.468 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7812 \t Loss:1.468 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7813 \t Loss:1.468 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7814 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7815 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7816 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7817 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7818 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7819 \t Loss:1.468 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7820 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7821 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7822 \t Loss:1.467 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7823 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7824 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7825 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7826 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7827 \t Loss:1.467 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7828 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7829 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7830 \t Loss:1.467 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7831 \t Loss:1.467 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7832 \t Loss:1.467 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7833 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7834 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7835 \t Loss:1.466 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7836 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7837 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7838 \t Loss:1.466 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7839 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7840 \t Loss:1.466 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7841 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7842 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7843 \t Loss:1.466 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7844 \t Loss:1.465 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7845 \t Loss:1.465 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7846 \t Loss:1.465 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7847 \t Loss:1.465 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7848 \t Loss:1.465 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7849 \t Loss:1.465 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7850 \t Loss:1.465 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7851 \t Loss:1.465 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7852 \t Loss:1.465 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7853 \t Loss:1.465 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7854 \t Loss:1.465 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7855 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7856 \t Loss:1.464 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7857 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7858 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7859 \t Loss:1.464 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7860 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7861 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7862 \t Loss:1.464 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7863 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7864 \t Loss:1.464 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7865 \t Loss:1.464 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7866 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7867 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7868 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7869 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7870 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7871 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7872 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7873 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7874 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7875 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7876 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7877 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7878 \t Loss:1.463 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7879 \t Loss:1.463 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7880 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7881 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7882 \t Loss:1.462 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7883 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7884 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7885 \t Loss:1.462 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7886 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7887 \t Loss:1.462 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7888 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7889 \t Loss:1.462 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7890 \t Loss:1.462 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7891 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7892 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7893 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7894 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7895 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7896 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7897 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7898 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7899 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7900 \t Loss:1.461 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7901 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7902 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7903 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7904 \t Loss:1.460 \t error(train):85.1% \t error(val):83.9%\n",
      "iter:7905 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7906 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7907 \t Loss:1.460 \t error(train):85.2% \t error(val):83.9%\n",
      "iter:7908 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7909 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7910 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7911 \t Loss:1.460 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7912 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7913 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7914 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7915 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7916 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7917 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7918 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7919 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7920 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7921 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7922 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7923 \t Loss:1.459 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7924 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7925 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7926 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7927 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7928 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7929 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7930 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7931 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7932 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7933 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7934 \t Loss:1.458 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7935 \t Loss:1.458 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7936 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7937 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7938 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7939 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7940 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7941 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7942 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7943 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7944 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7945 \t Loss:1.457 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7946 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7947 \t Loss:1.456 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7948 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7949 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7950 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7951 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7952 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7953 \t Loss:1.456 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7954 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7955 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7956 \t Loss:1.456 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7957 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7958 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7959 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7960 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7961 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7962 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7963 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7964 \t Loss:1.455 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:7965 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7966 \t Loss:1.455 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7967 \t Loss:1.455 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:7968 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7969 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7970 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7971 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7972 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7973 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7974 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7975 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7976 \t Loss:1.454 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:7977 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7978 \t Loss:1.454 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7979 \t Loss:1.454 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:7980 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7981 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7982 \t Loss:1.453 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7983 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7984 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7985 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7986 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7987 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7988 \t Loss:1.453 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:7989 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7990 \t Loss:1.453 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7991 \t Loss:1.452 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7992 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7993 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7994 \t Loss:1.452 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7995 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7996 \t Loss:1.452 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:7997 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7998 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:7999 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8000 \t Loss:1.452 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8001 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8002 \t Loss:1.452 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8003 \t Loss:1.451 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8004 \t Loss:1.451 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8005 \t Loss:1.451 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8006 \t Loss:1.451 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8007 \t Loss:1.451 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8008 \t Loss:1.451 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8009 \t Loss:1.451 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8010 \t Loss:1.451 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8011 \t Loss:1.451 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8012 \t Loss:1.451 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8013 \t Loss:1.450 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8014 \t Loss:1.450 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8015 \t Loss:1.450 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8016 \t Loss:1.450 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8017 \t Loss:1.450 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8018 \t Loss:1.450 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8019 \t Loss:1.450 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8020 \t Loss:1.450 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8021 \t Loss:1.450 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8022 \t Loss:1.450 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8023 \t Loss:1.450 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8024 \t Loss:1.449 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8025 \t Loss:1.449 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8026 \t Loss:1.449 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8027 \t Loss:1.449 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8028 \t Loss:1.449 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8029 \t Loss:1.449 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8030 \t Loss:1.449 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8031 \t Loss:1.449 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8032 \t Loss:1.449 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8033 \t Loss:1.449 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8034 \t Loss:1.449 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8035 \t Loss:1.448 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8036 \t Loss:1.448 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8037 \t Loss:1.448 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8038 \t Loss:1.448 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8039 \t Loss:1.448 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8040 \t Loss:1.448 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8041 \t Loss:1.448 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8042 \t Loss:1.448 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8043 \t Loss:1.448 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8044 \t Loss:1.448 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8045 \t Loss:1.448 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8046 \t Loss:1.447 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8047 \t Loss:1.447 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8048 \t Loss:1.447 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8049 \t Loss:1.447 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8050 \t Loss:1.447 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8051 \t Loss:1.447 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8052 \t Loss:1.447 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8053 \t Loss:1.447 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8054 \t Loss:1.447 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8055 \t Loss:1.447 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8056 \t Loss:1.447 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8057 \t Loss:1.446 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8058 \t Loss:1.446 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8059 \t Loss:1.446 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8060 \t Loss:1.446 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8061 \t Loss:1.446 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8062 \t Loss:1.446 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8063 \t Loss:1.446 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8064 \t Loss:1.446 \t error(train):85.2% \t error(val):84.1%\n",
      "iter:8065 \t Loss:1.446 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8066 \t Loss:1.446 \t error(train):85.2% \t error(val):84.0%\n",
      "iter:8067 \t Loss:1.446 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8068 \t Loss:1.446 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8069 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8070 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8071 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8072 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8073 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8074 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8075 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8076 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8077 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8078 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8079 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8080 \t Loss:1.445 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8081 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8082 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8083 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8084 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8085 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8086 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8087 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8088 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8089 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8090 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8091 \t Loss:1.444 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8092 \t Loss:1.443 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8093 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8094 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8095 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8096 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8097 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8098 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8099 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8100 \t Loss:1.443 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8101 \t Loss:1.443 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8102 \t Loss:1.443 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8103 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8104 \t Loss:1.442 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8105 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8106 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8107 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8108 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8109 \t Loss:1.442 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8110 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8111 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8112 \t Loss:1.442 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8113 \t Loss:1.442 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8114 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8115 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8116 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8117 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8118 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8119 \t Loss:1.441 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8120 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8121 \t Loss:1.441 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8122 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8123 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8124 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8125 \t Loss:1.441 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8126 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8127 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8128 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8129 \t Loss:1.440 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8130 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8131 \t Loss:1.440 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8132 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8133 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8134 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8135 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8136 \t Loss:1.440 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8137 \t Loss:1.440 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8138 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8139 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8140 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8141 \t Loss:1.439 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8142 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8143 \t Loss:1.439 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8144 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8145 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8146 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8147 \t Loss:1.439 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8148 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8149 \t Loss:1.439 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8150 \t Loss:1.439 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8151 \t Loss:1.438 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8152 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8153 \t Loss:1.438 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8154 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8155 \t Loss:1.438 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8156 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8157 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8158 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8159 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8160 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8161 \t Loss:1.438 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8162 \t Loss:1.438 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8163 \t Loss:1.438 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8164 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8165 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8166 \t Loss:1.437 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8167 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8168 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8169 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8170 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8171 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8172 \t Loss:1.437 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8173 \t Loss:1.437 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8174 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8175 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8176 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8177 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8178 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8179 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8180 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8181 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8182 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8183 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8184 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8185 \t Loss:1.436 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8186 \t Loss:1.436 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8187 \t Loss:1.436 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8188 \t Loss:1.436 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8189 \t Loss:1.435 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8190 \t Loss:1.435 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8191 \t Loss:1.435 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8192 \t Loss:1.435 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8193 \t Loss:1.435 \t error(train):85.3% \t error(val):84.0%\n",
      "iter:8194 \t Loss:1.435 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8195 \t Loss:1.435 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8196 \t Loss:1.435 \t error(train):85.4% \t error(val):84.0%\n",
      "iter:8197 \t Loss:1.435 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8198 \t Loss:1.435 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8199 \t Loss:1.435 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8200 \t Loss:1.434 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8201 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8202 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8203 \t Loss:1.434 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8204 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8205 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8206 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8207 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8208 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8209 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8210 \t Loss:1.434 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8211 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8212 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8213 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8214 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8215 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8216 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8217 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8218 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8219 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8220 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8221 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8222 \t Loss:1.433 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8223 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8224 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8225 \t Loss:1.433 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8226 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8227 \t Loss:1.432 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8228 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8229 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8230 \t Loss:1.432 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8231 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8232 \t Loss:1.432 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8233 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8234 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8235 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8236 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8237 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8238 \t Loss:1.432 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8239 \t Loss:1.431 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8240 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8241 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8242 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8243 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8244 \t Loss:1.431 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8245 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8246 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8247 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8248 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8249 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8250 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8251 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8252 \t Loss:1.431 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8253 \t Loss:1.430 \t error(train):85.3% \t error(val):84.1%\n",
      "iter:8254 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8255 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8256 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8257 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8258 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8259 \t Loss:1.430 \t error(train):85.3% \t error(val):84.2%\n",
      "iter:8260 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8261 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8262 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8263 \t Loss:1.430 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8264 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8265 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8266 \t Loss:1.429 \t error(train):85.4% \t error(val):84.0%\n",
      "iter:8267 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8268 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8269 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8270 \t Loss:1.429 \t error(train):85.3% \t error(val):84.2%\n",
      "iter:8271 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8272 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8273 \t Loss:1.429 \t error(train):85.3% \t error(val):84.2%\n",
      "iter:8274 \t Loss:1.429 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8275 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8276 \t Loss:1.428 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8277 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8278 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8279 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8280 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8281 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8282 \t Loss:1.428 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8283 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8284 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8285 \t Loss:1.428 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8286 \t Loss:1.428 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8287 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8288 \t Loss:1.427 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8289 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8290 \t Loss:1.427 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8291 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8292 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8293 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8294 \t Loss:1.427 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8295 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8296 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8297 \t Loss:1.427 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8298 \t Loss:1.427 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8299 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8300 \t Loss:1.426 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8301 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8302 \t Loss:1.426 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8303 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8304 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8305 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8306 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8307 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8308 \t Loss:1.426 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8309 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8310 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8311 \t Loss:1.426 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8312 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8313 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8314 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8315 \t Loss:1.425 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8316 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8317 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8318 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8319 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8320 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8321 \t Loss:1.425 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8322 \t Loss:1.425 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8323 \t Loss:1.425 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8324 \t Loss:1.424 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8325 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8326 \t Loss:1.424 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8327 \t Loss:1.424 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8328 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8329 \t Loss:1.424 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8330 \t Loss:1.424 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8331 \t Loss:1.424 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8332 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8333 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8334 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8335 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8336 \t Loss:1.424 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8337 \t Loss:1.423 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8338 \t Loss:1.423 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8339 \t Loss:1.423 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8340 \t Loss:1.423 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8341 \t Loss:1.423 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8342 \t Loss:1.423 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8343 \t Loss:1.423 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8344 \t Loss:1.423 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8345 \t Loss:1.423 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8346 \t Loss:1.423 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8347 \t Loss:1.423 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8348 \t Loss:1.423 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8349 \t Loss:1.423 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8350 \t Loss:1.422 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8351 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8352 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8353 \t Loss:1.422 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8354 \t Loss:1.422 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8355 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8356 \t Loss:1.422 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8357 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8358 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8359 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8360 \t Loss:1.422 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8361 \t Loss:1.422 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8362 \t Loss:1.421 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8363 \t Loss:1.421 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8364 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8365 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8366 \t Loss:1.421 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8367 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8368 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8369 \t Loss:1.421 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8370 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8371 \t Loss:1.421 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8372 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8373 \t Loss:1.421 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8374 \t Loss:1.421 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8375 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8376 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8377 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8378 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8379 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8380 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8381 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8382 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8383 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8384 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8385 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8386 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8387 \t Loss:1.420 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8388 \t Loss:1.420 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8389 \t Loss:1.419 \t error(train):85.4% \t error(val):84.2%\n",
      "iter:8390 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8391 \t Loss:1.419 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8392 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8393 \t Loss:1.419 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8394 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8395 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8396 \t Loss:1.419 \t error(train):85.4% \t error(val):84.1%\n",
      "iter:8397 \t Loss:1.419 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8398 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8399 \t Loss:1.419 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8400 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8401 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8402 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8403 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8404 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8405 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8406 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8407 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8408 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8409 \t Loss:1.418 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8410 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8411 \t Loss:1.418 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8412 \t Loss:1.418 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8413 \t Loss:1.418 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8414 \t Loss:1.417 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8415 \t Loss:1.417 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8416 \t Loss:1.417 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8417 \t Loss:1.417 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8418 \t Loss:1.417 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8419 \t Loss:1.417 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8420 \t Loss:1.417 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8421 \t Loss:1.417 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8422 \t Loss:1.417 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8423 \t Loss:1.417 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8424 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8425 \t Loss:1.416 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8426 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8427 \t Loss:1.416 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8428 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8429 \t Loss:1.416 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8430 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8431 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8432 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8433 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8434 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8435 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8436 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8437 \t Loss:1.416 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8438 \t Loss:1.416 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8439 \t Loss:1.416 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8440 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8441 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8442 \t Loss:1.415 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8443 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8444 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8445 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8446 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8447 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8448 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8449 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8450 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8451 \t Loss:1.415 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8452 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8453 \t Loss:1.414 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8454 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8455 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8456 \t Loss:1.414 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8457 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8458 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8459 \t Loss:1.414 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8460 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8461 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8462 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8463 \t Loss:1.414 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8464 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8465 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8466 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8467 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8468 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8469 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8470 \t Loss:1.413 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8471 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8472 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8473 \t Loss:1.413 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8474 \t Loss:1.413 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8475 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8476 \t Loss:1.412 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8477 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8478 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8479 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8480 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8481 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8482 \t Loss:1.412 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8483 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8484 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8485 \t Loss:1.412 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8486 \t Loss:1.412 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8487 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8488 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8489 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8490 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8491 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8492 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8493 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8494 \t Loss:1.411 \t error(train):85.5% \t error(val):84.1%\n",
      "iter:8495 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8496 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8497 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8498 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8499 \t Loss:1.411 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8500 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8501 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8502 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8503 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8504 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8505 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8506 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8507 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8508 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8509 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8510 \t Loss:1.410 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8511 \t Loss:1.410 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8512 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8513 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8514 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8515 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8516 \t Loss:1.409 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8517 \t Loss:1.409 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8518 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8519 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8520 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8521 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8522 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8523 \t Loss:1.409 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8524 \t Loss:1.409 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8525 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8526 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8527 \t Loss:1.408 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8528 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8529 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8530 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8531 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8532 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8533 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8534 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8535 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8536 \t Loss:1.408 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8537 \t Loss:1.408 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8538 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8539 \t Loss:1.407 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8540 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8541 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8542 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8543 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8544 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8545 \t Loss:1.407 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8546 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8547 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8548 \t Loss:1.407 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8549 \t Loss:1.407 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8550 \t Loss:1.406 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8551 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8552 \t Loss:1.406 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8553 \t Loss:1.406 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8554 \t Loss:1.406 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8555 \t Loss:1.406 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8556 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8557 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8558 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8559 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8560 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8561 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8562 \t Loss:1.406 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8563 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8564 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8565 \t Loss:1.405 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8566 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8567 \t Loss:1.405 \t error(train):85.6% \t error(val):84.1%\n",
      "iter:8568 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8569 \t Loss:1.405 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8570 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8571 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8572 \t Loss:1.405 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8573 \t Loss:1.404 \t error(train):85.6% \t error(val):84.1%\n",
      "iter:8574 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8575 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8576 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8577 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8578 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8579 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8580 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8581 \t Loss:1.404 \t error(train):85.6% \t error(val):84.1%\n",
      "iter:8582 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8583 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8584 \t Loss:1.404 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8585 \t Loss:1.404 \t error(train):85.6% \t error(val):84.1%\n",
      "iter:8586 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8587 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8588 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8589 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8590 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8591 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8592 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8593 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8594 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8595 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8596 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8597 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8598 \t Loss:1.403 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8599 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8600 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8601 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8602 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8603 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8604 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8605 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8606 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8607 \t Loss:1.402 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8608 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8609 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8610 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8611 \t Loss:1.402 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8612 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8613 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8614 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8615 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8616 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8617 \t Loss:1.401 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8618 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8619 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8620 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8621 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8622 \t Loss:1.401 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8623 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8624 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8625 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8626 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8627 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8628 \t Loss:1.400 \t error(train):85.5% \t error(val):84.2%\n",
      "iter:8629 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8630 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8631 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8632 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8633 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8634 \t Loss:1.400 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8635 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8636 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8637 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8638 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8639 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8640 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8641 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8642 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8643 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8644 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8645 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8646 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8647 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8648 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8649 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8650 \t Loss:1.399 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8651 \t Loss:1.398 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8652 \t Loss:1.398 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8653 \t Loss:1.398 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8654 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8655 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8656 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8657 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8658 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8659 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8660 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8661 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8662 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8663 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8664 \t Loss:1.397 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8665 \t Loss:1.396 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8666 \t Loss:1.396 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8667 \t Loss:1.396 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8668 \t Loss:1.396 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8669 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8670 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8671 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8672 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8673 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8674 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8675 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8676 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8677 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8678 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8679 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8680 \t Loss:1.395 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8681 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8682 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8683 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8684 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8685 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8686 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8687 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8688 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8689 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8690 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8691 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8692 \t Loss:1.394 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8693 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8694 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8695 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8696 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8697 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8698 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8699 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8700 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8701 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8702 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8703 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8704 \t Loss:1.393 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8705 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8706 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8707 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8708 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8709 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8710 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8711 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8712 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8713 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8714 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8715 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8716 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8717 \t Loss:1.392 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8718 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8719 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8720 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8721 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8722 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8723 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8724 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8725 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8726 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8727 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8728 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8729 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8730 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8731 \t Loss:1.391 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8732 \t Loss:1.391 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8733 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8734 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8735 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8736 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8737 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8738 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8739 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8740 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8741 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8742 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8743 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8744 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8745 \t Loss:1.390 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8746 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8747 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8748 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8749 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8750 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8751 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8752 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8753 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8754 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8755 \t Loss:1.389 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8756 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8757 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8758 \t Loss:1.389 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8759 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8760 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8761 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8762 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8763 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8764 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8765 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8766 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8767 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8768 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8769 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8770 \t Loss:1.388 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8771 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8772 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8773 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8774 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8775 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8776 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8777 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8778 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8779 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8780 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8781 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8782 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8783 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8784 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8785 \t Loss:1.387 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8786 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8787 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8788 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8789 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8790 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8791 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8792 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8793 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8794 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8795 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8796 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8797 \t Loss:1.386 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8798 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8799 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8800 \t Loss:1.385 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8801 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8802 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8803 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8804 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8805 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8806 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8807 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8808 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8809 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8810 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8811 \t Loss:1.385 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8812 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8813 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8814 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8815 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8816 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8817 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8818 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8819 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8820 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8821 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8822 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8823 \t Loss:1.384 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8824 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8825 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8826 \t Loss:1.383 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8827 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8828 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8829 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8830 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8831 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8832 \t Loss:1.383 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8833 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8834 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8835 \t Loss:1.383 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8836 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8837 \t Loss:1.382 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8838 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8839 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8840 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8841 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8842 \t Loss:1.382 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8843 \t Loss:1.382 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8844 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8845 \t Loss:1.382 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8846 \t Loss:1.382 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8847 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8848 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8849 \t Loss:1.382 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8850 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8851 \t Loss:1.381 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8852 \t Loss:1.381 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8853 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8854 \t Loss:1.381 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8855 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8856 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8857 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8858 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8859 \t Loss:1.381 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8860 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8861 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8862 \t Loss:1.381 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8863 \t Loss:1.381 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8864 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8865 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8866 \t Loss:1.380 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8867 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8868 \t Loss:1.380 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8869 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8870 \t Loss:1.380 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8871 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8872 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8873 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8874 \t Loss:1.380 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8875 \t Loss:1.380 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8876 \t Loss:1.380 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8877 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8878 \t Loss:1.379 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8879 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8880 \t Loss:1.379 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8881 \t Loss:1.379 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8882 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8883 \t Loss:1.379 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8884 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8885 \t Loss:1.379 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8886 \t Loss:1.379 \t error(train):85.6% \t error(val):84.2%\n",
      "iter:8887 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8888 \t Loss:1.379 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8889 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8890 \t Loss:1.379 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8891 \t Loss:1.379 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8892 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8893 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8894 \t Loss:1.378 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8895 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8896 \t Loss:1.378 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8897 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8898 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8899 \t Loss:1.378 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8900 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8901 \t Loss:1.378 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8902 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8903 \t Loss:1.378 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8904 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8905 \t Loss:1.378 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8906 \t Loss:1.378 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8907 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8908 \t Loss:1.377 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8909 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8910 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8911 \t Loss:1.377 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8912 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8913 \t Loss:1.377 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8914 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8915 \t Loss:1.377 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8916 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8917 \t Loss:1.377 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8918 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8919 \t Loss:1.377 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8920 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8921 \t Loss:1.377 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8922 \t Loss:1.377 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8923 \t Loss:1.376 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8924 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8925 \t Loss:1.376 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8926 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8927 \t Loss:1.376 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8928 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8929 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8930 \t Loss:1.376 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8931 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8932 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8933 \t Loss:1.376 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8934 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8935 \t Loss:1.376 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8936 \t Loss:1.376 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8937 \t Loss:1.376 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8938 \t Loss:1.375 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8939 \t Loss:1.375 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8940 \t Loss:1.375 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8941 \t Loss:1.375 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8942 \t Loss:1.375 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8943 \t Loss:1.375 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8944 \t Loss:1.375 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8945 \t Loss:1.375 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8946 \t Loss:1.375 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8947 \t Loss:1.375 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8948 \t Loss:1.375 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8949 \t Loss:1.375 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8950 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8951 \t Loss:1.374 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8952 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8953 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8954 \t Loss:1.374 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8955 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8956 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8957 \t Loss:1.374 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8958 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8959 \t Loss:1.374 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8960 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8961 \t Loss:1.374 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8962 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8963 \t Loss:1.374 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8964 \t Loss:1.374 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8965 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8966 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8967 \t Loss:1.373 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8968 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8969 \t Loss:1.373 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8970 \t Loss:1.373 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8971 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8972 \t Loss:1.373 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8973 \t Loss:1.373 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8974 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8975 \t Loss:1.373 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8976 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8977 \t Loss:1.373 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8978 \t Loss:1.372 \t error(train):85.6% \t error(val):84.3%\n",
      "iter:8979 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8980 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8981 \t Loss:1.372 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8982 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8983 \t Loss:1.372 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8984 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8985 \t Loss:1.372 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8986 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8987 \t Loss:1.372 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8988 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8989 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8990 \t Loss:1.372 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8991 \t Loss:1.372 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8992 \t Loss:1.371 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8993 \t Loss:1.371 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8994 \t Loss:1.371 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8995 \t Loss:1.371 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8996 \t Loss:1.371 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8997 \t Loss:1.371 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:8998 \t Loss:1.371 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:8999 \t Loss:1.371 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9000 \t Loss:1.371 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9001 \t Loss:1.371 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9002 \t Loss:1.371 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9003 \t Loss:1.371 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9004 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9005 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9006 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9007 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9008 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9009 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9010 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9011 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9012 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9013 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9014 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9015 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9016 \t Loss:1.370 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9017 \t Loss:1.370 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9018 \t Loss:1.369 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9019 \t Loss:1.369 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9020 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9021 \t Loss:1.369 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9022 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9023 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9024 \t Loss:1.369 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9025 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9026 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9027 \t Loss:1.369 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9028 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9029 \t Loss:1.369 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9030 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9031 \t Loss:1.369 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9032 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9033 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9034 \t Loss:1.368 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9035 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9036 \t Loss:1.368 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9037 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9038 \t Loss:1.368 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9039 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9040 \t Loss:1.368 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9041 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9042 \t Loss:1.368 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9043 \t Loss:1.368 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9044 \t Loss:1.368 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9045 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9046 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9047 \t Loss:1.367 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9048 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9049 \t Loss:1.367 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9050 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9051 \t Loss:1.367 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9052 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9053 \t Loss:1.367 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9054 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9055 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9056 \t Loss:1.367 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9057 \t Loss:1.367 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9058 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9059 \t Loss:1.366 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9060 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9061 \t Loss:1.366 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9062 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9063 \t Loss:1.366 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9064 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9065 \t Loss:1.366 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9066 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9067 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9068 \t Loss:1.366 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9069 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9070 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9071 \t Loss:1.366 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9072 \t Loss:1.365 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9073 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9074 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9075 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9076 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9077 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9078 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9079 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9080 \t Loss:1.365 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9081 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9082 \t Loss:1.365 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9083 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9084 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9085 \t Loss:1.365 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9086 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9087 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9088 \t Loss:1.364 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9089 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9090 \t Loss:1.364 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9091 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9092 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9093 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9094 \t Loss:1.364 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9095 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9096 \t Loss:1.364 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9097 \t Loss:1.364 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9098 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9099 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9100 \t Loss:1.363 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9101 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9102 \t Loss:1.363 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9103 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9104 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9105 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9106 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9107 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9108 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9109 \t Loss:1.363 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9110 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9111 \t Loss:1.363 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9112 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9113 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9114 \t Loss:1.362 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9115 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9116 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9117 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9118 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9119 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9120 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9121 \t Loss:1.362 \t error(train):85.7% \t error(val):84.2%\n",
      "iter:9122 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9123 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9124 \t Loss:1.362 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9125 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9126 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9127 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9128 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9129 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9130 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9131 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9132 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9133 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9134 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9135 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9136 \t Loss:1.361 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9137 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9138 \t Loss:1.361 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9139 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9140 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9141 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9142 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9143 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9144 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9145 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9146 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9147 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9148 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9149 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9150 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9151 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9152 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9153 \t Loss:1.360 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9154 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9155 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9156 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9157 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9158 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9159 \t Loss:1.359 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9160 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9161 \t Loss:1.359 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9162 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9163 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9164 \t Loss:1.359 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9165 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9166 \t Loss:1.359 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9167 \t Loss:1.359 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9168 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9169 \t Loss:1.358 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9170 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9171 \t Loss:1.358 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9172 \t Loss:1.358 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9173 \t Loss:1.358 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9174 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9175 \t Loss:1.358 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9176 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9177 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9178 \t Loss:1.358 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9179 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9180 \t Loss:1.358 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9181 \t Loss:1.357 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9182 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9183 \t Loss:1.357 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9184 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9185 \t Loss:1.357 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9186 \t Loss:1.357 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9187 \t Loss:1.357 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9188 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9189 \t Loss:1.357 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9190 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9191 \t Loss:1.357 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9192 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9193 \t Loss:1.357 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9194 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9195 \t Loss:1.357 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9196 \t Loss:1.357 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9197 \t Loss:1.357 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9198 \t Loss:1.357 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9199 \t Loss:1.356 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9200 \t Loss:1.356 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9201 \t Loss:1.356 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9202 \t Loss:1.356 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9203 \t Loss:1.356 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9204 \t Loss:1.356 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9205 \t Loss:1.356 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9206 \t Loss:1.356 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9207 \t Loss:1.356 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9208 \t Loss:1.356 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9209 \t Loss:1.356 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9210 \t Loss:1.356 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9211 \t Loss:1.356 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9212 \t Loss:1.356 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9213 \t Loss:1.355 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9214 \t Loss:1.355 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9215 \t Loss:1.355 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9216 \t Loss:1.355 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9217 \t Loss:1.355 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9218 \t Loss:1.355 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9219 \t Loss:1.355 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9220 \t Loss:1.355 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9221 \t Loss:1.355 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9222 \t Loss:1.355 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9223 \t Loss:1.355 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9224 \t Loss:1.355 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9225 \t Loss:1.355 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9226 \t Loss:1.355 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9227 \t Loss:1.354 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9228 \t Loss:1.354 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9229 \t Loss:1.354 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9230 \t Loss:1.354 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9231 \t Loss:1.354 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9232 \t Loss:1.354 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9233 \t Loss:1.354 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9234 \t Loss:1.354 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9235 \t Loss:1.354 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9236 \t Loss:1.354 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9237 \t Loss:1.354 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9238 \t Loss:1.354 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9239 \t Loss:1.354 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9240 \t Loss:1.353 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9241 \t Loss:1.353 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9242 \t Loss:1.353 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9243 \t Loss:1.353 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9244 \t Loss:1.353 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9245 \t Loss:1.353 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9246 \t Loss:1.353 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9247 \t Loss:1.353 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9248 \t Loss:1.353 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9249 \t Loss:1.353 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9250 \t Loss:1.353 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9251 \t Loss:1.353 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9252 \t Loss:1.353 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9253 \t Loss:1.353 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9254 \t Loss:1.353 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9255 \t Loss:1.353 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9256 \t Loss:1.353 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9257 \t Loss:1.352 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9258 \t Loss:1.352 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9259 \t Loss:1.352 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9260 \t Loss:1.352 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9261 \t Loss:1.352 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9262 \t Loss:1.352 \t error(train):85.7% \t error(val):84.3%\n",
      "iter:9263 \t Loss:1.352 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9264 \t Loss:1.352 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9265 \t Loss:1.352 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9266 \t Loss:1.352 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9267 \t Loss:1.352 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9268 \t Loss:1.352 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9269 \t Loss:1.352 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9270 \t Loss:1.352 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9271 \t Loss:1.352 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9272 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9273 \t Loss:1.351 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9274 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9275 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9276 \t Loss:1.351 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9277 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9278 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9279 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9280 \t Loss:1.351 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9281 \t Loss:1.351 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9282 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9283 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9284 \t Loss:1.351 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9285 \t Loss:1.351 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9286 \t Loss:1.350 \t error(train):85.7% \t error(val):84.4%\n",
      "iter:9287 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9288 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9289 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9290 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9291 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9292 \t Loss:1.350 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9293 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9294 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9295 \t Loss:1.350 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9296 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9297 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9298 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9299 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9300 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9301 \t Loss:1.350 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9302 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9303 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9304 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9305 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9306 \t Loss:1.349 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9307 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9308 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9309 \t Loss:1.349 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9310 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9311 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9312 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9313 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9314 \t Loss:1.349 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9315 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9316 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9317 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9318 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9319 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9320 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9321 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9322 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9323 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9324 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9325 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9326 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9327 \t Loss:1.348 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9328 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9329 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9330 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9331 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9332 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9333 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9334 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9335 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9336 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9337 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9338 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9339 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9340 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9341 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9342 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9343 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9344 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9345 \t Loss:1.347 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9346 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9347 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9348 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9349 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9350 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9351 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9352 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9353 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9354 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9355 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9356 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9357 \t Loss:1.346 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9358 \t Loss:1.346 \t error(train):85.8% \t error(val):84.2%\n",
      "iter:9359 \t Loss:1.345 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9360 \t Loss:1.345 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9361 \t Loss:1.345 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9362 \t Loss:1.345 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9363 \t Loss:1.345 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9364 \t Loss:1.345 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9365 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9366 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9367 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9368 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9369 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9370 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9371 \t Loss:1.344 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9372 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9373 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9374 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9375 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9376 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9377 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9378 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9379 \t Loss:1.344 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9380 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9381 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9382 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9383 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9384 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9385 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9386 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9387 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9388 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9389 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9390 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9391 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9392 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9393 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9394 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9395 \t Loss:1.343 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9396 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9397 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9398 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9399 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9400 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9401 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9402 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9403 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9404 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9405 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9406 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9407 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9408 \t Loss:1.342 \t error(train):85.8% \t error(val):84.3%\n",
      "iter:9409 \t Loss:1.342 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9410 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9411 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9412 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9413 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9414 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9415 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9416 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9417 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9418 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9419 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9420 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9421 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9422 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9423 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9424 \t Loss:1.341 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9425 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9426 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9427 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9428 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9429 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9430 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9431 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9432 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9433 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9434 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9435 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9436 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9437 \t Loss:1.340 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9438 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9439 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9440 \t Loss:1.340 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9441 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9442 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9443 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9444 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9445 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9446 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9447 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9448 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9449 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9450 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9451 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9452 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9453 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9454 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9455 \t Loss:1.339 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9456 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9457 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9458 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9459 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9460 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9461 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9462 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9463 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9464 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9465 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9466 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9467 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9468 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9469 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9470 \t Loss:1.338 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9471 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9472 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9473 \t Loss:1.337 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9474 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9475 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9476 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9477 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9478 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9479 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9480 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9481 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9482 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9483 \t Loss:1.337 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9484 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9485 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9486 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9487 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9488 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9489 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9490 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9491 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9492 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9493 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9494 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9495 \t Loss:1.336 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9496 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9497 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9498 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9499 \t Loss:1.336 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9500 \t Loss:1.336 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9501 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9502 \t Loss:1.335 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9503 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9504 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9505 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9506 \t Loss:1.335 \t error(train):85.9% \t error(val):84.3%\n",
      "iter:9507 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9508 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9509 \t Loss:1.335 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9510 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9511 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9512 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9513 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9514 \t Loss:1.335 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9515 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9516 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9517 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9518 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9519 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9520 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9521 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9522 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9523 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9524 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9525 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9526 \t Loss:1.334 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9527 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9528 \t Loss:1.334 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9529 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9530 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9531 \t Loss:1.333 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9532 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9533 \t Loss:1.333 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9534 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9535 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9536 \t Loss:1.333 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9537 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9538 \t Loss:1.333 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9539 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9540 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9541 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9542 \t Loss:1.333 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9543 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9544 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9545 \t Loss:1.333 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9546 \t Loss:1.332 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9547 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9548 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9549 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9550 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9551 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9552 \t Loss:1.332 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9553 \t Loss:1.332 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9554 \t Loss:1.332 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9555 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9556 \t Loss:1.332 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9557 \t Loss:1.332 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9558 \t Loss:1.331 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9559 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9560 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9561 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9562 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9563 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9564 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9565 \t Loss:1.331 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9566 \t Loss:1.331 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9567 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9568 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9569 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9570 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9571 \t Loss:1.331 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9572 \t Loss:1.331 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9573 \t Loss:1.330 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9574 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9575 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9576 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9577 \t Loss:1.330 \t error(train):85.8% \t error(val):84.4%\n",
      "iter:9578 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9579 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9580 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9581 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9582 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9583 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9584 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9585 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9586 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9587 \t Loss:1.330 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9588 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9589 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9590 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9591 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9592 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9593 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9594 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9595 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9596 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9597 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9598 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9599 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9600 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9601 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9602 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9603 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9604 \t Loss:1.329 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9605 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9606 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9607 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9608 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9609 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9610 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9611 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9612 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9613 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9614 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9615 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9616 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9617 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9618 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9619 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9620 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9621 \t Loss:1.328 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9622 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9623 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9624 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9625 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9626 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9627 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9628 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9629 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9630 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9631 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9632 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9633 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9634 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9635 \t Loss:1.327 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9636 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9637 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9638 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9639 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9640 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9641 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9642 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9643 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9644 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9645 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9646 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9647 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9648 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9649 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9650 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9651 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9652 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9653 \t Loss:1.326 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9654 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9655 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9656 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9657 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9658 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9659 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9660 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9661 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9662 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9663 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9664 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9665 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9666 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9667 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9668 \t Loss:1.325 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9669 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9670 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9671 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9672 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9673 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9674 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9675 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9676 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9677 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9678 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9679 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9680 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9681 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9682 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9683 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9684 \t Loss:1.324 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9685 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9686 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9687 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9688 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9689 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9690 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9691 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9692 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9693 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9694 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9695 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9696 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9697 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9698 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9699 \t Loss:1.323 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9700 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9701 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9702 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9703 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9704 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9705 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9706 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9707 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9708 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9709 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9710 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9711 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9712 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9713 \t Loss:1.322 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9714 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9715 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9716 \t Loss:1.322 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9717 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9718 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9719 \t Loss:1.321 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9720 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9721 \t Loss:1.321 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9722 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9723 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9724 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9725 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9726 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9727 \t Loss:1.321 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9728 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9729 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9730 \t Loss:1.321 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9731 \t Loss:1.321 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9732 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9733 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9734 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9735 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9736 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9737 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9738 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9739 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9740 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9741 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9742 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9743 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9744 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9745 \t Loss:1.320 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9746 \t Loss:1.320 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9747 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9748 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9749 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9750 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9751 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9752 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9753 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9754 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9755 \t Loss:1.319 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9756 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9757 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9758 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9759 \t Loss:1.319 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9760 \t Loss:1.319 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9761 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9762 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9763 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9764 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9765 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9766 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9767 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9768 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9769 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9770 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9771 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9772 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9773 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9774 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9775 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9776 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9777 \t Loss:1.318 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9778 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9779 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9780 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9781 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9782 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9783 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9784 \t Loss:1.317 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9785 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9786 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9787 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9788 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9789 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9790 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9791 \t Loss:1.317 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9792 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9793 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9794 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9795 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9796 \t Loss:1.316 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9797 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9798 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9799 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9800 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9801 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9802 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9803 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9804 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9805 \t Loss:1.316 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9806 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9807 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9808 \t Loss:1.316 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9809 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9810 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9811 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9812 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9813 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9814 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9815 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9816 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9817 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9818 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9819 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9820 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9821 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9822 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9823 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9824 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9825 \t Loss:1.315 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9826 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9827 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9828 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9829 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9830 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9831 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9832 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9833 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9834 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9835 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9836 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9837 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9838 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9839 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9840 \t Loss:1.314 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9841 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9842 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9843 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9844 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9845 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9846 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9847 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9848 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9849 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9850 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9851 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9852 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9853 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9854 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9855 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9856 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9857 \t Loss:1.313 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9858 \t Loss:1.312 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9859 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9860 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9861 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9862 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9863 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9864 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9865 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9866 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9867 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9868 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9869 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9870 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9871 \t Loss:1.312 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9872 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9873 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9874 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9875 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9876 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9877 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9878 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9879 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9880 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9881 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9882 \t Loss:1.311 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9883 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9884 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9885 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9886 \t Loss:1.311 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9887 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9888 \t Loss:1.310 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9889 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9890 \t Loss:1.310 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9891 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9892 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9893 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9894 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9895 \t Loss:1.310 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9896 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9897 \t Loss:1.310 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9898 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9899 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9900 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9901 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9902 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9903 \t Loss:1.310 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9904 \t Loss:1.309 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9905 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9906 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9907 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9908 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9909 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9910 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9911 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9912 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9913 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9914 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9915 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9916 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9917 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9918 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9919 \t Loss:1.309 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9920 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9921 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9922 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9923 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9924 \t Loss:1.308 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9925 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9926 \t Loss:1.308 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9927 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9928 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9929 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9930 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9931 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9932 \t Loss:1.308 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9933 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9934 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9935 \t Loss:1.308 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9936 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9937 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9938 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9939 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9940 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9941 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9942 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9943 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9944 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9945 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9946 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9947 \t Loss:1.307 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9948 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9949 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9950 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9951 \t Loss:1.306 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9952 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9953 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9954 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9955 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9956 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9957 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9958 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9959 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9960 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9961 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9962 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9963 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9964 \t Loss:1.306 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9965 \t Loss:1.305 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9966 \t Loss:1.305 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9967 \t Loss:1.305 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9968 \t Loss:1.305 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9969 \t Loss:1.305 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9970 \t Loss:1.305 \t error(train):85.9% \t error(val):84.4%\n",
      "iter:9971 \t Loss:1.305 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9972 \t Loss:1.304 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9973 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9974 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9975 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9976 \t Loss:1.304 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9977 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9978 \t Loss:1.304 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9979 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9980 \t Loss:1.304 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9981 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9982 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9983 \t Loss:1.304 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9984 \t Loss:1.304 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9985 \t Loss:1.304 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:9986 \t Loss:1.303 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9987 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9988 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9989 \t Loss:1.303 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9990 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9991 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9992 \t Loss:1.303 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9993 \t Loss:1.303 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:9994 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9995 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9996 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:9997 \t Loss:1.303 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:9998 \t Loss:1.303 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:9999 \t Loss:1.303 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10000 \t Loss:1.303 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10001 \t Loss:1.303 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10002 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10003 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10004 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10005 \t Loss:1.302 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10006 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10007 \t Loss:1.302 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10008 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10009 \t Loss:1.302 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10010 \t Loss:1.302 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10011 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10012 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10013 \t Loss:1.302 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10014 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10015 \t Loss:1.302 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10016 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10017 \t Loss:1.302 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10018 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10019 \t Loss:1.302 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10020 \t Loss:1.301 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10021 \t Loss:1.301 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10022 \t Loss:1.301 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10023 \t Loss:1.301 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10024 \t Loss:1.301 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10025 \t Loss:1.301 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10026 \t Loss:1.301 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10027 \t Loss:1.301 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10028 \t Loss:1.301 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10029 \t Loss:1.301 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10030 \t Loss:1.301 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10031 \t Loss:1.301 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10032 \t Loss:1.301 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10033 \t Loss:1.301 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10034 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10035 \t Loss:1.300 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10036 \t Loss:1.300 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10037 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10038 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10039 \t Loss:1.300 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10040 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10041 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10042 \t Loss:1.300 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10043 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10044 \t Loss:1.300 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10045 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10046 \t Loss:1.300 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10047 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10048 \t Loss:1.300 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10049 \t Loss:1.300 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10050 \t Loss:1.299 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10051 \t Loss:1.299 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10052 \t Loss:1.299 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10053 \t Loss:1.299 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10054 \t Loss:1.299 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10055 \t Loss:1.299 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10056 \t Loss:1.299 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10057 \t Loss:1.299 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10058 \t Loss:1.299 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10059 \t Loss:1.299 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10060 \t Loss:1.299 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10061 \t Loss:1.299 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10062 \t Loss:1.299 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10063 \t Loss:1.299 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10064 \t Loss:1.299 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10065 \t Loss:1.298 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10066 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10067 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10068 \t Loss:1.298 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10069 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10070 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10071 \t Loss:1.298 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10072 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10073 \t Loss:1.298 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10074 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10075 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10076 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10077 \t Loss:1.298 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10078 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10079 \t Loss:1.298 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10080 \t Loss:1.298 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10081 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10082 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10083 \t Loss:1.297 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10084 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10085 \t Loss:1.297 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10086 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10087 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10088 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10089 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10090 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10091 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10092 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10093 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10094 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10095 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10096 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10097 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10098 \t Loss:1.297 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10099 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10100 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10101 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10102 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10103 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10104 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10105 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10106 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10107 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10108 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10109 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10110 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10111 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10112 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10113 \t Loss:1.296 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10114 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10115 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10116 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10117 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10118 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10119 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10120 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10121 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10122 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10123 \t Loss:1.295 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10124 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10125 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10126 \t Loss:1.295 \t error(train):86.0% \t error(val):84.4%\n",
      "iter:10127 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10128 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10129 \t Loss:1.295 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10130 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10131 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10132 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10133 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10134 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10135 \t Loss:1.294 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10136 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10137 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10138 \t Loss:1.294 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10139 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10140 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10141 \t Loss:1.294 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10142 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10143 \t Loss:1.294 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10144 \t Loss:1.294 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10145 \t Loss:1.293 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10146 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10147 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10148 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10149 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10150 \t Loss:1.293 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10151 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10152 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10153 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10154 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10155 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10156 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10157 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10158 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10159 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10160 \t Loss:1.293 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10161 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10162 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10163 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10164 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10165 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10166 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10167 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10168 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10169 \t Loss:1.292 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10170 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10171 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10172 \t Loss:1.292 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10173 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10174 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10175 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10176 \t Loss:1.292 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10177 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10178 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10179 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10180 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10181 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10182 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10183 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10184 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10185 \t Loss:1.291 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10186 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10187 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10188 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10189 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10190 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10191 \t Loss:1.291 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10192 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10193 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10194 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10195 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10196 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10197 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10198 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10199 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10200 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10201 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10202 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10203 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10204 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10205 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10206 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10207 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10208 \t Loss:1.290 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10209 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10210 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10211 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10212 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10213 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10214 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10215 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10216 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10217 \t Loss:1.289 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10218 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10219 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10220 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10221 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10222 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10223 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10224 \t Loss:1.289 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10225 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10226 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10227 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10228 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10229 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10230 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10231 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10232 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10233 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10234 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10235 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10236 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10237 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10238 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10239 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10240 \t Loss:1.288 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10241 \t Loss:1.288 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10242 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10243 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10244 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10245 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10246 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10247 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10248 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10249 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10250 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10251 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10252 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10253 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10254 \t Loss:1.287 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10255 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10256 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10257 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10258 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10259 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10260 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10261 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10262 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10263 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10264 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10265 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10266 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10267 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10268 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10269 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10270 \t Loss:1.286 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10271 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10272 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10273 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10274 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10275 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10276 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10277 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10278 \t Loss:1.285 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10279 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10280 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10281 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10282 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10283 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10284 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10285 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10286 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10287 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10288 \t Loss:1.284 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10289 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10290 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10291 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10292 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10293 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10294 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10295 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10296 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10297 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10298 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10299 \t Loss:1.283 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10300 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10301 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10302 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10303 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10304 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10305 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10306 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10307 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10308 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10309 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10310 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10311 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10312 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10313 \t Loss:1.282 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10314 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10315 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10316 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10317 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10318 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10319 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10320 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10321 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10322 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10323 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10324 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10325 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10326 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10327 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10328 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10329 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10330 \t Loss:1.281 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10331 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10332 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10333 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10334 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10335 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10336 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10337 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10338 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10339 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10340 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10341 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10342 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10343 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10344 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10345 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10346 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10347 \t Loss:1.280 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10348 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10349 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10350 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10351 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10352 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10353 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10354 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10355 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10356 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10357 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10358 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10359 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10360 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10361 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10362 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10363 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10364 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10365 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10366 \t Loss:1.279 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10367 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10368 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10369 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10370 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10371 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10372 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10373 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10374 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10375 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10376 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10377 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10378 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10379 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10380 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10381 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10382 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10383 \t Loss:1.278 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10384 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10385 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10386 \t Loss:1.277 \t error(train):86.0% \t error(val):84.5%\n",
      "iter:10387 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10388 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10389 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10390 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10391 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10392 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10393 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10394 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10395 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10396 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10397 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10398 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10399 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10400 \t Loss:1.277 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10401 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10402 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10403 \t Loss:1.276 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10404 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10405 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10406 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10407 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10408 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10409 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10410 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10411 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10412 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10413 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10414 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10415 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10416 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10417 \t Loss:1.276 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10418 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10419 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10420 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10421 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10422 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10423 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10424 \t Loss:1.275 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10425 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10426 \t Loss:1.275 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10427 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10428 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10429 \t Loss:1.275 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10430 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10431 \t Loss:1.275 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10432 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10433 \t Loss:1.275 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10434 \t Loss:1.275 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10435 \t Loss:1.275 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10436 \t Loss:1.275 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10437 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10438 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10439 \t Loss:1.274 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10440 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10441 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10442 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10443 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10444 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10445 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10446 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10447 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10448 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10449 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10450 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10451 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10452 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10453 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10454 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10455 \t Loss:1.274 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10456 \t Loss:1.274 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10457 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10458 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10459 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10460 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10461 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10462 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10463 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10464 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10465 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10466 \t Loss:1.273 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10467 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10468 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10469 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10470 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10471 \t Loss:1.273 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10472 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10473 \t Loss:1.273 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10474 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10475 \t Loss:1.272 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10476 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10477 \t Loss:1.272 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10478 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10479 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10480 \t Loss:1.272 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10481 \t Loss:1.272 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10482 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10483 \t Loss:1.272 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10484 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10485 \t Loss:1.272 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10486 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10487 \t Loss:1.272 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10488 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10489 \t Loss:1.272 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10490 \t Loss:1.272 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10491 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10492 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10493 \t Loss:1.271 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10494 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10495 \t Loss:1.271 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10496 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10497 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10498 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10499 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10500 \t Loss:1.271 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10501 \t Loss:1.271 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10502 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10503 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10504 \t Loss:1.271 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10505 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10506 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10507 \t Loss:1.270 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10508 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10509 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10510 \t Loss:1.270 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10511 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10512 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10513 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10514 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10515 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10516 \t Loss:1.270 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10517 \t Loss:1.270 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10518 \t Loss:1.270 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10519 \t Loss:1.270 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10520 \t Loss:1.269 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10521 \t Loss:1.269 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10522 \t Loss:1.269 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10523 \t Loss:1.269 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10524 \t Loss:1.269 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10525 \t Loss:1.269 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10526 \t Loss:1.269 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10527 \t Loss:1.269 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10528 \t Loss:1.269 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10529 \t Loss:1.269 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10530 \t Loss:1.269 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10531 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10532 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10533 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10534 \t Loss:1.268 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10535 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10536 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10537 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10538 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10539 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10540 \t Loss:1.268 \t error(train):86.1% \t error(val):84.4%\n",
      "iter:10541 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10542 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10543 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10544 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10545 \t Loss:1.268 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10546 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10547 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10548 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10549 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10550 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10551 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10552 \t Loss:1.267 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10553 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10554 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10555 \t Loss:1.267 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10556 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10557 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10558 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10559 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10560 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10561 \t Loss:1.267 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10562 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10563 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10564 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10565 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10566 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10567 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10568 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10569 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10570 \t Loss:1.266 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10571 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10572 \t Loss:1.266 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10573 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10574 \t Loss:1.266 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10575 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10576 \t Loss:1.266 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10577 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10578 \t Loss:1.266 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10579 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10580 \t Loss:1.266 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10581 \t Loss:1.265 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10582 \t Loss:1.265 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10583 \t Loss:1.265 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10584 \t Loss:1.265 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10585 \t Loss:1.265 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10586 \t Loss:1.265 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10587 \t Loss:1.264 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10588 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10589 \t Loss:1.264 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10590 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10591 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10592 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10593 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10594 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10595 \t Loss:1.264 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10596 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10597 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10598 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10599 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10600 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10601 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10602 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10603 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10604 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10605 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10606 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10607 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10608 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10609 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10610 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10611 \t Loss:1.263 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10612 \t Loss:1.263 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10613 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10614 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10615 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10616 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10617 \t Loss:1.262 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10618 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10619 \t Loss:1.262 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10620 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10621 \t Loss:1.262 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10622 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10623 \t Loss:1.262 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10624 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10625 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10626 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10627 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10628 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10629 \t Loss:1.262 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10630 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10631 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10632 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10633 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10634 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10635 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10636 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10637 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10638 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10639 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10640 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10641 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10642 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10643 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10644 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10645 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10646 \t Loss:1.261 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10647 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10648 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10649 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10650 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10651 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10652 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10653 \t Loss:1.260 \t error(train):86.1% \t error(val):84.5%\n",
      "iter:10654 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10655 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10656 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10657 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10658 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10659 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10660 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10661 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10662 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10663 \t Loss:1.260 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10664 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10665 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10666 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10667 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10668 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10669 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10670 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10671 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10672 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10673 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10674 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10675 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10676 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10677 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10678 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10679 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10680 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10681 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10682 \t Loss:1.259 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10683 \t Loss:1.259 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10684 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10685 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10686 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10687 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10688 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10689 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10690 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10691 \t Loss:1.258 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10692 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10693 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10694 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10695 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10696 \t Loss:1.258 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10697 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10698 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10699 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10700 \t Loss:1.258 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10701 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10702 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10703 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10704 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10705 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10706 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10707 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10708 \t Loss:1.257 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10709 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10710 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10711 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10712 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10713 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10714 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10715 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10716 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10717 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10718 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10719 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10720 \t Loss:1.257 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10721 \t Loss:1.256 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10722 \t Loss:1.256 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10723 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10724 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10725 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10726 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10727 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10728 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10729 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10730 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10731 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10732 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10733 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10734 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10735 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10736 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10737 \t Loss:1.256 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10738 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10739 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10740 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10741 \t Loss:1.255 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10742 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10743 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10744 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10745 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10746 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10747 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10748 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10749 \t Loss:1.255 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10750 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10751 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10752 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10753 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10754 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10755 \t Loss:1.255 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10756 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10757 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10758 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10759 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10760 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10761 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10762 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10763 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10764 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10765 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10766 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10767 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10768 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10769 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10770 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10771 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10772 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10773 \t Loss:1.254 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10774 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10775 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10776 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10777 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10778 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10779 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10780 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10781 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10782 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10783 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10784 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10785 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10786 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10787 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10788 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10789 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10790 \t Loss:1.253 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10791 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10792 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10793 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10794 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10795 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10796 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10797 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10798 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10799 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10800 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10801 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10802 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10803 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10804 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10805 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10806 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10807 \t Loss:1.252 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10808 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10809 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10810 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10811 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10812 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10813 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10814 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10815 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10816 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10817 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10818 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10819 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10820 \t Loss:1.251 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10821 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10822 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10823 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10824 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10825 \t Loss:1.251 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10826 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10827 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10828 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10829 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10830 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10831 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10832 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10833 \t Loss:1.250 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10834 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10835 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10836 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10837 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10838 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10839 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10840 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10841 \t Loss:1.250 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10842 \t Loss:1.250 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10843 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10844 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10845 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10846 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10847 \t Loss:1.249 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10848 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10849 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10850 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10851 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10852 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10853 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10854 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10855 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10856 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10857 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10858 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10859 \t Loss:1.249 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:10860 \t Loss:1.249 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10861 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10862 \t Loss:1.248 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10863 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10864 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10865 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10866 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10867 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10868 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10869 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10870 \t Loss:1.248 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10871 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10872 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10873 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10874 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10875 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10876 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10877 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10878 \t Loss:1.248 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10879 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10880 \t Loss:1.248 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10881 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10882 \t Loss:1.247 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10883 \t Loss:1.247 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10884 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10885 \t Loss:1.247 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:10886 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10887 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10888 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10889 \t Loss:1.247 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10890 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10891 \t Loss:1.247 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10892 \t Loss:1.247 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10893 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10894 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10895 \t Loss:1.247 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10896 \t Loss:1.247 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10897 \t Loss:1.246 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10898 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10899 \t Loss:1.246 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10900 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10901 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10902 \t Loss:1.246 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:10903 \t Loss:1.246 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10904 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10905 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10906 \t Loss:1.246 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10907 \t Loss:1.246 \t error(train):86.2% \t error(val):84.6%\n",
      "iter:10908 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10909 \t Loss:1.246 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10910 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10911 \t Loss:1.246 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10912 \t Loss:1.246 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10913 \t Loss:1.246 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10914 \t Loss:1.246 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10915 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10916 \t Loss:1.245 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10917 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10918 \t Loss:1.245 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10919 \t Loss:1.245 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10920 \t Loss:1.245 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10921 \t Loss:1.245 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10922 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10923 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10924 \t Loss:1.245 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10925 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10926 \t Loss:1.245 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10927 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10928 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10929 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10930 \t Loss:1.245 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10931 \t Loss:1.245 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10932 \t Loss:1.245 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10933 \t Loss:1.245 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10934 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10935 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10936 \t Loss:1.244 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10937 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10938 \t Loss:1.244 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10939 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10940 \t Loss:1.244 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10941 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10942 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10943 \t Loss:1.244 \t error(train):86.2% \t error(val):84.5%\n",
      "iter:10944 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10945 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10946 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10947 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10948 \t Loss:1.244 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10949 \t Loss:1.244 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10950 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10951 \t Loss:1.243 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10952 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10953 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10954 \t Loss:1.243 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10955 \t Loss:1.243 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:10956 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10957 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10958 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10959 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10960 \t Loss:1.243 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10961 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10962 \t Loss:1.243 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10963 \t Loss:1.243 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10964 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10965 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10966 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10967 \t Loss:1.243 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10968 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10969 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10970 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10971 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10972 \t Loss:1.242 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10973 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10974 \t Loss:1.242 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10975 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10976 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10977 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10978 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10979 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10980 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10981 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10982 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10983 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10984 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10985 \t Loss:1.242 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10986 \t Loss:1.241 \t error(train):86.3% \t error(val):84.6%\n",
      "iter:10987 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10988 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10989 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10990 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10991 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10992 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10993 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10994 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10995 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10996 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10997 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10998 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:10999 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11000 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11001 \t Loss:1.241 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11002 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11003 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11004 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11005 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11006 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11007 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11008 \t Loss:1.240 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11009 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11010 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11011 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11012 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11013 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11014 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11015 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11016 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11017 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11018 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11019 \t Loss:1.240 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11020 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11021 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11022 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11023 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11024 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11025 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11026 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11027 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11028 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11029 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11030 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11031 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11032 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11033 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11034 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11035 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11036 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11037 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11038 \t Loss:1.239 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11039 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11040 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11041 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11042 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11043 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11044 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11045 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11046 \t Loss:1.238 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11047 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11048 \t Loss:1.238 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11049 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11050 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11051 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11052 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11053 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11054 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11055 \t Loss:1.238 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11056 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11057 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11058 \t Loss:1.237 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11059 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11060 \t Loss:1.237 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11061 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11062 \t Loss:1.237 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11063 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11064 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11065 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11066 \t Loss:1.237 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11067 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11068 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11069 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11070 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11071 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11072 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11073 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11074 \t Loss:1.237 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11075 \t Loss:1.237 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11076 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11077 \t Loss:1.236 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11078 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11079 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11080 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11081 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11082 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11083 \t Loss:1.236 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11084 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11085 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11086 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11087 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11088 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11089 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11090 \t Loss:1.236 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11091 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11092 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11093 \t Loss:1.236 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11094 \t Loss:1.236 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11095 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11096 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11097 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11098 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11099 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11100 \t Loss:1.235 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11101 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11102 \t Loss:1.235 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11103 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11104 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11105 \t Loss:1.235 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11106 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11107 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11108 \t Loss:1.235 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11109 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11110 \t Loss:1.235 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11111 \t Loss:1.235 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11112 \t Loss:1.235 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11113 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11114 \t Loss:1.234 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11115 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11116 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11117 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11118 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11119 \t Loss:1.234 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11120 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11121 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11122 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11123 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11124 \t Loss:1.234 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11125 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11126 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11127 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11128 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11129 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11130 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11131 \t Loss:1.234 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11132 \t Loss:1.234 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11133 \t Loss:1.233 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11134 \t Loss:1.233 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11135 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11136 \t Loss:1.233 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11137 \t Loss:1.233 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11138 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11139 \t Loss:1.233 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11140 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11141 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11142 \t Loss:1.233 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11143 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11144 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11145 \t Loss:1.233 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11146 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11147 \t Loss:1.233 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11148 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11149 \t Loss:1.233 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11150 \t Loss:1.233 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11151 \t Loss:1.232 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11152 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11153 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11154 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11155 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11156 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11157 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11158 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11159 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11160 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11161 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11162 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11163 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11164 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11165 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11166 \t Loss:1.232 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11167 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11168 \t Loss:1.232 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11169 \t Loss:1.232 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11170 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11171 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11172 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11173 \t Loss:1.231 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11174 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11175 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11176 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11177 \t Loss:1.231 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11178 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11179 \t Loss:1.231 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11180 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11181 \t Loss:1.231 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11182 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11183 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11184 \t Loss:1.231 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11185 \t Loss:1.231 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11186 \t Loss:1.231 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11187 \t Loss:1.231 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11188 \t Loss:1.230 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11189 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11190 \t Loss:1.230 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11191 \t Loss:1.230 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11192 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11193 \t Loss:1.230 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11194 \t Loss:1.230 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11195 \t Loss:1.230 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11196 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11197 \t Loss:1.230 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11198 \t Loss:1.230 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11199 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11200 \t Loss:1.230 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11201 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11202 \t Loss:1.230 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11203 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11204 \t Loss:1.230 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11205 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11206 \t Loss:1.230 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11207 \t Loss:1.230 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11208 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11209 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11210 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11211 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11212 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11213 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11214 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11215 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11216 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11217 \t Loss:1.229 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11218 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11219 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11220 \t Loss:1.229 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11221 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11222 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11223 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11224 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11225 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11226 \t Loss:1.229 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11227 \t Loss:1.229 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11228 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11229 \t Loss:1.228 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11230 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11231 \t Loss:1.228 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11232 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11233 \t Loss:1.228 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11234 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11235 \t Loss:1.228 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11236 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11237 \t Loss:1.228 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11238 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11239 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11240 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11241 \t Loss:1.228 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11242 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11243 \t Loss:1.228 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11244 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11245 \t Loss:1.228 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11246 \t Loss:1.228 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11247 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11248 \t Loss:1.227 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11249 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11250 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11251 \t Loss:1.227 \t error(train):86.3% \t error(val):84.4%\n",
      "iter:11252 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11253 \t Loss:1.227 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11254 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11255 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11256 \t Loss:1.227 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11257 \t Loss:1.227 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11258 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11259 \t Loss:1.227 \t error(train):86.3% \t error(val):84.5%\n",
      "iter:11260 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11261 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11262 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11263 \t Loss:1.227 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11264 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11265 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11266 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11267 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11268 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11269 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11270 \t Loss:1.226 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11271 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11272 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11273 \t Loss:1.226 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11274 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11275 \t Loss:1.226 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11276 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11277 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11278 \t Loss:1.226 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11279 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11280 \t Loss:1.226 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11281 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11282 \t Loss:1.226 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11283 \t Loss:1.226 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11284 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11285 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11286 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11287 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11288 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11289 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11290 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11291 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11292 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11293 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11294 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11295 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11296 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11297 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11298 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11299 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11300 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11301 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11302 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11303 \t Loss:1.225 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11304 \t Loss:1.225 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11305 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11306 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11307 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11308 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11309 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11310 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11311 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11312 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11313 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11314 \t Loss:1.224 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11315 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11316 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11317 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11318 \t Loss:1.224 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11319 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11320 \t Loss:1.224 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11321 \t Loss:1.224 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11322 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11323 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11324 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11325 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11326 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11327 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11328 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11329 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11330 \t Loss:1.223 \t error(train):86.4% \t error(val):84.4%\n",
      "iter:11331 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11332 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11333 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11334 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11335 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11336 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11337 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11338 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11339 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11340 \t Loss:1.223 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11341 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11342 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11343 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11344 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11345 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11346 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11347 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11348 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11349 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11350 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11351 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11352 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11353 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11354 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11355 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11356 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11357 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11358 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11359 \t Loss:1.222 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11360 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11361 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11362 \t Loss:1.221 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11363 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11364 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11365 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11366 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11367 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11368 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11369 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11370 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11371 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11372 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11373 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11374 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11375 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11376 \t Loss:1.221 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11377 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11378 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11379 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11380 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11381 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11382 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11383 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11384 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11385 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11386 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11387 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11388 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11389 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11390 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11391 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11392 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11393 \t Loss:1.220 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11394 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11395 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11396 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11397 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11398 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11399 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11400 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11401 \t Loss:1.219 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11402 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11403 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11404 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11405 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11406 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11407 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11408 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11409 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11410 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11411 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11412 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11413 \t Loss:1.219 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11414 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11415 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11416 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11417 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11418 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11419 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11420 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11421 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11422 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11423 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11424 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11425 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11426 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11427 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11428 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11429 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11430 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11431 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11432 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11433 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11434 \t Loss:1.218 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11435 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11436 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11437 \t Loss:1.217 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11438 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11439 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11440 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11441 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11442 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11443 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11444 \t Loss:1.217 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11445 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11446 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11447 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11448 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11449 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11450 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11451 \t Loss:1.217 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11452 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11453 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11454 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11455 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11456 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11457 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11458 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11459 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11460 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11461 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11462 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11463 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11464 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11465 \t Loss:1.216 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11466 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11467 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11468 \t Loss:1.216 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11469 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11470 \t Loss:1.216 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11471 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11472 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11473 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11474 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11475 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11476 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11477 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11478 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11479 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11480 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11481 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11482 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11483 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11484 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11485 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11486 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11487 \t Loss:1.215 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11488 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11489 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11490 \t Loss:1.215 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11491 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11492 \t Loss:1.215 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11493 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11494 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11495 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11496 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11497 \t Loss:1.214 \t error(train):86.4% \t error(val):84.6%\n",
      "iter:11498 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11499 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11500 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11501 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11502 \t Loss:1.214 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11503 \t Loss:1.214 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11504 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11505 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11506 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11507 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11508 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11509 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11510 \t Loss:1.214 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11511 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11512 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11513 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11514 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11515 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11516 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11517 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11518 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11519 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11520 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11521 \t Loss:1.213 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11522 \t Loss:1.213 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11523 \t Loss:1.213 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11524 \t Loss:1.213 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11525 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11526 \t Loss:1.213 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11527 \t Loss:1.213 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11528 \t Loss:1.213 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11529 \t Loss:1.213 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11530 \t Loss:1.212 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11531 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11532 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11533 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11534 \t Loss:1.212 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11535 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11536 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11537 \t Loss:1.212 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11538 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11539 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11540 \t Loss:1.212 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11541 \t Loss:1.212 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11542 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11543 \t Loss:1.212 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11544 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11545 \t Loss:1.212 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11546 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11547 \t Loss:1.212 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11548 \t Loss:1.212 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11549 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11550 \t Loss:1.211 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11551 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11552 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11553 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11554 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11555 \t Loss:1.211 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11556 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11557 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11558 \t Loss:1.211 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11559 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11560 \t Loss:1.211 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11561 \t Loss:1.211 \t error(train):86.4% \t error(val):84.5%\n",
      "iter:11562 \t Loss:1.211 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11563 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11564 \t Loss:1.211 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11565 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11566 \t Loss:1.211 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11567 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11568 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11569 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11570 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11571 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11572 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11573 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11574 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11575 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11576 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11577 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11578 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11579 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11580 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11581 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11582 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11583 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11584 \t Loss:1.210 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11585 \t Loss:1.210 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11586 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11587 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11588 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11589 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11590 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11591 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11592 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11593 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11594 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11595 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11596 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11597 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11598 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11599 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11600 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11601 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11602 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11603 \t Loss:1.209 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11604 \t Loss:1.209 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11605 \t Loss:1.208 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11606 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11607 \t Loss:1.208 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11608 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11609 \t Loss:1.208 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11610 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11611 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11612 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11613 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11614 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11615 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11616 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11617 \t Loss:1.208 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11618 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11619 \t Loss:1.208 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11620 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11621 \t Loss:1.208 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11622 \t Loss:1.208 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11623 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11624 \t Loss:1.207 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11625 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11626 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11627 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11628 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11629 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11630 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11631 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11632 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11633 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11634 \t Loss:1.207 \t error(train):86.5% \t error(val):84.5%\n",
      "iter:11635 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11636 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11637 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11638 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11639 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11640 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11641 \t Loss:1.207 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11642 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11643 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11644 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11645 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11646 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11647 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11648 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11649 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11650 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11651 \t Loss:1.206 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11652 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11653 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11654 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11655 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11656 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11657 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11658 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11659 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11660 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11661 \t Loss:1.205 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11662 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11663 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11664 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11665 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11666 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11667 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11668 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11669 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11670 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11671 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11672 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11673 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11674 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11675 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11676 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11677 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11678 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11679 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11680 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11681 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11682 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11683 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11684 \t Loss:1.204 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11685 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11686 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11687 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11688 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11689 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11690 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11691 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11692 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11693 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11694 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11695 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11696 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11697 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11698 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11699 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11700 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11701 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11702 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11703 \t Loss:1.203 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11704 \t Loss:1.203 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11705 \t Loss:1.203 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11706 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11707 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11708 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11709 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11710 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11711 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11712 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11713 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11714 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11715 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11716 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11717 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11718 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11719 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11720 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11721 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11722 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11723 \t Loss:1.202 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11724 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11725 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11726 \t Loss:1.202 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11727 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11728 \t Loss:1.201 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11729 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11730 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11731 \t Loss:1.201 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11732 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11733 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11734 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11735 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11736 \t Loss:1.201 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11737 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11738 \t Loss:1.201 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11739 \t Loss:1.201 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11740 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11741 \t Loss:1.201 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11742 \t Loss:1.201 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11743 \t Loss:1.201 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11744 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11745 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11746 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11747 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11748 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11749 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11750 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11751 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11752 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11753 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11754 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11755 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11756 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11757 \t Loss:1.200 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11758 \t Loss:1.200 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11759 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11760 \t Loss:1.200 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11761 \t Loss:1.200 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11762 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11763 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11764 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11765 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11766 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11767 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11768 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11769 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11770 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11771 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11772 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11773 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11774 \t Loss:1.199 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11775 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11776 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11777 \t Loss:1.199 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11778 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11779 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11780 \t Loss:1.199 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11781 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11782 \t Loss:1.199 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11783 \t Loss:1.198 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11784 \t Loss:1.198 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11785 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11786 \t Loss:1.198 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11787 \t Loss:1.198 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11788 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11789 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11790 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11791 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11792 \t Loss:1.198 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11793 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11794 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11795 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11796 \t Loss:1.198 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11797 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11798 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11799 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11800 \t Loss:1.198 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11801 \t Loss:1.198 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11802 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11803 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11804 \t Loss:1.197 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11805 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11806 \t Loss:1.197 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11807 \t Loss:1.197 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11808 \t Loss:1.197 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11809 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11810 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11811 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11812 \t Loss:1.197 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11813 \t Loss:1.197 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11814 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11815 \t Loss:1.197 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11816 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11817 \t Loss:1.197 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11818 \t Loss:1.197 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11819 \t Loss:1.197 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11820 \t Loss:1.197 \t error(train):86.5% \t error(val):84.6%\n",
      "iter:11821 \t Loss:1.196 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11822 \t Loss:1.196 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11823 \t Loss:1.196 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11824 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11825 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11826 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11827 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11828 \t Loss:1.196 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11829 \t Loss:1.196 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11830 \t Loss:1.196 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11831 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11832 \t Loss:1.196 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11833 \t Loss:1.196 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11834 \t Loss:1.196 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11835 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11836 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11837 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11838 \t Loss:1.196 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11839 \t Loss:1.196 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11840 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11841 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11842 \t Loss:1.195 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11843 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11844 \t Loss:1.195 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11845 \t Loss:1.195 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11846 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11847 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11848 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11849 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11850 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11851 \t Loss:1.195 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11852 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11853 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11854 \t Loss:1.195 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11855 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11856 \t Loss:1.195 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11857 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11858 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11859 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11860 \t Loss:1.195 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11861 \t Loss:1.195 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11862 \t Loss:1.194 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11863 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11864 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11865 \t Loss:1.194 \t error(train):86.5% \t error(val):84.7%\n",
      "iter:11866 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11867 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11868 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11869 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11870 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11871 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11872 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11873 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11874 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11875 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11876 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11877 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11878 \t Loss:1.194 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11879 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11880 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11881 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11882 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11883 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11884 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11885 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11886 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11887 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11888 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11889 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11890 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11891 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11892 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11893 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11894 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11895 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11896 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11897 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11898 \t Loss:1.193 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11899 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11900 \t Loss:1.192 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11901 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11902 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11903 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11904 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11905 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11906 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11907 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11908 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11909 \t Loss:1.192 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11910 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11911 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11912 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11913 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11914 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11915 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11916 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11917 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11918 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11919 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11920 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11921 \t Loss:1.191 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11922 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11923 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11924 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11925 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11926 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11927 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11928 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11929 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11930 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11931 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11932 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11933 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11934 \t Loss:1.190 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11935 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11936 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11937 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11938 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11939 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11940 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11941 \t Loss:1.190 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11942 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11943 \t Loss:1.190 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11944 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11945 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11946 \t Loss:1.189 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11947 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11948 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11949 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11950 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11951 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11952 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11953 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11954 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11955 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11956 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11957 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11958 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11959 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11960 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11961 \t Loss:1.189 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11962 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11963 \t Loss:1.189 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11964 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11965 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11966 \t Loss:1.188 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11967 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11968 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11969 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11970 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11971 \t Loss:1.188 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11972 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11973 \t Loss:1.188 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11974 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11975 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11976 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11977 \t Loss:1.188 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11978 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11979 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11980 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11981 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11982 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11983 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11984 \t Loss:1.188 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11985 \t Loss:1.188 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11986 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11987 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11988 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11989 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11990 \t Loss:1.187 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:11991 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11992 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11993 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11994 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11995 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11996 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11997 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11998 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:11999 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12000 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12001 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12002 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12003 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12004 \t Loss:1.187 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12005 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12006 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12007 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12008 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12009 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12010 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12011 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12012 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12013 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12014 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12015 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12016 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12017 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12018 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12019 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12020 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12021 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12022 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12023 \t Loss:1.186 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12024 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12025 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12026 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12027 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12028 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12029 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12030 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12031 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12032 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12033 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12034 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12035 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12036 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12037 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12038 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12039 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12040 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12041 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12042 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12043 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12044 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12045 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12046 \t Loss:1.185 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12047 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12048 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12049 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12050 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12051 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12052 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12053 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12054 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12055 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12056 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12057 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12058 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12059 \t Loss:1.184 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12060 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12061 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12062 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12063 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12064 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12065 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12066 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12067 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12068 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12069 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12070 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12071 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12072 \t Loss:1.183 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12073 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12074 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12075 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12076 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12077 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12078 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12079 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12080 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12081 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12082 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12083 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12084 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12085 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12086 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12087 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12088 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12089 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12090 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12091 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12092 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12093 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12094 \t Loss:1.182 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12095 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12096 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12097 \t Loss:1.181 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:12098 \t Loss:1.181 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12099 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12100 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12101 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12102 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12103 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12104 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12105 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12106 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12107 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12108 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12109 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12110 \t Loss:1.181 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12111 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12112 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12113 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12114 \t Loss:1.181 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12115 \t Loss:1.181 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12116 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12117 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12118 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12119 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12120 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12121 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12122 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12123 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12124 \t Loss:1.180 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12125 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12126 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12127 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12128 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12129 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12130 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12131 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12132 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12133 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12134 \t Loss:1.180 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12135 \t Loss:1.179 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12136 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12137 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12138 \t Loss:1.179 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12139 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12140 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12141 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12142 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12143 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12144 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12145 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12146 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12147 \t Loss:1.179 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12148 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12149 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12150 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12151 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12152 \t Loss:1.179 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12153 \t Loss:1.178 \t error(train):86.6% \t error(val):84.6%\n",
      "iter:12154 \t Loss:1.178 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12155 \t Loss:1.178 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12156 \t Loss:1.178 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12157 \t Loss:1.178 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12158 \t Loss:1.178 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12159 \t Loss:1.178 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12160 \t Loss:1.178 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12161 \t Loss:1.178 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12162 \t Loss:1.178 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12163 \t Loss:1.178 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12164 \t Loss:1.178 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12165 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12166 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12167 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12168 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12169 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12170 \t Loss:1.177 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12171 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12172 \t Loss:1.177 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12173 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12174 \t Loss:1.177 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12175 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12176 \t Loss:1.177 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12177 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12178 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12179 \t Loss:1.176 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12180 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12181 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12182 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12183 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12184 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12185 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12186 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12187 \t Loss:1.176 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12188 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12189 \t Loss:1.176 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12190 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12191 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12192 \t Loss:1.176 \t error(train):86.6% \t error(val):84.7%\n",
      "iter:12193 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12194 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12195 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12196 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12197 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12198 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12199 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12200 \t Loss:1.176 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12201 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12202 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12203 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12204 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12205 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12206 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12207 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12208 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12209 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12210 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12211 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12212 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12213 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12214 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12215 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12216 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12217 \t Loss:1.175 \t error(train):86.7% \t error(val):84.6%\n",
      "iter:12218 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12219 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12220 \t Loss:1.175 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12221 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12222 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12223 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12224 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12225 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12226 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12227 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12228 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12229 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12230 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12231 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12232 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12233 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12234 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12235 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12236 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12237 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12238 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12239 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12240 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12241 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12242 \t Loss:1.174 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12243 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12244 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12245 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12246 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12247 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12248 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12249 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12250 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12251 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12252 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12253 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12254 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12255 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12256 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12257 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12258 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12259 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12260 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12261 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12262 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12263 \t Loss:1.173 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12264 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12265 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12266 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12267 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12268 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12269 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12270 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12271 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12272 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12273 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12274 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12275 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12276 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12277 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12278 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12279 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12280 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12281 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12282 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12283 \t Loss:1.172 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12284 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12285 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12286 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12287 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12288 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12289 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12290 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12291 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12292 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12293 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12294 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12295 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12296 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12297 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12298 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12299 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12300 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12301 \t Loss:1.171 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12302 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12303 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12304 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12305 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12306 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12307 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12308 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12309 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12310 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12311 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12312 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12313 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12314 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12315 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12316 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12317 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12318 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12319 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12320 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12321 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12322 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12323 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12324 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12325 \t Loss:1.170 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12326 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12327 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12328 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12329 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12330 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12331 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12332 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12333 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12334 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12335 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12336 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12337 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12338 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12339 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12340 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12341 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12342 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12343 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12344 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12345 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12346 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12347 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12348 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12349 \t Loss:1.169 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12350 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12351 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12352 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12353 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12354 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12355 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12356 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12357 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12358 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12359 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12360 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12361 \t Loss:1.168 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12362 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12363 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12364 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12365 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12366 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12367 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12368 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12369 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12370 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12371 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12372 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12373 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12374 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12375 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12376 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12377 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12378 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12379 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12380 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12381 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12382 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12383 \t Loss:1.167 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12384 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12385 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12386 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12387 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12388 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12389 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12390 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12391 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12392 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12393 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12394 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12395 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12396 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12397 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12398 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12399 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12400 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12401 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12402 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12403 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12404 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12405 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12406 \t Loss:1.166 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12407 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12408 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12409 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12410 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12411 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12412 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12413 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12414 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12415 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12416 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12417 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12418 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12419 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12420 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12421 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12422 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12423 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12424 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12425 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12426 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12427 \t Loss:1.165 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12428 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12429 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12430 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12431 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12432 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12433 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12434 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12435 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12436 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12437 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12438 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12439 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12440 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12441 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12442 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12443 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12444 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12445 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12446 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12447 \t Loss:1.164 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12448 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12449 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12450 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12451 \t Loss:1.164 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12452 \t Loss:1.163 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12453 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12454 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12455 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12456 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12457 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12458 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12459 \t Loss:1.163 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12460 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12461 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12462 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12463 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12464 \t Loss:1.163 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12465 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12466 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12467 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12468 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12469 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12470 \t Loss:1.163 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12471 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12472 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12473 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12474 \t Loss:1.163 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12475 \t Loss:1.163 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12476 \t Loss:1.163 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12477 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12478 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12479 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12480 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12481 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12482 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12483 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12484 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12485 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12486 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12487 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12488 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12489 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12490 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12491 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12492 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12493 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12494 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12495 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12496 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12497 \t Loss:1.162 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12498 \t Loss:1.162 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12499 \t Loss:1.161 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12500 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12501 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12502 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12503 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12504 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12505 \t Loss:1.161 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12506 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12507 \t Loss:1.161 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12508 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12509 \t Loss:1.161 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12510 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12511 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12512 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12513 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12514 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12515 \t Loss:1.161 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12516 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12517 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12518 \t Loss:1.161 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12519 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12520 \t Loss:1.161 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12521 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12522 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12523 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12524 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12525 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12526 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12527 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12528 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12529 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12530 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12531 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12532 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12533 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12534 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12535 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12536 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12537 \t Loss:1.160 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12538 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12539 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12540 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12541 \t Loss:1.160 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12542 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12543 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12544 \t Loss:1.159 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12545 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12546 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12547 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12548 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12549 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12550 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12551 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12552 \t Loss:1.159 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12553 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12554 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12555 \t Loss:1.159 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12556 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12557 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12558 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12559 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12560 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12561 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12562 \t Loss:1.159 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12563 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12564 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12565 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12566 \t Loss:1.158 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12567 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12568 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12569 \t Loss:1.158 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12570 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12571 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12572 \t Loss:1.158 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12573 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12574 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12575 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12576 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12577 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12578 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12579 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12580 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12581 \t Loss:1.158 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12582 \t Loss:1.158 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12583 \t Loss:1.158 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12584 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12585 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12586 \t Loss:1.157 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12587 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12588 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12589 \t Loss:1.157 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12590 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12591 \t Loss:1.157 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12592 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12593 \t Loss:1.157 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12594 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12595 \t Loss:1.157 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12596 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12597 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12598 \t Loss:1.157 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12599 \t Loss:1.157 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12600 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12601 \t Loss:1.157 \t error(train):86.7% \t error(val):84.7%\n",
      "iter:12602 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12603 \t Loss:1.157 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12604 \t Loss:1.157 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12605 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12606 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12607 \t Loss:1.156 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12608 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12609 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12610 \t Loss:1.156 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12611 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12612 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12613 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12614 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12615 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12616 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12617 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12618 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12619 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12620 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12621 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12622 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12623 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12624 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12625 \t Loss:1.156 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12626 \t Loss:1.156 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12627 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12628 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12629 \t Loss:1.155 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12630 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12631 \t Loss:1.155 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12632 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12633 \t Loss:1.155 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12634 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12635 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12636 \t Loss:1.155 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12637 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12638 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12639 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12640 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12641 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12642 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12643 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12644 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12645 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12646 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12647 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12648 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12649 \t Loss:1.155 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12650 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12651 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12652 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12653 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12654 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12655 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12656 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12657 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12658 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12659 \t Loss:1.154 \t error(train):86.7% \t error(val):84.8%\n",
      "iter:12660 \t Loss:1.154 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12661 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12662 \t Loss:1.154 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12663 \t Loss:1.154 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12664 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12665 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12666 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12667 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12668 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12669 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12670 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12671 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12672 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12673 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12674 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12675 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12676 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12677 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12678 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12679 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12680 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12681 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12682 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12683 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12684 \t Loss:1.153 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12685 \t Loss:1.153 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12686 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12687 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12688 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12689 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12690 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12691 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12692 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12693 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12694 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12695 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12696 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12697 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12698 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12699 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12700 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12701 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12702 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12703 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12704 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12705 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12706 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12707 \t Loss:1.152 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12708 \t Loss:1.152 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12709 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12710 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12711 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12712 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12713 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12714 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12715 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12716 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12717 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12718 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12719 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12720 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12721 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12722 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12723 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12724 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12725 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12726 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12727 \t Loss:1.151 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12728 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12729 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12730 \t Loss:1.151 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12731 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12732 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12733 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12734 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12735 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12736 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12737 \t Loss:1.150 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12738 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12739 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12740 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12741 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12742 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12743 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12744 \t Loss:1.150 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12745 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12746 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12747 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12748 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12749 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12750 \t Loss:1.150 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12751 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12752 \t Loss:1.149 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12753 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12754 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12755 \t Loss:1.149 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12756 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12757 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12758 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12759 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12760 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12761 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12762 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12763 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12764 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12765 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12766 \t Loss:1.149 \t error(train):86.8% \t error(val):84.7%\n",
      "iter:12767 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12768 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12769 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12770 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12771 \t Loss:1.149 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12772 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12773 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12774 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12775 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12776 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12777 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12778 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12779 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12780 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12781 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12782 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12783 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12784 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12785 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12786 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12787 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12788 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12789 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12790 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12791 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12792 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12793 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12794 \t Loss:1.148 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12795 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12796 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12797 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12798 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12799 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12800 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12801 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12802 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12803 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12804 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12805 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12806 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12807 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12808 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12809 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12810 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12811 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12812 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12813 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12814 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12815 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12816 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12817 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12818 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12819 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12820 \t Loss:1.147 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12821 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12822 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12823 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12824 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12825 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12826 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12827 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12828 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12829 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12830 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12831 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12832 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12833 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12834 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12835 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12836 \t Loss:1.146 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12837 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12838 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12839 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12840 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12841 \t Loss:1.146 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12842 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12843 \t Loss:1.146 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12844 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12845 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12846 \t Loss:1.146 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12847 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12848 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12849 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12850 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12851 \t Loss:1.145 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12852 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12853 \t Loss:1.145 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12854 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12855 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12856 \t Loss:1.145 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12857 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12858 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12859 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12860 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12861 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12862 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12863 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12864 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12865 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12866 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12867 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12868 \t Loss:1.145 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12869 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12870 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12871 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12872 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12873 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12874 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12875 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12876 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12877 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12878 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12879 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12880 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12881 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12882 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12883 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12884 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12885 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12886 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12887 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12888 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12889 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12890 \t Loss:1.144 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12891 \t Loss:1.144 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12892 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12893 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12894 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12895 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12896 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12897 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12898 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12899 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12900 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12901 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12902 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12903 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12904 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12905 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12906 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12907 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12908 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12909 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12910 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12911 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12912 \t Loss:1.143 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12913 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12914 \t Loss:1.143 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12915 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12916 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12917 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12918 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12919 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12920 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12921 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12922 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12923 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12924 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12925 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12926 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12927 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12928 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12929 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12930 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12931 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12932 \t Loss:1.142 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12933 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12934 \t Loss:1.142 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12935 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12936 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12937 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12938 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12939 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12940 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12941 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12942 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12943 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12944 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12945 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12946 \t Loss:1.141 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12947 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12948 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12949 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12950 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12951 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12952 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12953 \t Loss:1.141 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12954 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12955 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12956 \t Loss:1.141 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12957 \t Loss:1.141 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12958 \t Loss:1.141 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12959 \t Loss:1.141 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12960 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12961 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12962 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12963 \t Loss:1.140 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12964 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12965 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12966 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12967 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12968 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12969 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12970 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12971 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12972 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12973 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12974 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12975 \t Loss:1.140 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12976 \t Loss:1.140 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:12977 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12978 \t Loss:1.140 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:12979 \t Loss:1.140 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12980 \t Loss:1.140 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12981 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12982 \t Loss:1.140 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12983 \t Loss:1.140 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12984 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12985 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12986 \t Loss:1.139 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12987 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12988 \t Loss:1.139 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:12989 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12990 \t Loss:1.139 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:12991 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12992 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12993 \t Loss:1.139 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:12994 \t Loss:1.139 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12995 \t Loss:1.139 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:12996 \t Loss:1.139 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:12997 \t Loss:1.139 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:12998 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:12999 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13000 \t Loss:1.139 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13001 \t Loss:1.139 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13002 \t Loss:1.139 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13003 \t Loss:1.138 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13004 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13005 \t Loss:1.138 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13006 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13007 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13008 \t Loss:1.138 \t error(train):86.8% \t error(val):84.8%\n",
      "iter:13009 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13010 \t Loss:1.138 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13011 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13012 \t Loss:1.138 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13013 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13014 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13015 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13016 \t Loss:1.138 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13017 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13018 \t Loss:1.138 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13019 \t Loss:1.138 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13020 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13021 \t Loss:1.138 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13022 \t Loss:1.138 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13023 \t Loss:1.138 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13024 \t Loss:1.138 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13025 \t Loss:1.137 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13026 \t Loss:1.137 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13027 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13028 \t Loss:1.137 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13029 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13030 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13031 \t Loss:1.137 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13032 \t Loss:1.137 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13033 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13034 \t Loss:1.137 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13035 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13036 \t Loss:1.137 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13037 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13038 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13039 \t Loss:1.137 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13040 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13041 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13042 \t Loss:1.137 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13043 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13044 \t Loss:1.137 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13045 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13046 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13047 \t Loss:1.137 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13048 \t Loss:1.136 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13049 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13050 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13051 \t Loss:1.136 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13052 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13053 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13054 \t Loss:1.136 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13055 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13056 \t Loss:1.136 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13057 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13058 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13059 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13060 \t Loss:1.136 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13061 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13062 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13063 \t Loss:1.136 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13064 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13065 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13066 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13067 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13068 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13069 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13070 \t Loss:1.136 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13071 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13072 \t Loss:1.135 \t error(train):86.8% \t error(val):84.9%\n",
      "iter:13073 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13074 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13075 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13076 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13077 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13078 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13079 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13080 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13081 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13082 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13083 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13084 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13085 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13086 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13087 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13088 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13089 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13090 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13091 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13092 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13093 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13094 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13095 \t Loss:1.135 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13096 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13097 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13098 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13099 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13100 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13101 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13102 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13103 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13104 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13105 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13106 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13107 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13108 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13109 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13110 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13111 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13112 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13113 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13114 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13115 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13116 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13117 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13118 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13119 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13120 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13121 \t Loss:1.134 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13122 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13123 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13124 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13125 \t Loss:1.133 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13126 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13127 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13128 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13129 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13130 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13131 \t Loss:1.133 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13132 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13133 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13134 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13135 \t Loss:1.133 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13136 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13137 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13138 \t Loss:1.133 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13139 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13140 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13141 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13142 \t Loss:1.133 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13143 \t Loss:1.133 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13144 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13145 \t Loss:1.132 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13146 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13147 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13148 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13149 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13150 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13151 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13152 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13153 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13154 \t Loss:1.132 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13155 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13156 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13157 \t Loss:1.132 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13158 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13159 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13160 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13161 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13162 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13163 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13164 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13165 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13166 \t Loss:1.132 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13167 \t Loss:1.132 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13168 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13169 \t Loss:1.131 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13170 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13171 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13172 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13173 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13174 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13175 \t Loss:1.131 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13176 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13177 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13178 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13179 \t Loss:1.131 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13180 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13181 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13182 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13183 \t Loss:1.131 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13184 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13185 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13186 \t Loss:1.131 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13187 \t Loss:1.131 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13188 \t Loss:1.131 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13189 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13190 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13191 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13192 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13193 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13194 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13195 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13196 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13197 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13198 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13199 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13200 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13201 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13202 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13203 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13204 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13205 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13206 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13207 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13208 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13209 \t Loss:1.130 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13210 \t Loss:1.130 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13211 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13212 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13213 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13214 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13215 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13216 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13217 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13218 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13219 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13220 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13221 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13222 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13223 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13224 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13225 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13226 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13227 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13228 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13229 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13230 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13231 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13232 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13233 \t Loss:1.129 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13234 \t Loss:1.129 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13235 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13236 \t Loss:1.128 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13237 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13238 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13239 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13240 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13241 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13242 \t Loss:1.128 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13243 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13244 \t Loss:1.128 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13245 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13246 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13247 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13248 \t Loss:1.128 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13249 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13250 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13251 \t Loss:1.128 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13252 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13253 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13254 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13255 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13256 \t Loss:1.128 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13257 \t Loss:1.128 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13258 \t Loss:1.128 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13259 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13260 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13261 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13262 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13263 \t Loss:1.127 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13264 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13265 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13266 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13267 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13268 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13269 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13270 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13271 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13272 \t Loss:1.127 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13273 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13274 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13275 \t Loss:1.127 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13276 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13277 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13278 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13279 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13280 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13281 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13282 \t Loss:1.127 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13283 \t Loss:1.127 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13284 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13285 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13286 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13287 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13288 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13289 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13290 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13291 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13292 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13293 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13294 \t Loss:1.126 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13295 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13296 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13297 \t Loss:1.126 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13298 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13299 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13300 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13301 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13302 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13303 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13304 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13305 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13306 \t Loss:1.126 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13307 \t Loss:1.126 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13308 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13309 \t Loss:1.125 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13310 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13311 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13312 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13313 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13314 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13315 \t Loss:1.125 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13316 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13317 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13318 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13319 \t Loss:1.125 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13320 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13321 \t Loss:1.125 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13322 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13323 \t Loss:1.125 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13324 \t Loss:1.125 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13325 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13326 \t Loss:1.125 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13327 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13328 \t Loss:1.125 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13329 \t Loss:1.125 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13330 \t Loss:1.125 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13331 \t Loss:1.125 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13332 \t Loss:1.125 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13333 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13334 \t Loss:1.124 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13335 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13336 \t Loss:1.124 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13337 \t Loss:1.124 \t error(train):86.9% \t error(val):84.8%\n",
      "iter:13338 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13339 \t Loss:1.124 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13340 \t Loss:1.124 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13341 \t Loss:1.124 \t error(train):86.9% \t error(val):84.9%\n",
      "iter:13342 \t Loss:1.124 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13343 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13344 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13345 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13346 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13347 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13348 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13349 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13350 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13351 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13352 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13353 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13354 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13355 \t Loss:1.124 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13356 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13357 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13358 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13359 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13360 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13361 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13362 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13363 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13364 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13365 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13366 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13367 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13368 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13369 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13370 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13371 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13372 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13373 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13374 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13375 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13376 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13377 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13378 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13379 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13380 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13381 \t Loss:1.123 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13382 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13383 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13384 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13385 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13386 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13387 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13388 \t Loss:1.122 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13389 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13390 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13391 \t Loss:1.122 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13392 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13393 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13394 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13395 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13396 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13397 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13398 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13399 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13400 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13401 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13402 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13403 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13404 \t Loss:1.122 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13405 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13406 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13407 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13408 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13409 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13410 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13411 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13412 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13413 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13414 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13415 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13416 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13417 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13418 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13419 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13420 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13421 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13422 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13423 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13424 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13425 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13426 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13427 \t Loss:1.121 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13428 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13429 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13430 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13431 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13432 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13433 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13434 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13435 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13436 \t Loss:1.120 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13437 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13438 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13439 \t Loss:1.120 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13440 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13441 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13442 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13443 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13444 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13445 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13446 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13447 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13448 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13449 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13450 \t Loss:1.120 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13451 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13452 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13453 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13454 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13455 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13456 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13457 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13458 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13459 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13460 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13461 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13462 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13463 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13464 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13465 \t Loss:1.119 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13466 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13467 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13468 \t Loss:1.119 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13469 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13470 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13471 \t Loss:1.119 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13472 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13473 \t Loss:1.119 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13474 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13475 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13476 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13477 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13478 \t Loss:1.118 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13479 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13480 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13481 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13482 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13483 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13484 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13485 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13486 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13487 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13488 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13489 \t Loss:1.118 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13490 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13491 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13492 \t Loss:1.118 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13493 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13494 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13495 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13496 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13497 \t Loss:1.118 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13498 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13499 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13500 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13501 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13502 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13503 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13504 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13505 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13506 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13507 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13508 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13509 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13510 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13511 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13512 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13513 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13514 \t Loss:1.117 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13515 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13516 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13517 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13518 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13519 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13520 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13521 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13522 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13523 \t Loss:1.117 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13524 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13525 \t Loss:1.116 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13526 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13527 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13528 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13529 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13530 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13531 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13532 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13533 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13534 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13535 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13536 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13537 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13538 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13539 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13540 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13541 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13542 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13543 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13544 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13545 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13546 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13547 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13548 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13549 \t Loss:1.116 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13550 \t Loss:1.116 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13551 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13552 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13553 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13554 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13555 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13556 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13557 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13558 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13559 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13560 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13561 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13562 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13563 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13564 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13565 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13566 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13567 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13568 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13569 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13570 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13571 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13572 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13573 \t Loss:1.115 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13574 \t Loss:1.115 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13575 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13576 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13577 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13578 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13579 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13580 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13581 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13582 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13583 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13584 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13585 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13586 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13587 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13588 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13589 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13590 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13591 \t Loss:1.114 \t error(train):87.0% \t error(val):84.8%\n",
      "iter:13592 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13593 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13594 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13595 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13596 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13597 \t Loss:1.114 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13598 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13599 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13600 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13601 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13602 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13603 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13604 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13605 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13606 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13607 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13608 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13609 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13610 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13611 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13612 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13613 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13614 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13615 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13616 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13617 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13618 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13619 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13620 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13621 \t Loss:1.113 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13622 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13623 \t Loss:1.112 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13624 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13625 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13626 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13627 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13628 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13629 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13630 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13631 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13632 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13633 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13634 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13635 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13636 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13637 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13638 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13639 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13640 \t Loss:1.112 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13641 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13642 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13643 \t Loss:1.112 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13644 \t Loss:1.112 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13645 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13646 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13647 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13648 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13649 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13650 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13651 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13652 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13653 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13654 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13655 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13656 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13657 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13658 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13659 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13660 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13661 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13662 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13663 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13664 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13665 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13666 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13667 \t Loss:1.111 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13668 \t Loss:1.111 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13669 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13670 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13671 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13672 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13673 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13674 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13675 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13676 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13677 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13678 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13679 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13680 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13681 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13682 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13683 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13684 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13685 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13686 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13687 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13688 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13689 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13690 \t Loss:1.110 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13691 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13692 \t Loss:1.110 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13693 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13694 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13695 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13696 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13697 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13698 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13699 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13700 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13701 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13702 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13703 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13704 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13705 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13706 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13707 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13708 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13709 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13710 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13711 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13712 \t Loss:1.109 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13713 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13714 \t Loss:1.109 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13715 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13716 \t Loss:1.109 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13717 \t Loss:1.109 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13718 \t Loss:1.109 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13719 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13720 \t Loss:1.108 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13721 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13722 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13723 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13724 \t Loss:1.108 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13725 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13726 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13727 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13728 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13729 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13730 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13731 \t Loss:1.108 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13732 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13733 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13734 \t Loss:1.108 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13735 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13736 \t Loss:1.107 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13737 \t Loss:1.107 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13738 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13739 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13740 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13741 \t Loss:1.107 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13742 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13743 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13744 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13745 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13746 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13747 \t Loss:1.107 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13748 \t Loss:1.107 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13749 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13750 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13751 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13752 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13753 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13754 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13755 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13756 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13757 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13758 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13759 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13760 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13761 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13762 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13763 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13764 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13765 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13766 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13767 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13768 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13769 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13770 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13771 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13772 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13773 \t Loss:1.106 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13774 \t Loss:1.106 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13775 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13776 \t Loss:1.106 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13777 \t Loss:1.105 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13778 \t Loss:1.105 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13779 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13780 \t Loss:1.105 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13781 \t Loss:1.105 \t error(train):87.0% \t error(val):84.9%\n",
      "iter:13782 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13783 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13784 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13785 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13786 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13787 \t Loss:1.105 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13788 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13789 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13790 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13791 \t Loss:1.105 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13792 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13793 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13794 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13795 \t Loss:1.105 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13796 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13797 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13798 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13799 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13800 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13801 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13802 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13803 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13804 \t Loss:1.105 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13805 \t Loss:1.105 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13806 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13807 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13808 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13809 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13810 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13811 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13812 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13813 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13814 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13815 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13816 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13817 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13818 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13819 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13820 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13821 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13822 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13823 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13824 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13825 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13826 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13827 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13828 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13829 \t Loss:1.104 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13830 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13831 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13832 \t Loss:1.104 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13833 \t Loss:1.104 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13834 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13835 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13836 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13837 \t Loss:1.103 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13838 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13839 \t Loss:1.103 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13840 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13841 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13842 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13843 \t Loss:1.103 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13844 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13845 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13846 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13847 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13848 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13849 \t Loss:1.103 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13850 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13851 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13852 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13853 \t Loss:1.103 \t error(train):87.0% \t error(val):85.0%\n",
      "iter:13854 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13855 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13856 \t Loss:1.103 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13857 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13858 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13859 \t Loss:1.103 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13860 \t Loss:1.103 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13861 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13862 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13863 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13864 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13865 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13866 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13867 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13868 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13869 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13870 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13871 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13872 \t Loss:1.102 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13873 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13874 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13875 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13876 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13877 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13878 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13879 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13880 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13881 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13882 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13883 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13884 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13885 \t Loss:1.102 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13886 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13887 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13888 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13889 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13890 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13891 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13892 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13893 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13894 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13895 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13896 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13897 \t Loss:1.101 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13898 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13899 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13900 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13901 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13902 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13903 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13904 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13905 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13906 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13907 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13908 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13909 \t Loss:1.101 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13910 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13911 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13912 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13913 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13914 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13915 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13916 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13917 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13918 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13919 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13920 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13921 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13922 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13923 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13924 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13925 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13926 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13927 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13928 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13929 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13930 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13931 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13932 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13933 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13934 \t Loss:1.100 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13935 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13936 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13937 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13938 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13939 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13940 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13941 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13942 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13943 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13944 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13945 \t Loss:1.099 \t error(train):87.1% \t error(val):84.9%\n",
      "iter:13946 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13947 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13948 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13949 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13950 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13951 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13952 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13953 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13954 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13955 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13956 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13957 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13958 \t Loss:1.099 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13959 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13960 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13961 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13962 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13963 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13964 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13965 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13966 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13967 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13968 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13969 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13970 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13971 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13972 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13973 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13974 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13975 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13976 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13977 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13978 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13979 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13980 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13981 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13982 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13983 \t Loss:1.098 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13984 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13985 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13986 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13987 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13988 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13989 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13990 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13991 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13992 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13993 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13994 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13995 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13996 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13997 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13998 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:13999 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14000 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14001 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14002 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14003 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14004 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14005 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14006 \t Loss:1.097 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14007 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14008 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14009 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14010 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14011 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14012 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14013 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14014 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14015 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14016 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14017 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14018 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14019 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14020 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14021 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14022 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14023 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14024 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14025 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14026 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14027 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14028 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14029 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14030 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14031 \t Loss:1.096 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14032 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14033 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14034 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14035 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14036 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14037 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14038 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14039 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14040 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14041 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14042 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14043 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14044 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14045 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14046 \t Loss:1.095 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14047 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14048 \t Loss:1.095 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14049 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14050 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14051 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14052 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14053 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14054 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14055 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14056 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14057 \t Loss:1.095 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14058 \t Loss:1.095 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14059 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14060 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14061 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14062 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14063 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14064 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14065 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14066 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14067 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14068 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14069 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14070 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14071 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14072 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14073 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14074 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14075 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14076 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14077 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14078 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14079 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14080 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14081 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14082 \t Loss:1.094 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14083 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14084 \t Loss:1.094 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14085 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14086 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14087 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14088 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14089 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14090 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14091 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14092 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14093 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14094 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14095 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14096 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14097 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14098 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14099 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14100 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14101 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14102 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14103 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14104 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14105 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14106 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14107 \t Loss:1.093 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14108 \t Loss:1.093 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14109 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14110 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14111 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14112 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14113 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14114 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14115 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14116 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14117 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14118 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14119 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14120 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14121 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14122 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14123 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14124 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14125 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14126 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14127 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14128 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14129 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14130 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14131 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14132 \t Loss:1.092 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14133 \t Loss:1.092 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14134 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14135 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14136 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14137 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14138 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14139 \t Loss:1.091 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14140 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14141 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14142 \t Loss:1.091 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14143 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14144 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14145 \t Loss:1.091 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14146 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14147 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14148 \t Loss:1.091 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14149 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14150 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14151 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14152 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14153 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14154 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14155 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14156 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14157 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14158 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14159 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14160 \t Loss:1.091 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14161 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14162 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14163 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14164 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14165 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14166 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14167 \t Loss:1.090 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14168 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14169 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14170 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14171 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14172 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14173 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14174 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14175 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14176 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14177 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14178 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14179 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14180 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14181 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14182 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14183 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14184 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14185 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14186 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14187 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14188 \t Loss:1.090 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14189 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14190 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14191 \t Loss:1.089 \t error(train):87.1% \t error(val):85.0%\n",
      "iter:14192 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14193 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14194 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14195 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14196 \t Loss:1.089 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14197 \t Loss:1.089 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14198 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14199 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14200 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14201 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14202 \t Loss:1.089 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14203 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14204 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14205 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14206 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14207 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14208 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14209 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14210 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14211 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14212 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14213 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14214 \t Loss:1.089 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14215 \t Loss:1.089 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14216 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14217 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14218 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14219 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14220 \t Loss:1.088 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14221 \t Loss:1.088 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14222 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14223 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14224 \t Loss:1.088 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14225 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14226 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14227 \t Loss:1.088 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14228 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14229 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14230 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14231 \t Loss:1.088 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14232 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14233 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14234 \t Loss:1.088 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14235 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14236 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14237 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14238 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14239 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14240 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14241 \t Loss:1.088 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14242 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14243 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14244 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14245 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14246 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14247 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14248 \t Loss:1.087 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14249 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14250 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14251 \t Loss:1.087 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14252 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14253 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14254 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14255 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14256 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14257 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14258 \t Loss:1.087 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14259 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14260 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14261 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14262 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14263 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14264 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14265 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14266 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14267 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14268 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14269 \t Loss:1.087 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14270 \t Loss:1.086 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14271 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14272 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14273 \t Loss:1.086 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14274 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14275 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14276 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14277 \t Loss:1.086 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14278 \t Loss:1.086 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14279 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14280 \t Loss:1.086 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14281 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14282 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14283 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14284 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14285 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14286 \t Loss:1.086 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14287 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14288 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14289 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14290 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14291 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14292 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14293 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14294 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14295 \t Loss:1.086 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14296 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14297 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14298 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14299 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14300 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14301 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14302 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14303 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14304 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14305 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14306 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14307 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14308 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14309 \t Loss:1.085 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14310 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14311 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14312 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14313 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14314 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14315 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14316 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14317 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14318 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14319 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14320 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14321 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14322 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14323 \t Loss:1.085 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14324 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14325 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14326 \t Loss:1.084 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14327 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14328 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14329 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14330 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14331 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14332 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14333 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14334 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14335 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14336 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14337 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14338 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14339 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14340 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14341 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14342 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14343 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14344 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14345 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14346 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14347 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14348 \t Loss:1.084 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14349 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14350 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14351 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14352 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14353 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14354 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14355 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14356 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14357 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14358 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14359 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14360 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14361 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14362 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14363 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14364 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14365 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14366 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14367 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14368 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14369 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14370 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14371 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14372 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14373 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14374 \t Loss:1.083 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14375 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14376 \t Loss:1.083 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14377 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14378 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14379 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14380 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14381 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14382 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14383 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14384 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14385 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14386 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14387 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14388 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14389 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14390 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14391 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14392 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14393 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14394 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14395 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14396 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14397 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14398 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14399 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14400 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14401 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14402 \t Loss:1.082 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14403 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14404 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14405 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14406 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14407 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14408 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14409 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14410 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14411 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14412 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14413 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14414 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14415 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14416 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14417 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14418 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14419 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14420 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14421 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14422 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14423 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14424 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14425 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14426 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14427 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14428 \t Loss:1.081 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14429 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14430 \t Loss:1.080 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14431 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14432 \t Loss:1.080 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14433 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14434 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14435 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14436 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14437 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14438 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14439 \t Loss:1.080 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14440 \t Loss:1.080 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14441 \t Loss:1.080 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14442 \t Loss:1.080 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14443 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14444 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14445 \t Loss:1.079 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14446 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14447 \t Loss:1.079 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14448 \t Loss:1.079 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14449 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14450 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14451 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14452 \t Loss:1.079 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14453 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14454 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14455 \t Loss:1.079 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14456 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14457 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14458 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14459 \t Loss:1.079 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14460 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14461 \t Loss:1.079 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14462 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14463 \t Loss:1.079 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14464 \t Loss:1.078 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14465 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14466 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14467 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14468 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14469 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14470 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14471 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14472 \t Loss:1.078 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14473 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14474 \t Loss:1.078 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14475 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14476 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14477 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14478 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14479 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14480 \t Loss:1.078 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14481 \t Loss:1.078 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14482 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14483 \t Loss:1.078 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14484 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14485 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14486 \t Loss:1.077 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14487 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14488 \t Loss:1.077 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14489 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14490 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14491 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14492 \t Loss:1.077 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14493 \t Loss:1.077 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14494 \t Loss:1.077 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14495 \t Loss:1.077 \t error(train):87.1% \t error(val):85.2%\n",
      "iter:14496 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14497 \t Loss:1.077 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14498 \t Loss:1.077 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14499 \t Loss:1.077 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14500 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14501 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14502 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14503 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14504 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14505 \t Loss:1.076 \t error(train):87.1% \t error(val):85.1%\n",
      "iter:14506 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14507 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14508 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14509 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14510 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14511 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14512 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14513 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14514 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14515 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14516 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14517 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14518 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14519 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14520 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14521 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14522 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14523 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14524 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14525 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14526 \t Loss:1.076 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14527 \t Loss:1.076 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14528 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14529 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14530 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14531 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14532 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14533 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14534 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14535 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14536 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14537 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14538 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14539 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14540 \t Loss:1.075 \t error(train):87.1% \t error(val):85.2%\n",
      "iter:14541 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14542 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14543 \t Loss:1.075 \t error(train):87.1% \t error(val):85.2%\n",
      "iter:14544 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14545 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14546 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14547 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14548 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14549 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14550 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14551 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14552 \t Loss:1.075 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14553 \t Loss:1.075 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14554 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14555 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14556 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14557 \t Loss:1.074 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14558 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14559 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14560 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14561 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14562 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14563 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14564 \t Loss:1.074 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14565 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14566 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14567 \t Loss:1.074 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14568 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14569 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14570 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14571 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14572 \t Loss:1.074 \t error(train):87.1% \t error(val):85.2%\n",
      "iter:14573 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14574 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14575 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14576 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14577 \t Loss:1.074 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14578 \t Loss:1.074 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14579 \t Loss:1.074 \t error(train):87.1% \t error(val):85.2%\n",
      "iter:14580 \t Loss:1.074 \t error(train):87.1% \t error(val):85.2%\n",
      "iter:14581 \t Loss:1.074 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14582 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14583 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14584 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14585 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14586 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14587 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14588 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14589 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14590 \t Loss:1.073 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14591 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14592 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14593 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14594 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14595 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14596 \t Loss:1.073 \t error(train):87.2% \t error(val):85.1%\n",
      "iter:14597 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14598 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14599 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14600 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14601 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14602 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14603 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14604 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14605 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14606 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14607 \t Loss:1.073 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14608 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14609 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14610 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14611 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14612 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14613 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14614 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14615 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14616 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14617 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14618 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14619 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14620 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14621 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14622 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14623 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14624 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14625 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14626 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14627 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14628 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14629 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14630 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14631 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14632 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14633 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14634 \t Loss:1.072 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14635 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14636 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14637 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14638 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14639 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14640 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14641 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14642 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14643 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14644 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14645 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14646 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14647 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14648 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14649 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14650 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14651 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14652 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14653 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14654 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14655 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14656 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14657 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14658 \t Loss:1.071 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14659 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14660 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14661 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14662 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14663 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14664 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14665 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14666 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14667 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14668 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14669 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14670 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14671 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14672 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14673 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14674 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14675 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14676 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14677 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14678 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14679 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14680 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14681 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14682 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14683 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14684 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14685 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14686 \t Loss:1.070 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14687 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14688 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14689 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14690 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14691 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14692 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14693 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14694 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14695 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14696 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14697 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14698 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14699 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14700 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14701 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14702 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14703 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14704 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14705 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14706 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14707 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14708 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14709 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14710 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14711 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14712 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14713 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14714 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14715 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14716 \t Loss:1.069 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14717 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14718 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14719 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14720 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14721 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14722 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14723 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14724 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14725 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14726 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14727 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14728 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14729 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14730 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14731 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14732 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14733 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14734 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14735 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14736 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14737 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14738 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14739 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14740 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14741 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14742 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14743 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14744 \t Loss:1.068 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14745 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14746 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14747 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14748 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14749 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14750 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14751 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14752 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14753 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14754 \t Loss:1.067 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14755 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14756 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14757 \t Loss:1.067 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14758 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14759 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14760 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14761 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14762 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14763 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14764 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14765 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14766 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14767 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14768 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14769 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14770 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14771 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14772 \t Loss:1.067 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14773 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14774 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14775 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14776 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14777 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14778 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14779 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14780 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14781 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14782 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14783 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14784 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14785 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14786 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14787 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14788 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14789 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14790 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14791 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14792 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14793 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14794 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14795 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14796 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14797 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14798 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14799 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14800 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14801 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14802 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14803 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14804 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14805 \t Loss:1.066 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14806 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14807 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14808 \t Loss:1.065 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14809 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14810 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14811 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14812 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14813 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14814 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14815 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14816 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14817 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14818 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14819 \t Loss:1.065 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14820 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14821 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14822 \t Loss:1.065 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14823 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14824 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14825 \t Loss:1.065 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14826 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14827 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14828 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14829 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14830 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14831 \t Loss:1.065 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14832 \t Loss:1.065 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14833 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14834 \t Loss:1.064 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14835 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14836 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14837 \t Loss:1.064 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14838 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14839 \t Loss:1.064 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14840 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14841 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14842 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14843 \t Loss:1.064 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14844 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14845 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14846 \t Loss:1.064 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14847 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14848 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14849 \t Loss:1.064 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14850 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14851 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14852 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14853 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14854 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14855 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14856 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14857 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14858 \t Loss:1.064 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14859 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14860 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14861 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14862 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14863 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14864 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14865 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14866 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14867 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14868 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14869 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14870 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14871 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14872 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14873 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14874 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14875 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14876 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14877 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14878 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14879 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14880 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14881 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14882 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14883 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14884 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14885 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14886 \t Loss:1.063 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14887 \t Loss:1.063 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14888 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14889 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14890 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14891 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14892 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14893 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14894 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14895 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14896 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14897 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14898 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14899 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14900 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14901 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14902 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14903 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14904 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14905 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14906 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14907 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14908 \t Loss:1.062 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14909 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14910 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14911 \t Loss:1.062 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14912 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14913 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14914 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14915 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14916 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14917 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14918 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14919 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14920 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14921 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14922 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14923 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14924 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14925 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14926 \t Loss:1.061 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14927 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14928 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14929 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14930 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14931 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14932 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14933 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14934 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14935 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14936 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14937 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14938 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14939 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14940 \t Loss:1.061 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14941 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14942 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14943 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14944 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14945 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14946 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14947 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14948 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14949 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14950 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14951 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14952 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14953 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14954 \t Loss:1.060 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14955 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14956 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14957 \t Loss:1.060 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14958 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14959 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14960 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14961 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14962 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14963 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14964 \t Loss:1.060 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14965 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14966 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14967 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14968 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14969 \t Loss:1.060 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14970 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14971 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14972 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14973 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14974 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14975 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14976 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14977 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14978 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14979 \t Loss:1.059 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:14980 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14981 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14982 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14983 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14984 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14985 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14986 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14987 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14988 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14989 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14990 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14991 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14992 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14993 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14994 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14995 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14996 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14997 \t Loss:1.059 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:14998 \t Loss:1.059 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:14999 \t Loss:1.058 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15000 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15001 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15002 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15003 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15004 \t Loss:1.058 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15005 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15006 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15007 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15008 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15009 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15010 \t Loss:1.058 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15011 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15012 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15013 \t Loss:1.058 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15014 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15015 \t Loss:1.058 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15016 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15017 \t Loss:1.058 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15018 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15019 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15020 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15021 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15022 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15023 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15024 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15025 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15026 \t Loss:1.058 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15027 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15028 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15029 \t Loss:1.058 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15030 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15031 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15032 \t Loss:1.057 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15033 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15034 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15035 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15036 \t Loss:1.057 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15037 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15038 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15039 \t Loss:1.057 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15040 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15041 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15042 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15043 \t Loss:1.057 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15044 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15045 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15046 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15047 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15048 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15049 \t Loss:1.057 \t error(train):87.2% \t error(val):85.2%\n",
      "iter:15050 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15051 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15052 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15053 \t Loss:1.057 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15054 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15055 \t Loss:1.057 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15056 \t Loss:1.057 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15057 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15058 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15059 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15060 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15061 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15062 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15063 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15064 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15065 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15066 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15067 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15068 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15069 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15070 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15071 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15072 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15073 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15074 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15075 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15076 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15077 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15078 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15079 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15080 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15081 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15082 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15083 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15084 \t Loss:1.056 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15085 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15086 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15087 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15088 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15089 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15090 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15091 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15092 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15093 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15094 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15095 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15096 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15097 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15098 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15099 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15100 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15101 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15102 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15103 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15104 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15105 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15106 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15107 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15108 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15109 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15110 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15111 \t Loss:1.055 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15112 \t Loss:1.055 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15113 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15114 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15115 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15116 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15117 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15118 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15119 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15120 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15121 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15122 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15123 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15124 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15125 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15126 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15127 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15128 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15129 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15130 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15131 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15132 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15133 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15134 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15135 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15136 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15137 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15138 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15139 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15140 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15141 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15142 \t Loss:1.054 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15143 \t Loss:1.054 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15144 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15145 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15146 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15147 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15148 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15149 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15150 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15151 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15152 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15153 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15154 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15155 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15156 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15157 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15158 \t Loss:1.053 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15159 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15160 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15161 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15162 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15163 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15164 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15165 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15166 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15167 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15168 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15169 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15170 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15171 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15172 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15173 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15174 \t Loss:1.053 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15175 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15176 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15177 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15178 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15179 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15180 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15181 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15182 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15183 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15184 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15185 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15186 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15187 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15188 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15189 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15190 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15191 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15192 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15193 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15194 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15195 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15196 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15197 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15198 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15199 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15200 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15201 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15202 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15203 \t Loss:1.052 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15204 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15205 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15206 \t Loss:1.052 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15207 \t Loss:1.052 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15208 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15209 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15210 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15211 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15212 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15213 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15214 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15215 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15216 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15217 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15218 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15219 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15220 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15221 \t Loss:1.051 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15222 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15223 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15224 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15225 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15226 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15227 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15228 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15229 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15230 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15231 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15232 \t Loss:1.051 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15233 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15234 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15235 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15236 \t Loss:1.051 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15237 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15238 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15239 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15240 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15241 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15242 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15243 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15244 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15245 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15246 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15247 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15248 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15249 \t Loss:1.050 \t error(train):87.2% \t error(val):85.3%\n",
      "iter:15250 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15251 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15252 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15253 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15254 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15255 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15256 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15257 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15258 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15259 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15260 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15261 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15262 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15263 \t Loss:1.050 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15264 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15265 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15266 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15267 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15268 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15269 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15270 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15271 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15272 \t Loss:1.049 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15273 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15274 \t Loss:1.049 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15275 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15276 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15277 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15278 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15279 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15280 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15281 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15282 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15283 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15284 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15285 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15286 \t Loss:1.049 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15287 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15288 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15289 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15290 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15291 \t Loss:1.049 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15292 \t Loss:1.048 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15293 \t Loss:1.048 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15294 \t Loss:1.048 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15295 \t Loss:1.048 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15296 \t Loss:1.048 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15297 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15298 \t Loss:1.047 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15299 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15300 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15301 \t Loss:1.047 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15302 \t Loss:1.047 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15303 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15304 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15305 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15306 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15307 \t Loss:1.047 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15308 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15309 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15310 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15311 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15312 \t Loss:1.047 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15313 \t Loss:1.047 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15314 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15315 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15316 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15317 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15318 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15319 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15320 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15321 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15322 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15323 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15324 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15325 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15326 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15327 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15328 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15329 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15330 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15331 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15332 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15333 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15334 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15335 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15336 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15337 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15338 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15339 \t Loss:1.046 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15340 \t Loss:1.046 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15341 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15342 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15343 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15344 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15345 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15346 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15347 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15348 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15349 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15350 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15351 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15352 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15353 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15354 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15355 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15356 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15357 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15358 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15359 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15360 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15361 \t Loss:1.045 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15362 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15363 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15364 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15365 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15366 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15367 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15368 \t Loss:1.045 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15369 \t Loss:1.045 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15370 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15371 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15372 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15373 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15374 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15375 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15376 \t Loss:1.044 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15377 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15378 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15379 \t Loss:1.044 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15380 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15381 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15382 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15383 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15384 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15385 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15386 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15387 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15388 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15389 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15390 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15391 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15392 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15393 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15394 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15395 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15396 \t Loss:1.044 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15397 \t Loss:1.044 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15398 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15399 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15400 \t Loss:1.043 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15401 \t Loss:1.043 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15402 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15403 \t Loss:1.043 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15404 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15405 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15406 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15407 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15408 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15409 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15410 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15411 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15412 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15413 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15414 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15415 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15416 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15417 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15418 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15419 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15420 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15421 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15422 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15423 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15424 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15425 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15426 \t Loss:1.043 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15427 \t Loss:1.043 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15428 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15429 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15430 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15431 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15432 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15433 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15434 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15435 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15436 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15437 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15438 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15439 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15440 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15441 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15442 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15443 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15444 \t Loss:1.042 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15445 \t Loss:1.042 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15446 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15447 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15448 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15449 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15450 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15451 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15452 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15453 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15454 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15455 \t Loss:1.042 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15456 \t Loss:1.042 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15457 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15458 \t Loss:1.042 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15459 \t Loss:1.042 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15460 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15461 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15462 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15463 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15464 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15465 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15466 \t Loss:1.041 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15467 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15468 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15469 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15470 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15471 \t Loss:1.041 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15472 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15473 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15474 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15475 \t Loss:1.041 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15476 \t Loss:1.041 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15477 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15478 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15479 \t Loss:1.041 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15480 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15481 \t Loss:1.041 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15482 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15483 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15484 \t Loss:1.041 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15485 \t Loss:1.041 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15486 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15487 \t Loss:1.041 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15488 \t Loss:1.041 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15489 \t Loss:1.041 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15490 \t Loss:1.041 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15491 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15492 \t Loss:1.040 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15493 \t Loss:1.040 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15494 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15495 \t Loss:1.040 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15496 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15497 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15498 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15499 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15500 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15501 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15502 \t Loss:1.040 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15503 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15504 \t Loss:1.040 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15505 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15506 \t Loss:1.040 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15507 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15508 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15509 \t Loss:1.040 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15510 \t Loss:1.040 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15511 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15512 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15513 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15514 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15515 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15516 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15517 \t Loss:1.040 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15518 \t Loss:1.039 \t error(train):87.3% \t error(val):85.3%\n",
      "iter:15519 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15520 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15521 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15522 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15523 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15524 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15525 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15526 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15527 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15528 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15529 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15530 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15531 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15532 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15533 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15534 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15535 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15536 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15537 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15538 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15539 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15540 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15541 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15542 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15543 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15544 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15545 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15546 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15547 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15548 \t Loss:1.039 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15549 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15550 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15551 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15552 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15553 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15554 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15555 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15556 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15557 \t Loss:1.038 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15558 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15559 \t Loss:1.038 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15560 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15561 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15562 \t Loss:1.038 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15563 \t Loss:1.038 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15564 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15565 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15566 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15567 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15568 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15569 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15570 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15571 \t Loss:1.038 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15572 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15573 \t Loss:1.038 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15574 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15575 \t Loss:1.038 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15576 \t Loss:1.038 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15577 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15578 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15579 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15580 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15581 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15582 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15583 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15584 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15585 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15586 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15587 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15588 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15589 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15590 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15591 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15592 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15593 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15594 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15595 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15596 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15597 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15598 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15599 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15600 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15601 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15602 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15603 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15604 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15605 \t Loss:1.037 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15606 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15607 \t Loss:1.037 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15608 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15609 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15610 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15611 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15612 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15613 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15614 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15615 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15616 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15617 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15618 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15619 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15620 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15621 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15622 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15623 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15624 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15625 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15626 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15627 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15628 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15629 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15630 \t Loss:1.036 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15631 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15632 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15633 \t Loss:1.036 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15634 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15635 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15636 \t Loss:1.035 \t error(train):87.3% \t error(val):85.4%\n",
      "iter:15637 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15638 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15639 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15640 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15641 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15642 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15643 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15644 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15645 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15646 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15647 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15648 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15649 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15650 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15651 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15652 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15653 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15654 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15655 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15656 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15657 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15658 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15659 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15660 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15661 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15662 \t Loss:1.035 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15663 \t Loss:1.035 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15664 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15665 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15666 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15667 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15668 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15669 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15670 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15671 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15672 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15673 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15674 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15675 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15676 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15677 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15678 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15679 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15680 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15681 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15682 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15683 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15684 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15685 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15686 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15687 \t Loss:1.034 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15688 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15689 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15690 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15691 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15692 \t Loss:1.034 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15693 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15694 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15695 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15696 \t Loss:1.033 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15697 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15698 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15699 \t Loss:1.033 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15700 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15701 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15702 \t Loss:1.033 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15703 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15704 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15705 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15706 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15707 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15708 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15709 \t Loss:1.033 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15710 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15711 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15712 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15713 \t Loss:1.033 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15714 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15715 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15716 \t Loss:1.033 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15717 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15718 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15719 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15720 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15721 \t Loss:1.033 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15722 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15723 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15724 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15725 \t Loss:1.032 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15726 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15727 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15728 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15729 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15730 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15731 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15732 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15733 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15734 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15735 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15736 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15737 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15738 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15739 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15740 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15741 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15742 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15743 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15744 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15745 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15746 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15747 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15748 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15749 \t Loss:1.032 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15750 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15751 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15752 \t Loss:1.032 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15753 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15754 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15755 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15756 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15757 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15758 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15759 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15760 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15761 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15762 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15763 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15764 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15765 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15766 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15767 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15768 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15769 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15770 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15771 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15772 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15773 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15774 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15775 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15776 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15777 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15778 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15779 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15780 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15781 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15782 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15783 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15784 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15785 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15786 \t Loss:1.031 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15787 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15788 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15789 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15790 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15791 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15792 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15793 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15794 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15795 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15796 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15797 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15798 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15799 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15800 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15801 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15802 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15803 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15804 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15805 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15806 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15807 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15808 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15809 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15810 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15811 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15812 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15813 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15814 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15815 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15816 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15817 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15818 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15819 \t Loss:1.030 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15820 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15821 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15822 \t Loss:1.029 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15823 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15824 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15825 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15826 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15827 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15828 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15829 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15830 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15831 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15832 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15833 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15834 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15835 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15836 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15837 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15838 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15839 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15840 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15841 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15842 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15843 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15844 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15845 \t Loss:1.029 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15846 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15847 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15848 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15849 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15850 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15851 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15852 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15853 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15854 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15855 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15856 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15857 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15858 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15859 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15860 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15861 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15862 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15863 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15864 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15865 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15866 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15867 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15868 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15869 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15870 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15871 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15872 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15873 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15874 \t Loss:1.028 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15875 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15876 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15877 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15878 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15879 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15880 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15881 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15882 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15883 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15884 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15885 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15886 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15887 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15888 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15889 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15890 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15891 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15892 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15893 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15894 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15895 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15896 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15897 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15898 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15899 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15900 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15901 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15902 \t Loss:1.027 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15903 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15904 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15905 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15906 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15907 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15908 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15909 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15910 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15911 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15912 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15913 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15914 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15915 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15916 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15917 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15918 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15919 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15920 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15921 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15922 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15923 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15924 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15925 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15926 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15927 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15928 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15929 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15930 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15931 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15932 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15933 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15934 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15935 \t Loss:1.026 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15936 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15937 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15938 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15939 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15940 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15941 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15942 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15943 \t Loss:1.025 \t error(train):87.4% \t error(val):85.3%\n",
      "iter:15944 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15945 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15946 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15947 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15948 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15949 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15950 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15951 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15952 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15953 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15954 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15955 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15956 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15957 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15958 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15959 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15960 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15961 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15962 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15963 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15964 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15965 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15966 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15967 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15968 \t Loss:1.025 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15969 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15970 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15971 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15972 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15973 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15974 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15975 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15976 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15977 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15978 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15979 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15980 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15981 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15982 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15983 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15984 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15985 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15986 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15987 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15988 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15989 \t Loss:1.024 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:15990 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15991 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15992 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15993 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15994 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15995 \t Loss:1.024 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:15996 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15997 \t Loss:1.024 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:15998 \t Loss:1.024 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:15999 \t Loss:1.024 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16000 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16001 \t Loss:1.023 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16002 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16003 \t Loss:1.023 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16004 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16005 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16006 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16007 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16008 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16009 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16010 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16011 \t Loss:1.023 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16012 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16013 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16014 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16015 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16016 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16017 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16018 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16019 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16020 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16021 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16022 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16023 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16024 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16025 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16026 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16027 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16028 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16029 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16030 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16031 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16032 \t Loss:1.023 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16033 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16034 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16035 \t Loss:1.022 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16036 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16037 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16038 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16039 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16040 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16041 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16042 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16043 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16044 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16045 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16046 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16047 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16048 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16049 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16050 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16051 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16052 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16053 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16054 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16055 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16056 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16057 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16058 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16059 \t Loss:1.022 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16060 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16061 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16062 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16063 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16064 \t Loss:1.022 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16065 \t Loss:1.022 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16066 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16067 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16068 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16069 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16070 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16071 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16072 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16073 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16074 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16075 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16076 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16077 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16078 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16079 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16080 \t Loss:1.021 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16081 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16082 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16083 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16084 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16085 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16086 \t Loss:1.021 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16087 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16088 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16089 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16090 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16091 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16092 \t Loss:1.021 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16093 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16094 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16095 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16096 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16097 \t Loss:1.020 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16098 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16099 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16100 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16101 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16102 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16103 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16104 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16105 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16106 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16107 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16108 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16109 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16110 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16111 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16112 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16113 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16114 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16115 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16116 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16117 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16118 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16119 \t Loss:1.020 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16120 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16121 \t Loss:1.020 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16122 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16123 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16124 \t Loss:1.020 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16125 \t Loss:1.020 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16126 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16127 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16128 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16129 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16130 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16131 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16132 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16133 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16134 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16135 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16136 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16137 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16138 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16139 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16140 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16141 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16142 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16143 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16144 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16145 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16146 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16147 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16148 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16149 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16150 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16151 \t Loss:1.019 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16152 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16153 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16154 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16155 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16156 \t Loss:1.019 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16157 \t Loss:1.019 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16158 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16159 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16160 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16161 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16162 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16163 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16164 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16165 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16166 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16167 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16168 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16169 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16170 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16171 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16172 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16173 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16174 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16175 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16176 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16177 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16178 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16179 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16180 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16181 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16182 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16183 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16184 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16185 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16186 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16187 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16188 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16189 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16190 \t Loss:1.018 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16191 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16192 \t Loss:1.018 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16193 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16194 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16195 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16196 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16197 \t Loss:1.017 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16198 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16199 \t Loss:1.017 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16200 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16201 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16202 \t Loss:1.017 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16203 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16204 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16205 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16206 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16207 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16208 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16209 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16210 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16211 \t Loss:1.017 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16212 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16213 \t Loss:1.017 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16214 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16215 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16216 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16217 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16218 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16219 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16220 \t Loss:1.017 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16221 \t Loss:1.017 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16222 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16223 \t Loss:1.016 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16224 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16225 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16226 \t Loss:1.016 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16227 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16228 \t Loss:1.016 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16229 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16230 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16231 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16232 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16233 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16234 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16235 \t Loss:1.016 \t error(train):87.4% \t error(val):85.5%\n",
      "iter:16236 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16237 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16238 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16239 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16240 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16241 \t Loss:1.016 \t error(train):87.4% \t error(val):85.4%\n",
      "iter:16242 \t Loss:1.016 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16243 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16244 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16245 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16246 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16247 \t Loss:1.016 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16248 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16249 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16250 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16251 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16252 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16253 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16254 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16255 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16256 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16257 \t Loss:1.016 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16258 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16259 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16260 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16261 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16262 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16263 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16264 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16265 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16266 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16267 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16268 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16269 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16270 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16271 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16272 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16273 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16274 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16275 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16276 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16277 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16278 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16279 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16280 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16281 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16282 \t Loss:1.015 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16283 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16284 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16285 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16286 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16287 \t Loss:1.015 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16288 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16289 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16290 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16291 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16292 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16293 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16294 \t Loss:1.014 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16295 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16296 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16297 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16298 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16299 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16300 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16301 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16302 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16303 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16304 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16305 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16306 \t Loss:1.014 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16307 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16308 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16309 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16310 \t Loss:1.014 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16311 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16312 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16313 \t Loss:1.014 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16314 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16315 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16316 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16317 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16318 \t Loss:1.014 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16319 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16320 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16321 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16322 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16323 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16324 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16325 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16326 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16327 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16328 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16329 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16330 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16331 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16332 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16333 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16334 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16335 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16336 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16337 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16338 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16339 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16340 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16341 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16342 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16343 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16344 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16345 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16346 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16347 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16348 \t Loss:1.013 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16349 \t Loss:1.013 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16350 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16351 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16352 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16353 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16354 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16355 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16356 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16357 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16358 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16359 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16360 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16361 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16362 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16363 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16364 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16365 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16366 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16367 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16368 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16369 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16370 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16371 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16372 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16373 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16374 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16375 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16376 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16377 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16378 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16379 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16380 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16381 \t Loss:1.012 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16382 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16383 \t Loss:1.012 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16384 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16385 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16386 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16387 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16388 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16389 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16390 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16391 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16392 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16393 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16394 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16395 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16396 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16397 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16398 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16399 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16400 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16401 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16402 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16403 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16404 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16405 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16406 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16407 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16408 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16409 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16410 \t Loss:1.011 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16411 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16412 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16413 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16414 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16415 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16416 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16417 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16418 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16419 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16420 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16421 \t Loss:1.011 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16422 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16423 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16424 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16425 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16426 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16427 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16428 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16429 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16430 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16431 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16432 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16433 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16434 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16435 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16436 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16437 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16438 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16439 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16440 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16441 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16442 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16443 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16444 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16445 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16446 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16447 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16448 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16449 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16450 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16451 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16452 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16453 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16454 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16455 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16456 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16457 \t Loss:1.010 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16458 \t Loss:1.010 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16459 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16460 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16461 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16462 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16463 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16464 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16465 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16466 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16467 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16468 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16469 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16470 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16471 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16472 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16473 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16474 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16475 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16476 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16477 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16478 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16479 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16480 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16481 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16482 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16483 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16484 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16485 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16486 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16487 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16488 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16489 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16490 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16491 \t Loss:1.009 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16492 \t Loss:1.009 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16493 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16494 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16495 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16496 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16497 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16498 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16499 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16500 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16501 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16502 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16503 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16504 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16505 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16506 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16507 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16508 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16509 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16510 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16511 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16512 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16513 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16514 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16515 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16516 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16517 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16518 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16519 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16520 \t Loss:1.008 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16521 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16522 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16523 \t Loss:1.008 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16524 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16525 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16526 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16527 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16528 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16529 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16530 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16531 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16532 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16533 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16534 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16535 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16536 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16537 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16538 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16539 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16540 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16541 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16542 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16543 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16544 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16545 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16546 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16547 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16548 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16549 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16550 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16551 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16552 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16553 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16554 \t Loss:1.007 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16555 \t Loss:1.007 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16556 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16557 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16558 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16559 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16560 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16561 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16562 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16563 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16564 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16565 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16566 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16567 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16568 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16569 \t Loss:1.006 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16570 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16571 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16572 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16573 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16574 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16575 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16576 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16577 \t Loss:1.006 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16578 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16579 \t Loss:1.006 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16580 \t Loss:1.006 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16581 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16582 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16583 \t Loss:1.006 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16584 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16585 \t Loss:1.006 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16586 \t Loss:1.006 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16587 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16588 \t Loss:1.005 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16589 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16590 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16591 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16592 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16593 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16594 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16595 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16596 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16597 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16598 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16599 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16600 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16601 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16602 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16603 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16604 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16605 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16606 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16607 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16608 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16609 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16610 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16611 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16612 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16613 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16614 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16615 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16616 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16617 \t Loss:1.005 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16618 \t Loss:1.005 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16619 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16620 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16621 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16622 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16623 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16624 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16625 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16626 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16627 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16628 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16629 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16630 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16631 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16632 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16633 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16634 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16635 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16636 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16637 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16638 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16639 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16640 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16641 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16642 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16643 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16644 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16645 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16646 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16647 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16648 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16649 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16650 \t Loss:1.004 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16651 \t Loss:1.004 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16652 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16653 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16654 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16655 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16656 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16657 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16658 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16659 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16660 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16661 \t Loss:1.003 \t error(train):87.5% \t error(val):85.5%\n",
      "iter:16662 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16663 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16664 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16665 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16666 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16667 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16668 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16669 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16670 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16671 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16672 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16673 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16674 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16675 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16676 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16677 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16678 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16679 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16680 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16681 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16682 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16683 \t Loss:1.003 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16684 \t Loss:1.003 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16685 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16686 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16687 \t Loss:1.002 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16688 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16689 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16690 \t Loss:1.002 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16691 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16692 \t Loss:1.002 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16693 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16694 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16695 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16696 \t Loss:1.002 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16697 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16698 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16699 \t Loss:1.002 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16700 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16701 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16702 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16703 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16704 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16705 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16706 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16707 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16708 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16709 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16710 \t Loss:1.002 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16711 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16712 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16713 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16714 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16715 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16716 \t Loss:1.002 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16717 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16718 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16719 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16720 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16721 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16722 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16723 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16724 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16725 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16726 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16727 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16728 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16729 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16730 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16731 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16732 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16733 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16734 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16735 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16736 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16737 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16738 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16739 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16740 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16741 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16742 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16743 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16744 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16745 \t Loss:1.001 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16746 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16747 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16748 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16749 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16750 \t Loss:1.001 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16751 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16752 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16753 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16754 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16755 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16756 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16757 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16758 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16759 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16760 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16761 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16762 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16763 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16764 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16765 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16766 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16767 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16768 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16769 \t Loss:1.000 \t error(train):87.5% \t error(val):85.4%\n",
      "iter:16770 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16771 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16772 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16773 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16774 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16775 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16776 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16777 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16778 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16779 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16780 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16781 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16782 \t Loss:1.000 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16783 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16784 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16785 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16786 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16787 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16788 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16789 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16790 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16791 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16792 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16793 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16794 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16795 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16796 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16797 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16798 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16799 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16800 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16801 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16802 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16803 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16804 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16805 \t Loss:0.999 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16806 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16807 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16808 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16809 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16810 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16811 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16812 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16813 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16814 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16815 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16816 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16817 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16818 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16819 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16820 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16821 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16822 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16823 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16824 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16825 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16826 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16827 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16828 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16829 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16830 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16831 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16832 \t Loss:0.998 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16833 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16834 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16835 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16836 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16837 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16838 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16839 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16840 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16841 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16842 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16843 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16844 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16845 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16846 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16847 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16848 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16849 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16850 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16851 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16852 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16853 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16854 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16855 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16856 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16857 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16858 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16859 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16860 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16861 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16862 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16863 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16864 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16865 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16866 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16867 \t Loss:0.997 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16868 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16869 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16870 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16871 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16872 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16873 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16874 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16875 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16876 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16877 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16878 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16879 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16880 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16881 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16882 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16883 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16884 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16885 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16886 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16887 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16888 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16889 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16890 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16891 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16892 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16893 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16894 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16895 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16896 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16897 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16898 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16899 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16900 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16901 \t Loss:0.996 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16902 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16903 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16904 \t Loss:0.995 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16905 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16906 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16907 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16908 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16909 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16910 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16911 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16912 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16913 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16914 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16915 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16916 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16917 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16918 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16919 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16920 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16921 \t Loss:0.995 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16922 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16923 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16924 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16925 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16926 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16927 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16928 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16929 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16930 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16931 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16932 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16933 \t Loss:0.995 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16934 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16935 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16936 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16937 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16938 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16939 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16940 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16941 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16942 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16943 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16944 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16945 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16946 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16947 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16948 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16949 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16950 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16951 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16952 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16953 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16954 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16955 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16956 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16957 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16958 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16959 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16960 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16961 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16962 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16963 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16964 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16965 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16966 \t Loss:0.994 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16967 \t Loss:0.994 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16968 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16969 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16970 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16971 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16972 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16973 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16974 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16975 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16976 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16977 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16978 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16979 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16980 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16981 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16982 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16983 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16984 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16985 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16986 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16987 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16988 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:16989 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16990 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16991 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16992 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16993 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16994 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16995 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16996 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16997 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16998 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:16999 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17000 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17001 \t Loss:0.993 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17002 \t Loss:0.993 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17003 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17004 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17005 \t Loss:0.992 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17006 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17007 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17008 \t Loss:0.992 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17009 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17010 \t Loss:0.992 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17011 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17012 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17013 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17014 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17015 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17016 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17017 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17018 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17019 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17020 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17021 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17022 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17023 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17024 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17025 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17026 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17027 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17028 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17029 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17030 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17031 \t Loss:0.992 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17032 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17033 \t Loss:0.992 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17034 \t Loss:0.992 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17035 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17036 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17037 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17038 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17039 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17040 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17041 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17042 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17043 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17044 \t Loss:0.991 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17045 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17046 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17047 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17048 \t Loss:0.991 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17049 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17050 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17051 \t Loss:0.991 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17052 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17053 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17054 \t Loss:0.991 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17055 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17056 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17057 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17058 \t Loss:0.991 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17059 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17060 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17061 \t Loss:0.991 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17062 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17063 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17064 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17065 \t Loss:0.991 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17066 \t Loss:0.991 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17067 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17068 \t Loss:0.991 \t error(train):87.6% \t error(val):85.5%\n",
      "iter:17069 \t Loss:0.991 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17070 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17071 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17072 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17073 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17074 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17075 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17076 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17077 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17078 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17079 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17080 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17081 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17082 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17083 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17084 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17085 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17086 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17087 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17088 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17089 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17090 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17091 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17092 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17093 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17094 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17095 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17096 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17097 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17098 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17099 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17100 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17101 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17102 \t Loss:0.990 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17103 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17104 \t Loss:0.990 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17105 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17106 \t Loss:0.989 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17107 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17108 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17109 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17110 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17111 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17112 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17113 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17114 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17115 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17116 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17117 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17118 \t Loss:0.989 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17119 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17120 \t Loss:0.989 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17121 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17122 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17123 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17124 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17125 \t Loss:0.989 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17126 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17127 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17128 \t Loss:0.989 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17129 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17130 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17131 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17132 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17133 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17134 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17135 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17136 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17137 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17138 \t Loss:0.989 \t error(train):87.6% \t error(val):85.4%\n",
      "iter:17139 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17140 \t Loss:0.989 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17141 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17142 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17143 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17144 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17145 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17146 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17147 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17148 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17149 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17150 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17151 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17152 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17153 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17154 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17155 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17156 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17157 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17158 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17159 \t Loss:0.988 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17160 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17161 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17162 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17163 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17164 \t Loss:0.988 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17165 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17166 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17167 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17168 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17169 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17170 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17171 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17172 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17173 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17174 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17175 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17176 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17177 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17178 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17179 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17180 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17181 \t Loss:0.988 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17182 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17183 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17184 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17185 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17186 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17187 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17188 \t Loss:0.987 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17189 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17190 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17191 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17192 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17193 \t Loss:0.987 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17194 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17195 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17196 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17197 \t Loss:0.987 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17198 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17199 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17200 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17201 \t Loss:0.987 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17202 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17203 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17204 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17205 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17206 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17207 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17208 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17209 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17210 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17211 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17212 \t Loss:0.987 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17213 \t Loss:0.987 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17214 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17215 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17216 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17217 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17218 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17219 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17220 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17221 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17222 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17223 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17224 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17225 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17226 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17227 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17228 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17229 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17230 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17231 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17232 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17233 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17234 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17235 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17236 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17237 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17238 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17239 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17240 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17241 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17242 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17243 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17244 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17245 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17246 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17247 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17248 \t Loss:0.986 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17249 \t Loss:0.986 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17250 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17251 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17252 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17253 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17254 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17255 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17256 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17257 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17258 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17259 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17260 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17261 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17262 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17263 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17264 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17265 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17266 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17267 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17268 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17269 \t Loss:0.985 \t error(train):87.7% \t error(val):85.4%\n",
      "iter:17270 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17271 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17272 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17273 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17274 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17275 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17276 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17277 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17278 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17279 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17280 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17281 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17282 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17283 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17284 \t Loss:0.985 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17285 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17286 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17287 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17288 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17289 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17290 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17291 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17292 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17293 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17294 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17295 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17296 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17297 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17298 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17299 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17300 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17301 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17302 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17303 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17304 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17305 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17306 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17307 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17308 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17309 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17310 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17311 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17312 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17313 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17314 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17315 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17316 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17317 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17318 \t Loss:0.984 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17319 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17320 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17321 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17322 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17323 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17324 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17325 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17326 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17327 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17328 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17329 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17330 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17331 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17332 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17333 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17334 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17335 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17336 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17337 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17338 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17339 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17340 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17341 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17342 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17343 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17344 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17345 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17346 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17347 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17348 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17349 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17350 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17351 \t Loss:0.983 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17352 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17353 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17354 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17355 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17356 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17357 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17358 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17359 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17360 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17361 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17362 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17363 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17364 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17365 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17366 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17367 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17368 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17369 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17370 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17371 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17372 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17373 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17374 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17375 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17376 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17377 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17378 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17379 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17380 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17381 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17382 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17383 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17384 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17385 \t Loss:0.982 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17386 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17387 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17388 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17389 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17390 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17391 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17392 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17393 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17394 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17395 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17396 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17397 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17398 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17399 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17400 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17401 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17402 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17403 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17404 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17405 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17406 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17407 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17408 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17409 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17410 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17411 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17412 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17413 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17414 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17415 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17416 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17417 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17418 \t Loss:0.981 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17419 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17420 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17421 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17422 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17423 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17424 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17425 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17426 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17427 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17428 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17429 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17430 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17431 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17432 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17433 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17434 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17435 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17436 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17437 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17438 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17439 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17440 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17441 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17442 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17443 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17444 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17445 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17446 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17447 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17448 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17449 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17450 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17451 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17452 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17453 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17454 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17455 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17456 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17457 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17458 \t Loss:0.980 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17459 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17460 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17461 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17462 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17463 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17464 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17465 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17466 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17467 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17468 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17469 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17470 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17471 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17472 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17473 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17474 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17475 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17476 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17477 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17478 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17479 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17480 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17481 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17482 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17483 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17484 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17485 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17486 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17487 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17488 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17489 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17490 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17491 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17492 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17493 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17494 \t Loss:0.979 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17495 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17496 \t Loss:0.979 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17497 \t Loss:0.978 \t error(train):87.7% \t error(val):85.6%\n",
      "iter:17498 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17499 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17500 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17501 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17502 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17503 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17504 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17505 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17506 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17507 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17508 \t Loss:0.978 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17509 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17510 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17511 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17512 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17513 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17514 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17515 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17516 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17517 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17518 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17519 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17520 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17521 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17522 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17523 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17524 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17525 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17526 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17527 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17528 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17529 \t Loss:0.978 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17530 \t Loss:0.978 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17531 \t Loss:0.978 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17532 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17533 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17534 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17535 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17536 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17537 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17538 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17539 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17540 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17541 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17542 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17543 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17544 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17545 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17546 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17547 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17548 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17549 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17550 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17551 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17552 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17553 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17554 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17555 \t Loss:0.977 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17556 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17557 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17558 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17559 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17560 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17561 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17562 \t Loss:0.977 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17563 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17564 \t Loss:0.977 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17565 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17566 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17567 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17568 \t Loss:0.977 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17569 \t Loss:0.977 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17570 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17571 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17572 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17573 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17574 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17575 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17576 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17577 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17578 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17579 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17580 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17581 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17582 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17583 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17584 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17585 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17586 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17587 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17588 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17589 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17590 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17591 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17592 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17593 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17594 \t Loss:0.976 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17595 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17596 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17597 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17598 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17599 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17600 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17601 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17602 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17603 \t Loss:0.976 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17604 \t Loss:0.976 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17605 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17606 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17607 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17608 \t Loss:0.975 \t error(train):87.7% \t error(val):85.5%\n",
      "iter:17609 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17610 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17611 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17612 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17613 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17614 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17615 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17616 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17617 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17618 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17619 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17620 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17621 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17622 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17623 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17624 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17625 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17626 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17627 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17628 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17629 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17630 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17631 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17632 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17633 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17634 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17635 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17636 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17637 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17638 \t Loss:0.975 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17639 \t Loss:0.975 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17640 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17641 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17642 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17643 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17644 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17645 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17646 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17647 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17648 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17649 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17650 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17651 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17652 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17653 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17654 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17655 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17656 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17657 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17658 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17659 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17660 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17661 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17662 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17663 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17664 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17665 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17666 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17667 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17668 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17669 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17670 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17671 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17672 \t Loss:0.974 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17673 \t Loss:0.974 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17674 \t Loss:0.974 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17675 \t Loss:0.973 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17676 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17677 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17678 \t Loss:0.973 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17679 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17680 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17681 \t Loss:0.973 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17682 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17683 \t Loss:0.973 \t error(train):87.8% \t error(val):85.5%\n",
      "iter:17684 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17685 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17686 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17687 \t Loss:0.973 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17688 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17689 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17690 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17691 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17692 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17693 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17694 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17695 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17696 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17697 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17698 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17699 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17700 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17701 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17702 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17703 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17704 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17705 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17706 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17707 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17708 \t Loss:0.973 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17709 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17710 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17711 \t Loss:0.973 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17712 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17713 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17714 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17715 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17716 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17717 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17718 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17719 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17720 \t Loss:0.972 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17721 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17722 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17723 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17724 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17725 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17726 \t Loss:0.972 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17727 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17728 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17729 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17730 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17731 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17732 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17733 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17734 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17735 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17736 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17737 \t Loss:0.972 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17738 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17739 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17740 \t Loss:0.972 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17741 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17742 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17743 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17744 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17745 \t Loss:0.972 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17746 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17747 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17748 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17749 \t Loss:0.971 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17750 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17751 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17752 \t Loss:0.971 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17753 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17754 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17755 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17756 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17757 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17758 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17759 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17760 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17761 \t Loss:0.971 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17762 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17763 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17764 \t Loss:0.971 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17765 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17766 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17767 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17768 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17769 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17770 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17771 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17772 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17773 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17774 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17775 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17776 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17777 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17778 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17779 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17780 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17781 \t Loss:0.971 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17782 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17783 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17784 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17785 \t Loss:0.970 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17786 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17787 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17788 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17789 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17790 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17791 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17792 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17793 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17794 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17795 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17796 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17797 \t Loss:0.970 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17798 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17799 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17800 \t Loss:0.970 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17801 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17802 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17803 \t Loss:0.970 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17804 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17805 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17806 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17807 \t Loss:0.970 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17808 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17809 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17810 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17811 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17812 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17813 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17814 \t Loss:0.970 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17815 \t Loss:0.970 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17816 \t Loss:0.970 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17817 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17818 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17819 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17820 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17821 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17822 \t Loss:0.969 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17823 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17824 \t Loss:0.969 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17825 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17826 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17827 \t Loss:0.969 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17828 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17829 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17830 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17831 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17832 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17833 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17834 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17835 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17836 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17837 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17838 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17839 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17840 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17841 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17842 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17843 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17844 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17845 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17846 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17847 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17848 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17849 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17850 \t Loss:0.969 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17851 \t Loss:0.969 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17852 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17853 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17854 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17855 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17856 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17857 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17858 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17859 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17860 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17861 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17862 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17863 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17864 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17865 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17866 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17867 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17868 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17869 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17870 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17871 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17872 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17873 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17874 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17875 \t Loss:0.968 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17876 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17877 \t Loss:0.968 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17878 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17879 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17880 \t Loss:0.968 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:17881 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17882 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17883 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17884 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17885 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17886 \t Loss:0.968 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17887 \t Loss:0.968 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17888 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17889 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17890 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17891 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17892 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17893 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17894 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17895 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17896 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17897 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17898 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17899 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17900 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17901 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17902 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17903 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17904 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17905 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17906 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17907 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17908 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17909 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17910 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17911 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17912 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17913 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17914 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17915 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17916 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17917 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17918 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17919 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17920 \t Loss:0.967 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17921 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17922 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17923 \t Loss:0.967 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17924 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17925 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17926 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17927 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17928 \t Loss:0.966 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17929 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17930 \t Loss:0.966 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17931 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17932 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17933 \t Loss:0.966 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17934 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17935 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17936 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17937 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17938 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17939 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17940 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17941 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17942 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17943 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17944 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17945 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17946 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17947 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17948 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17949 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17950 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17951 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17952 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17953 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17954 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17955 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17956 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17957 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17958 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17959 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17960 \t Loss:0.966 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17961 \t Loss:0.966 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17962 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17963 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17964 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17965 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17966 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17967 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17968 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17969 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17970 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17971 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17972 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17973 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17974 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17975 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17976 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17977 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17978 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17979 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17980 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17981 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17982 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17983 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17984 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17985 \t Loss:0.965 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:17986 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17987 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17988 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17989 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17990 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17991 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17992 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17993 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17994 \t Loss:0.965 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17995 \t Loss:0.965 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17996 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17997 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:17998 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:17999 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18000 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18001 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18002 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18003 \t Loss:0.964 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18004 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18005 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18006 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18007 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18008 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18009 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18010 \t Loss:0.964 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18011 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18012 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18013 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18014 \t Loss:0.964 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18015 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18016 \t Loss:0.964 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18017 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18018 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18019 \t Loss:0.964 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18020 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18021 \t Loss:0.964 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18022 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18023 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18024 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18025 \t Loss:0.964 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18026 \t Loss:0.964 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18027 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18028 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18029 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18030 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18031 \t Loss:0.964 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18032 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18033 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18034 \t Loss:0.964 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18035 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18036 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18037 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18038 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18039 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18040 \t Loss:0.963 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18041 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18042 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18043 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18044 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18045 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18046 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18047 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18048 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18049 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18050 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18051 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18052 \t Loss:0.963 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18053 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18054 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18055 \t Loss:0.963 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18056 \t Loss:0.963 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18057 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18058 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18059 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18060 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18061 \t Loss:0.963 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18062 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18063 \t Loss:0.963 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18064 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18065 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18066 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18067 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18068 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18069 \t Loss:0.963 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18070 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18071 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18072 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18073 \t Loss:0.963 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18074 \t Loss:0.963 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18075 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18076 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18077 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18078 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18079 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18080 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18081 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18082 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18083 \t Loss:0.962 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18084 \t Loss:0.962 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18085 \t Loss:0.962 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18086 \t Loss:0.962 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18087 \t Loss:0.962 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18088 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18089 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18090 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18091 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18092 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18093 \t Loss:0.962 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18094 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18095 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18096 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18097 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18098 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18099 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18100 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18101 \t Loss:0.962 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18102 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18103 \t Loss:0.962 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18104 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18105 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18106 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18107 \t Loss:0.962 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18108 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18109 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18110 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18111 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18112 \t Loss:0.962 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18113 \t Loss:0.962 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18114 \t Loss:0.962 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18115 \t Loss:0.961 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18116 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18117 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18118 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18119 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18120 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18121 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18122 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18123 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18124 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18125 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18126 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18127 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18128 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18129 \t Loss:0.961 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18130 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18131 \t Loss:0.961 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18132 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18133 \t Loss:0.961 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18134 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18135 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18136 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18137 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18138 \t Loss:0.961 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18139 \t Loss:0.961 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18140 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18141 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18142 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18143 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18144 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18145 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18146 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18147 \t Loss:0.961 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18148 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18149 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18150 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18151 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18152 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18153 \t Loss:0.961 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18154 \t Loss:0.961 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18155 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18156 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18157 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18158 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18159 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18160 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18161 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18162 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18163 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18164 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18165 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18166 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18167 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18168 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18169 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18170 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18171 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18172 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18173 \t Loss:0.960 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18174 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18175 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18176 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18177 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18178 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18179 \t Loss:0.960 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18180 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18181 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18182 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18183 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18184 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18185 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18186 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18187 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18188 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18189 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18190 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18191 \t Loss:0.960 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18192 \t Loss:0.960 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18193 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18194 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18195 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18196 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18197 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18198 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18199 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18200 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18201 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18202 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18203 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18204 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18205 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18206 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18207 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18208 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18209 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18210 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18211 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18212 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18213 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18214 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18215 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18216 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18217 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18218 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18219 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18220 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18221 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18222 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18223 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18224 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18225 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18226 \t Loss:0.959 \t error(train):87.8% \t error(val):85.7%\n",
      "iter:18227 \t Loss:0.959 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18228 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18229 \t Loss:0.959 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18230 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18231 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18232 \t Loss:0.958 \t error(train):87.8% \t error(val):85.6%\n",
      "iter:18233 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18234 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18235 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18236 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18237 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18238 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18239 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18240 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18241 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18242 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18243 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18244 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18245 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18246 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18247 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18248 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18249 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18250 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18251 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18252 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18253 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18254 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18255 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18256 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18257 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18258 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18259 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18260 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18261 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18262 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18263 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18264 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18265 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18266 \t Loss:0.958 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18267 \t Loss:0.958 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18268 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18269 \t Loss:0.957 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18270 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18271 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18272 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18273 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18274 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18275 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18276 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18277 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18278 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18279 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18280 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18281 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18282 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18283 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18284 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18285 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18286 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18287 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18288 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18289 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18290 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18291 \t Loss:0.957 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18292 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18293 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18294 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18295 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18296 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18297 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18298 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18299 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18300 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18301 \t Loss:0.957 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18302 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18303 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18304 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18305 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18306 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18307 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18308 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18309 \t Loss:0.956 \t error(train):87.9% \t error(val):85.7%\n",
      "iter:18310 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18311 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18312 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18313 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18314 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18315 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18316 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18317 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18318 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18319 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18320 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18321 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18322 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18323 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18324 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18325 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18326 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18327 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18328 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18329 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18330 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18331 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18332 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18333 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18334 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18335 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18336 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18337 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18338 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18339 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18340 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18341 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18342 \t Loss:0.956 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18343 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18344 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18345 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18346 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18347 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18348 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18349 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18350 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18351 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18352 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18353 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18354 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18355 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18356 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18357 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18358 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18359 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18360 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18361 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18362 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18363 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18364 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18365 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18366 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18367 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18368 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18369 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18370 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18371 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18372 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18373 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18374 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18375 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18376 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18377 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18378 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18379 \t Loss:0.955 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18380 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18381 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18382 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18383 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18384 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18385 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18386 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18387 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18388 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18389 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18390 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18391 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18392 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18393 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18394 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18395 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18396 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18397 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18398 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18399 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18400 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18401 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18402 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18403 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18404 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18405 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18406 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18407 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18408 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18409 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18410 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18411 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18412 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18413 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18414 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18415 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18416 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18417 \t Loss:0.954 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18418 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18419 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18420 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18421 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18422 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18423 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18424 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18425 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18426 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18427 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18428 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18429 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18430 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18431 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18432 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18433 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18434 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18435 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18436 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18437 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18438 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18439 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18440 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18441 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18442 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18443 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18444 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18445 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18446 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18447 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18448 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18449 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18450 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18451 \t Loss:0.953 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18452 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18453 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18454 \t Loss:0.953 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18455 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18456 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18457 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18458 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18459 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18460 \t Loss:0.952 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18461 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18462 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18463 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18464 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18465 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18466 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18467 \t Loss:0.952 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18468 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18469 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18470 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18471 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18472 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18473 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18474 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18475 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18476 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18477 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18478 \t Loss:0.952 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18479 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18480 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18481 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18482 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18483 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18484 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18485 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18486 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18487 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18488 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18489 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18490 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18491 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18492 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18493 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18494 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18495 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18496 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18497 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18498 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18499 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18500 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18501 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18502 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18503 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18504 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18505 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18506 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18507 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18508 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18509 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18510 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18511 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18512 \t Loss:0.951 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18513 \t Loss:0.951 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18514 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18515 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18516 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18517 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18518 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18519 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18520 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18521 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18522 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18523 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18524 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18525 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18526 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18527 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18528 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18529 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18530 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18531 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18532 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18533 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18534 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18535 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18536 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18537 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18538 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18539 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18540 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18541 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18542 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18543 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18544 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18545 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18546 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18547 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18548 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18549 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18550 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18551 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18552 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18553 \t Loss:0.950 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18554 \t Loss:0.950 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18555 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18556 \t Loss:0.949 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18557 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18558 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18559 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18560 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18561 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18562 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18563 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18564 \t Loss:0.949 \t error(train):87.9% \t error(val):85.6%\n",
      "iter:18565 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18566 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18567 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18568 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18569 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18570 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18571 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18572 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18573 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18574 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18575 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18576 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18577 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18578 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18579 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18580 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18581 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18582 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18583 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18584 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18585 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18586 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18587 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18588 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18589 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18590 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18591 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18592 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18593 \t Loss:0.949 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18594 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18595 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18596 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18597 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18598 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18599 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18600 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18601 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18602 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18603 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18604 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18605 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18606 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18607 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18608 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18609 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18610 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18611 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18612 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18613 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18614 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18615 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18616 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18617 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18618 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18619 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18620 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18621 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18622 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18623 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18624 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18625 \t Loss:0.948 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18626 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18627 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18628 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18629 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18630 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18631 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18632 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18633 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18634 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18635 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18636 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18637 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18638 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18639 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18640 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18641 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18642 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18643 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18644 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18645 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18646 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18647 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18648 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18649 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18650 \t Loss:0.947 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18651 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18652 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18653 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18654 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18655 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18656 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18657 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18658 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18659 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18660 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18661 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18662 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18663 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18664 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18665 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18666 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18667 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18668 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18669 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18670 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18671 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18672 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18673 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18674 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18675 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18676 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18677 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18678 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18679 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18680 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18681 \t Loss:0.946 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18682 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18683 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18684 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18685 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18686 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18687 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18688 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18689 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18690 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18691 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18692 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18693 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18694 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18695 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18696 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18697 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18698 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18699 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18700 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18701 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18702 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18703 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18704 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18705 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18706 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18707 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18708 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18709 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18710 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18711 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18712 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18713 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18714 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18715 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18716 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18717 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18718 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18719 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18720 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18721 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18722 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18723 \t Loss:0.945 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18724 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18725 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18726 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18727 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18728 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18729 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18730 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18731 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18732 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18733 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18734 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18735 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18736 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18737 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18738 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18739 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18740 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18741 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18742 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18743 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18744 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18745 \t Loss:0.944 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18746 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18747 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18748 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18749 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18750 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18751 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18752 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18753 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18754 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18755 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18756 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18757 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18758 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18759 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18760 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18761 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18762 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18763 \t Loss:0.944 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18764 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18765 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18766 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18767 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18768 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18769 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18770 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18771 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18772 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18773 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18774 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18775 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18776 \t Loss:0.943 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18777 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18778 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18779 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18780 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18781 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18782 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18783 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18784 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18785 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18786 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18787 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18788 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18789 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18790 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18791 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18792 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18793 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18794 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18795 \t Loss:0.943 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18796 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18797 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18798 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18799 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18800 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18801 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18802 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18803 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18804 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18805 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18806 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18807 \t Loss:0.943 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18808 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18809 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18810 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18811 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18812 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18813 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18814 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18815 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18816 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18817 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18818 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18819 \t Loss:0.942 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18820 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18821 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18822 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18823 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18824 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18825 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18826 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18827 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18828 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18829 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18830 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18831 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18832 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18833 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18834 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18835 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18836 \t Loss:0.942 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18837 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18838 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18839 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18840 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18841 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18842 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18843 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18844 \t Loss:0.942 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18845 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18846 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18847 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18848 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18849 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18850 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18851 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18852 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18853 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18854 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18855 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18856 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18857 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18858 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18859 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18860 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18861 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18862 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18863 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18864 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18865 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18866 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18867 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18868 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18869 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18870 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18871 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18872 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18873 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18874 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18875 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18876 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18877 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18878 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18879 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18880 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18881 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18882 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18883 \t Loss:0.941 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18884 \t Loss:0.941 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18885 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18886 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18887 \t Loss:0.940 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18888 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18889 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18890 \t Loss:0.940 \t error(train):88.0% \t error(val):85.7%\n",
      "iter:18891 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18892 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18893 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18894 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18895 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18896 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18897 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18898 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18899 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18900 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18901 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18902 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18903 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18904 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18905 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18906 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18907 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18908 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18909 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18910 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18911 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18912 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18913 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18914 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18915 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18916 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18917 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18918 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18919 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18920 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18921 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18922 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18923 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18924 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18925 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18926 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18927 \t Loss:0.940 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18928 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18929 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18930 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18931 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18932 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18933 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18934 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18935 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18936 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18937 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18938 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18939 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18940 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18941 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18942 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18943 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18944 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18945 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18946 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18947 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18948 \t Loss:0.939 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:18949 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18950 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18951 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18952 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18953 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18954 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18955 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18956 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18957 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18958 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18959 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18960 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18961 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18962 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18963 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18964 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18965 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18966 \t Loss:0.939 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:18967 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18968 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18969 \t Loss:0.939 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18970 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18971 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18972 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18973 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18974 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18975 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18976 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18977 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18978 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18979 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18980 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18981 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18982 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18983 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18984 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18985 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18986 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18987 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18988 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18989 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18990 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18991 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18992 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18993 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18994 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18995 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18996 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18997 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18998 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:18999 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19000 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19001 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19002 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19003 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19004 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19005 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19006 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19007 \t Loss:0.938 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19008 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19009 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19010 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19011 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19012 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19013 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19014 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19015 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19016 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19017 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19018 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19019 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19020 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19021 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19022 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19023 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19024 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19025 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19026 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19027 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19028 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19029 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19030 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19031 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19032 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19033 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19034 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19035 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19036 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19037 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19038 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19039 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19040 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19041 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19042 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19043 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19044 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19045 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19046 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19047 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19048 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19049 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19050 \t Loss:0.937 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19051 \t Loss:0.937 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19052 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19053 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19054 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19055 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19056 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19057 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19058 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19059 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19060 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19061 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19062 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19063 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19064 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19065 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19066 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19067 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19068 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19069 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19070 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19071 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19072 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19073 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19074 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19075 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19076 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19077 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19078 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19079 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19080 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19081 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19082 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19083 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19084 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19085 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19086 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19087 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19088 \t Loss:0.936 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19089 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19090 \t Loss:0.936 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19091 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19092 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19093 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19094 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19095 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19096 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19097 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19098 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19099 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19100 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19101 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19102 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19103 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19104 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19105 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19106 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19107 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19108 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19109 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19110 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19111 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19112 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19113 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19114 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19115 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19116 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19117 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19118 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19119 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19120 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19121 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19122 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19123 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19124 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19125 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19126 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19127 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19128 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19129 \t Loss:0.935 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19130 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19131 \t Loss:0.935 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19132 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19133 \t Loss:0.934 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19134 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19135 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19136 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19137 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19138 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19139 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19140 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19141 \t Loss:0.934 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19142 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19143 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19144 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19145 \t Loss:0.934 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19146 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19147 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19148 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19149 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19150 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19151 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19152 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19153 \t Loss:0.934 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19154 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19155 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19156 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19157 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19158 \t Loss:0.934 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19159 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19160 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19161 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19162 \t Loss:0.934 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19163 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19164 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19165 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19166 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19167 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19168 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19169 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19170 \t Loss:0.934 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19171 \t Loss:0.933 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19172 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19173 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19174 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19175 \t Loss:0.933 \t error(train):88.0% \t error(val):85.6%\n",
      "iter:19176 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19177 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19178 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19179 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19180 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19181 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19182 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19183 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19184 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19185 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19186 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19187 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19188 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19189 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19190 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19191 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19192 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19193 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19194 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19195 \t Loss:0.933 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19196 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19197 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19198 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19199 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19200 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19201 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19202 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19203 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19204 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19205 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19206 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19207 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19208 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19209 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19210 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19211 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19212 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19213 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19214 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19215 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19216 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19217 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19218 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19219 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19220 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19221 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19222 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19223 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19224 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19225 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19226 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19227 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19228 \t Loss:0.932 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19229 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19230 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19231 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19232 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19233 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19234 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19235 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19236 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19237 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19238 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19239 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19240 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19241 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19242 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19243 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19244 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19245 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19246 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19247 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19248 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19249 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19250 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19251 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19252 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19253 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19254 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19255 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19256 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19257 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19258 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19259 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19260 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19261 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19262 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19263 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19264 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19265 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19266 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19267 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19268 \t Loss:0.931 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19269 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19270 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19271 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19272 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19273 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19274 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19275 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19276 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19277 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19278 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19279 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19280 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19281 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19282 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19283 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19284 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19285 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19286 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19287 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19288 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19289 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19290 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19291 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19292 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19293 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19294 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19295 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19296 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19297 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19298 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19299 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19300 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19301 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19302 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19303 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19304 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19305 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19306 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19307 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19308 \t Loss:0.930 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19309 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19310 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19311 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19312 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19313 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19314 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19315 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19316 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19317 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19318 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19319 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19320 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19321 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19322 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19323 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19324 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19325 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19326 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19327 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19328 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19329 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19330 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19331 \t Loss:0.929 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19332 \t Loss:0.929 \t error(train):88.1% \t error(val):85.7%\n",
      "iter:19333 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19334 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19335 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19336 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19337 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19338 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19339 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19340 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19341 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19342 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19343 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19344 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19345 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19346 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19347 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19348 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19349 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19350 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19351 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19352 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19353 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19354 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19355 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19356 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19357 \t Loss:0.928 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19358 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19359 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19360 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19361 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19362 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19363 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19364 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19365 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19366 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19367 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19368 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19369 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19370 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19371 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19372 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19373 \t Loss:0.928 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19374 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19375 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19376 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19377 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19378 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19379 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19380 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19381 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19382 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19383 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19384 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19385 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19386 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19387 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19388 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19389 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19390 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19391 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19392 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19393 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19394 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19395 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19396 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19397 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19398 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19399 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19400 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19401 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19402 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19403 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19404 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19405 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19406 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19407 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19408 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19409 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19410 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19411 \t Loss:0.927 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19412 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19413 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19414 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19415 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19416 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19417 \t Loss:0.927 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19418 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19419 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19420 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19421 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19422 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19423 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19424 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19425 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19426 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19427 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19428 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19429 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19430 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19431 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19432 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19433 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19434 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19435 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19436 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19437 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19438 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19439 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19440 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19441 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19442 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19443 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19444 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19445 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19446 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19447 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19448 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19449 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19450 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19451 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19452 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19453 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19454 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19455 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19456 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19457 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19458 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19459 \t Loss:0.926 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19460 \t Loss:0.926 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19461 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19462 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19463 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19464 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19465 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19466 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19467 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19468 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19469 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19470 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19471 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19472 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19473 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19474 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19475 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19476 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19477 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19478 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19479 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19480 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19481 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19482 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19483 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19484 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19485 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19486 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19487 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19488 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19489 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19490 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19491 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19492 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19493 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19494 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19495 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19496 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19497 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19498 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19499 \t Loss:0.925 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19500 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19501 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19502 \t Loss:0.925 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19503 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19504 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19505 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19506 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19507 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19508 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19509 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19510 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19511 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19512 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19513 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19514 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19515 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19516 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19517 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19518 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19519 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19520 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19521 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19522 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19523 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19524 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19525 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19526 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19527 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19528 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19529 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19530 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19531 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19532 \t Loss:0.924 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19533 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19534 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19535 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19536 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19537 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19538 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19539 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19540 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19541 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19542 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19543 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19544 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19545 \t Loss:0.924 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19546 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19547 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19548 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19549 \t Loss:0.923 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19550 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19551 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19552 \t Loss:0.923 \t error(train):88.1% \t error(val):85.6%\n",
      "iter:19553 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19554 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19555 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19556 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19557 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19558 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19559 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19560 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19561 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19562 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19563 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19564 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19565 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19566 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19567 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19568 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19569 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19570 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19571 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19572 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19573 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19574 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19575 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19576 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19577 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19578 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19579 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19580 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19581 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19582 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19583 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19584 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19585 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19586 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19587 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19588 \t Loss:0.923 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19589 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19590 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19591 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19592 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19593 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19594 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19595 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19596 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19597 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19598 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19599 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19600 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19601 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19602 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19603 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19604 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19605 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19606 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19607 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19608 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19609 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19610 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19611 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19612 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19613 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19614 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19615 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19616 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19617 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19618 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19619 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19620 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19621 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19622 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19623 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19624 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19625 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19626 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19627 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19628 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19629 \t Loss:0.922 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19630 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19631 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19632 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19633 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19634 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19635 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19636 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19637 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19638 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19639 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19640 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19641 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19642 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19643 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19644 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19645 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19646 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19647 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19648 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19649 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19650 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19651 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19652 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19653 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19654 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19655 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19656 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19657 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19658 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19659 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19660 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19661 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19662 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19663 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19664 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19665 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19666 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19667 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19668 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19669 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19670 \t Loss:0.921 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19671 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19672 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19673 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19674 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19675 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19676 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19677 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19678 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19679 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19680 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19681 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19682 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19683 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19684 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19685 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19686 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19687 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19688 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19689 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19690 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19691 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19692 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19693 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19694 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19695 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19696 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19697 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19698 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19699 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19700 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19701 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19702 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19703 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19704 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19705 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19706 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19707 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19708 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19709 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19710 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19711 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19712 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19713 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19714 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19715 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19716 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19717 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19718 \t Loss:0.920 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19719 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19720 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19721 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19722 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19723 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19724 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19725 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19726 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19727 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19728 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19729 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19730 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19731 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19732 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19733 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19734 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19735 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19736 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19737 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19738 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19739 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19740 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19741 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19742 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19743 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19744 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19745 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19746 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19747 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19748 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19749 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19750 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19751 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19752 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19753 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19754 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19755 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19756 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19757 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19758 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19759 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19760 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19761 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19762 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19763 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19764 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19765 \t Loss:0.919 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19766 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19767 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19768 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19769 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19770 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19771 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19772 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19773 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19774 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19775 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19776 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19777 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19778 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19779 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19780 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19781 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19782 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19783 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19784 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19785 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19786 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19787 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19788 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19789 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19790 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19791 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19792 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19793 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19794 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19795 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19796 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19797 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19798 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19799 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19800 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19801 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19802 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19803 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19804 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19805 \t Loss:0.918 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19806 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19807 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19808 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19809 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19810 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19811 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19812 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19813 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19814 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19815 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19816 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19817 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19818 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19819 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19820 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19821 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19822 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19823 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19824 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19825 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19826 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19827 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19828 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19829 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19830 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19831 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19832 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19833 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19834 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19835 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19836 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19837 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19838 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19839 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19840 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19841 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19842 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19843 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19844 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19845 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19846 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19847 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19848 \t Loss:0.917 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19849 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19850 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19851 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19852 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19853 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19854 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19855 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19856 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19857 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19858 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19859 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19860 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19861 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19862 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19863 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19864 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19865 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19866 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19867 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19868 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19869 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19870 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19871 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19872 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19873 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19874 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19875 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19876 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19877 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19878 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19879 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19880 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19881 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19882 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19883 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19884 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19885 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19886 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19887 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19888 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19889 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19890 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19891 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19892 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19893 \t Loss:0.916 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19894 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19895 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19896 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19897 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19898 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19899 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19900 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19901 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19902 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19903 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19904 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19905 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19906 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19907 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19908 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19909 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19910 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19911 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19912 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19913 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19914 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19915 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19916 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19917 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19918 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19919 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19920 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19921 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19922 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19923 \t Loss:0.915 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19924 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19925 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19926 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19927 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19928 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19929 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19930 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19931 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19932 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19933 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19934 \t Loss:0.915 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19935 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19936 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19937 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19938 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19939 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19940 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19941 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19942 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19943 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19944 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19945 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19946 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19947 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19948 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19949 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19950 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19951 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19952 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19953 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19954 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19955 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19956 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19957 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19958 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19959 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19960 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19961 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19962 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19963 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19964 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19965 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19966 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19967 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19968 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19969 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19970 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19971 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19972 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19973 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19974 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19975 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19976 \t Loss:0.914 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19977 \t Loss:0.914 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19978 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19979 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19980 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19981 \t Loss:0.913 \t error(train):88.2% \t error(val):85.7%\n",
      "iter:19982 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19983 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19984 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19985 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19986 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19987 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19988 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19989 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19990 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19991 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19992 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19993 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19994 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19995 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19996 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19997 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n",
      "iter:19998 \t Loss:0.913 \t error(train):88.2% \t error(val):85.6%\n",
      "iter:19999 \t Loss:0.913 \t error(train):88.3% \t error(val):85.6%\n"
     ]
    }
   ],
   "source": [
    "n_iter = 20000\n",
    "learning_rate = 1\n",
    "alpha = 0.5\n",
    "history = []\n",
    "history_learning_rate = []\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "beta=np.copy(beta_init_bw)\n",
    "\n",
    "start_time=time.time()\n",
    "for k in range(n_iter):\n",
    "    v,g = loss_value_and_grad(beta, X_train_bw, Y_train)\n",
    "    gradient = g\n",
    "    desc = -gradient # descent direction\n",
    "    \n",
    "    # automatically choose the learning rate\n",
    "    learning_rate = 3*learning_rate # make the learning rate a bit bigger\n",
    "    while loss_value_and_grad(beta+learning_rate*desc, X_train_bw, Y_train)[0]> loss_value_and_grad(beta, X_train_bw, Y_train)[0] + alpha*learning_rate*np.dot(desc, gradient):\n",
    "        # while condition not satisfied, divide the learning rate by two\n",
    "        learning_rate = 0.5 * learning_rate\n",
    "    \n",
    "    beta = beta + learning_rate * desc\n",
    "    history.append(v)\n",
    "    history_learning_rate.append(learning_rate)\n",
    "    if k % 1 == 0:\n",
    "        err_train = 100*compute_error_rate(beta, X_train_bw, Y_train)\n",
    "        train_acc.append(err_train)\n",
    "        err_val= 100*compute_error_rate(beta, X_test_bw, Y_test)   \n",
    "        test_acc.append(err_val)\n",
    "        print(f\"iter:{k} \\t Loss:{v:2.3f} \\t error(train):{err_train:2.1f}% \\t error(val):{err_val:2.1f}%\")\n",
    "        # typo!!\n",
    "        # error(train) should be accuracy(train)\n",
    "        # error(val) should be accuracy(val)\n",
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(88.25333333, dtype=float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_train_bw, Y_train) #train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(85.6, dtype=float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_test_bw, Y_test) #test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8983.98002409935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history, \"-^\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = prediction_batch(beta,X_test_bw)\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(Y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black and White Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t Loss:23.880 \t error(train):51.4% \t error(val):50.3%\n",
      "epoch:100 \t Loss:4.168 \t error(train):72.6% \t error(val):73.2%\n",
      "epoch:200 \t Loss:2.913 \t error(train):77.6% \t error(val):77.8%\n",
      "epoch:300 \t Loss:2.351 \t error(train):80.2% \t error(val):80.0%\n",
      "epoch:400 \t Loss:2.027 \t error(train):82.1% \t error(val):81.6%\n",
      "epoch:500 \t Loss:1.808 \t error(train):83.3% \t error(val):82.6%\n",
      "epoch:600 \t Loss:1.646 \t error(train):84.0% \t error(val):83.5%\n",
      "epoch:700 \t Loss:1.521 \t error(train):84.7% \t error(val):83.9%\n",
      "epoch:800 \t Loss:1.419 \t error(train):85.5% \t error(val):84.2%\n",
      "epoch:900 \t Loss:1.333 \t error(train):85.6% \t error(val):84.3%\n",
      "epoch:1000 \t Loss:1.260 \t error(train):86.1% \t error(val):84.6%\n",
      "epoch:1100 \t Loss:1.199 \t error(train):86.5% \t error(val):84.7%\n",
      "epoch:1200 \t Loss:1.143 \t error(train):86.7% \t error(val):84.8%\n",
      "epoch:1300 \t Loss:1.093 \t error(train):87.0% \t error(val):85.2%\n",
      "epoch:1400 \t Loss:1.048 \t error(train):87.4% \t error(val):85.3%\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1500\n",
    "minibatch_size = 5 #size of the minibatchs\n",
    "N = len(X_train_bw)  #15000, total number of images\n",
    "img_indices = np.arange(N)\n",
    "\n",
    "loss_history = []\n",
    "loss_history_end_epoch = []\n",
    "beta = np.copy(beta_init_bw)\n",
    "learning_rate = 0.000000005\n",
    "\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epoch):\n",
    "    # go through all the minibatches, sequetially\n",
    "    n_minibatch = N // minibatch_size + 1 # ensure that we're in the range [0,1]\n",
    "    # randomize the batches\n",
    "    np.random.shuffle(img_indices)\n",
    "    \n",
    "    all_loss_within_epoch = []\n",
    "    for k in range(n_minibatch):\n",
    "        # create the minibatch of examples\n",
    "        batch_indices = np.arange(k*minibatch_size, (k+1)*minibatch_size) % N\n",
    "        batch_indices = img_indices[batch_indices]\n",
    "        X_minibatch = X_train_bw[batch_indices]\n",
    "        Y_minibatch = Y_train[batch_indices]\n",
    "\n",
    "        # compute the stochastic gradient\n",
    "        val, grad = loss_value_and_grad(beta, X_minibatch, Y_minibatch)\n",
    "\n",
    "        # do one step of SGD\n",
    "        beta = beta - learning_rate*grad\n",
    "\n",
    "        # book-keeping\n",
    "        loss_history.append(val)\n",
    "        all_loss_within_epoch.append(val)\n",
    "    loss_history_end_epoch.append(np.mean(all_loss_within_epoch))\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        err_train = 100*compute_error_rate(beta, X_train_bw, Y_train)\n",
    "        train_acc.append(err_train)\n",
    "        err_val= 100*compute_error_rate(beta, X_test_bw, Y_test)\n",
    "        test_acc.append(err_val)\n",
    "        print(f\"epoch:{epoch} \\t Loss:{np.mean(all_loss_within_epoch):2.3f} \\t error(train):{err_train:2.1f}% \\t error(val):{err_val:2.1f}%\")\n",
    "        # typo!!\n",
    "        # error(train) should be accuracy(train)\n",
    "        # error(val) should be accuracy(val)\n",
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(87.58666667, dtype=float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_train_bw, Y_train) #train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(85.36, dtype=float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_test_bw, Y_test) #test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204.2509820461273"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_end_epoch, \"-^\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = prediction_batch(beta,X_test_bw)\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(Y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Task 1 : Impact of Different Train Sizes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black and White Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t error(val):41.4%\n",
      "epoch:100 \t error(val):57.3%\n",
      "epoch:200 \t error(val):62.3%\n",
      "epoch:300 \t error(val):64.7%\n",
      "epoch:400 \t error(val):65.7%\n",
      "epoch:500 \t error(val):65.9%\n",
      "epoch:600 \t error(val):66.8%\n",
      "epoch:700 \t error(val):67.1%\n",
      "epoch:800 \t error(val):67.4%\n",
      "epoch:900 \t error(val):67.3%\n",
      "epoch:1000 \t error(val):68.2%\n",
      "epoch:1100 \t error(val):68.2%\n",
      "epoch:1200 \t error(val):68.3%\n",
      "epoch:1300 \t error(val):68.3%\n",
      "epoch:1400 \t error(val):68.8%\n",
      "epoch:0 \t error(val):43.8%\n",
      "epoch:100 \t error(val):62.4%\n",
      "epoch:200 \t error(val):66.0%\n",
      "epoch:300 \t error(val):68.0%\n",
      "epoch:400 \t error(val):69.0%\n",
      "epoch:500 \t error(val):70.3%\n",
      "epoch:600 \t error(val):71.5%\n",
      "epoch:700 \t error(val):72.3%\n",
      "epoch:800 \t error(val):73.0%\n",
      "epoch:900 \t error(val):73.8%\n",
      "epoch:1000 \t error(val):74.1%\n",
      "epoch:1100 \t error(val):74.5%\n",
      "epoch:1200 \t error(val):74.7%\n",
      "epoch:1300 \t error(val):75.2%\n",
      "epoch:1400 \t error(val):75.5%\n",
      "epoch:0 \t error(val):46.8%\n",
      "epoch:100 \t error(val):65.6%\n",
      "epoch:200 \t error(val):68.9%\n",
      "epoch:300 \t error(val):69.8%\n",
      "epoch:400 \t error(val):71.3%\n",
      "epoch:500 \t error(val):72.6%\n",
      "epoch:600 \t error(val):73.5%\n",
      "epoch:700 \t error(val):73.9%\n",
      "epoch:800 \t error(val):74.4%\n",
      "epoch:900 \t error(val):75.3%\n",
      "epoch:1000 \t error(val):76.0%\n",
      "epoch:1100 \t error(val):76.1%\n",
      "epoch:1200 \t error(val):76.7%\n",
      "epoch:1300 \t error(val):76.9%\n",
      "epoch:1400 \t error(val):77.3%\n",
      "epoch:0 \t error(val):47.9%\n",
      "epoch:100 \t error(val):67.0%\n",
      "epoch:200 \t error(val):70.1%\n",
      "epoch:300 \t error(val):71.9%\n",
      "epoch:400 \t error(val):73.6%\n",
      "epoch:500 \t error(val):75.2%\n",
      "epoch:600 \t error(val):76.4%\n",
      "epoch:700 \t error(val):77.0%\n",
      "epoch:800 \t error(val):77.8%\n",
      "epoch:900 \t error(val):78.4%\n",
      "epoch:1000 \t error(val):78.8%\n",
      "epoch:1100 \t error(val):79.1%\n",
      "epoch:1200 \t error(val):79.4%\n",
      "epoch:1300 \t error(val):79.9%\n",
      "epoch:1400 \t error(val):80.2%\n",
      "epoch:0 \t error(val):48.7%\n",
      "epoch:100 \t error(val):67.5%\n",
      "epoch:200 \t error(val):70.6%\n",
      "epoch:300 \t error(val):72.9%\n",
      "epoch:400 \t error(val):74.7%\n",
      "epoch:500 \t error(val):76.1%\n",
      "epoch:600 \t error(val):77.2%\n",
      "epoch:700 \t error(val):77.9%\n",
      "epoch:800 \t error(val):78.3%\n",
      "epoch:900 \t error(val):78.8%\n",
      "epoch:1000 \t error(val):79.5%\n",
      "epoch:1100 \t error(val):79.5%\n",
      "epoch:1200 \t error(val):80.1%\n",
      "epoch:1300 \t error(val):80.2%\n",
      "epoch:1400 \t error(val):80.5%\n",
      "epoch:0 \t error(val):49.0%\n",
      "epoch:100 \t error(val):68.6%\n",
      "epoch:200 \t error(val):72.7%\n",
      "epoch:300 \t error(val):74.8%\n",
      "epoch:400 \t error(val):76.0%\n",
      "epoch:500 \t error(val):77.2%\n",
      "epoch:600 \t error(val):77.9%\n",
      "epoch:700 \t error(val):78.5%\n",
      "epoch:800 \t error(val):79.5%\n",
      "epoch:900 \t error(val):80.1%\n",
      "epoch:1000 \t error(val):80.7%\n",
      "epoch:1100 \t error(val):81.0%\n",
      "epoch:1200 \t error(val):81.5%\n",
      "epoch:1300 \t error(val):81.9%\n",
      "epoch:1400 \t error(val):82.0%\n",
      "epoch:0 \t error(val):48.6%\n",
      "epoch:100 \t error(val):69.0%\n",
      "epoch:200 \t error(val):72.4%\n",
      "epoch:300 \t error(val):75.1%\n",
      "epoch:400 \t error(val):76.4%\n",
      "epoch:500 \t error(val):78.0%\n",
      "epoch:600 \t error(val):79.3%\n",
      "epoch:700 \t error(val):79.9%\n",
      "epoch:800 \t error(val):80.5%\n",
      "epoch:900 \t error(val):81.0%\n",
      "epoch:1000 \t error(val):81.4%\n",
      "epoch:1100 \t error(val):81.8%\n",
      "epoch:1200 \t error(val):82.0%\n",
      "epoch:1300 \t error(val):82.4%\n",
      "epoch:1400 \t error(val):82.5%\n",
      "epoch:0 \t error(val):50.2%\n",
      "epoch:100 \t error(val):70.0%\n",
      "epoch:200 \t error(val):73.5%\n",
      "epoch:300 \t error(val):75.9%\n",
      "epoch:400 \t error(val):77.8%\n",
      "epoch:500 \t error(val):79.4%\n",
      "epoch:600 \t error(val):80.2%\n",
      "epoch:700 \t error(val):80.9%\n",
      "epoch:800 \t error(val):81.5%\n",
      "epoch:900 \t error(val):82.3%\n",
      "epoch:1000 \t error(val):82.6%\n",
      "epoch:1100 \t error(val):83.1%\n",
      "epoch:1200 \t error(val):83.2%\n",
      "epoch:1300 \t error(val):83.7%\n",
      "epoch:1400 \t error(val):83.9%\n",
      "epoch:0 \t error(val):49.5%\n",
      "epoch:100 \t error(val):70.2%\n",
      "epoch:200 \t error(val):74.4%\n",
      "epoch:300 \t error(val):76.9%\n",
      "epoch:400 \t error(val):78.4%\n",
      "epoch:500 \t error(val):79.8%\n",
      "epoch:600 \t error(val):81.0%\n",
      "epoch:700 \t error(val):81.7%\n",
      "epoch:800 \t error(val):82.3%\n",
      "epoch:900 \t error(val):82.5%\n",
      "epoch:1000 \t error(val):82.8%\n",
      "epoch:1100 \t error(val):83.1%\n",
      "epoch:1200 \t error(val):83.2%\n",
      "epoch:1300 \t error(val):83.3%\n",
      "epoch:1400 \t error(val):83.4%\n",
      "epoch:0 \t error(val):49.8%\n",
      "epoch:100 \t error(val):71.3%\n",
      "epoch:200 \t error(val):74.8%\n",
      "epoch:300 \t error(val):77.2%\n",
      "epoch:400 \t error(val):78.9%\n",
      "epoch:500 \t error(val):79.9%\n",
      "epoch:600 \t error(val):81.0%\n",
      "epoch:700 \t error(val):81.4%\n",
      "epoch:800 \t error(val):82.4%\n",
      "epoch:900 \t error(val):82.9%\n",
      "epoch:1000 \t error(val):83.3%\n",
      "epoch:1100 \t error(val):83.7%\n",
      "epoch:1200 \t error(val):83.8%\n",
      "epoch:1300 \t error(val):84.0%\n",
      "epoch:1400 \t error(val):84.0%\n",
      "epoch:0 \t error(val):48.8%\n",
      "epoch:100 \t error(val):71.3%\n",
      "epoch:200 \t error(val):75.8%\n",
      "epoch:300 \t error(val):78.2%\n",
      "epoch:400 \t error(val):79.6%\n",
      "epoch:500 \t error(val):81.0%\n",
      "epoch:600 \t error(val):81.7%\n",
      "epoch:700 \t error(val):82.2%\n",
      "epoch:800 \t error(val):82.6%\n",
      "epoch:900 \t error(val):83.3%\n",
      "epoch:1000 \t error(val):83.5%\n",
      "epoch:1100 \t error(val):83.6%\n",
      "epoch:1200 \t error(val):83.9%\n",
      "epoch:1300 \t error(val):83.8%\n",
      "epoch:1400 \t error(val):83.8%\n",
      "epoch:0 \t error(val):48.3%\n",
      "epoch:100 \t error(val):71.9%\n",
      "epoch:200 \t error(val):76.5%\n",
      "epoch:300 \t error(val):78.7%\n",
      "epoch:400 \t error(val):80.3%\n",
      "epoch:500 \t error(val):81.5%\n",
      "epoch:600 \t error(val):82.2%\n",
      "epoch:700 \t error(val):82.9%\n",
      "epoch:800 \t error(val):83.1%\n",
      "epoch:900 \t error(val):83.6%\n",
      "epoch:1000 \t error(val):83.7%\n",
      "epoch:1100 \t error(val):84.1%\n",
      "epoch:1200 \t error(val):84.2%\n",
      "epoch:1300 \t error(val):84.4%\n",
      "epoch:1400 \t error(val):84.6%\n",
      "epoch:0 \t error(val):49.1%\n",
      "epoch:100 \t error(val):72.8%\n",
      "epoch:200 \t error(val):77.0%\n",
      "epoch:300 \t error(val):78.9%\n",
      "epoch:400 \t error(val):80.2%\n",
      "epoch:500 \t error(val):81.5%\n",
      "epoch:600 \t error(val):82.6%\n",
      "epoch:700 \t error(val):83.2%\n",
      "epoch:800 \t error(val):83.7%\n",
      "epoch:900 \t error(val):83.5%\n",
      "epoch:1000 \t error(val):84.3%\n",
      "epoch:1100 \t error(val):84.4%\n",
      "epoch:1200 \t error(val):84.7%\n",
      "epoch:1300 \t error(val):84.8%\n",
      "epoch:1400 \t error(val):84.9%\n",
      "epoch:0 \t error(val):50.1%\n",
      "epoch:100 \t error(val):73.2%\n",
      "epoch:200 \t error(val):77.3%\n",
      "epoch:300 \t error(val):79.5%\n",
      "epoch:400 \t error(val):81.3%\n",
      "epoch:500 \t error(val):82.2%\n",
      "epoch:600 \t error(val):82.9%\n",
      "epoch:700 \t error(val):83.4%\n",
      "epoch:800 \t error(val):84.1%\n",
      "epoch:900 \t error(val):84.3%\n",
      "epoch:1000 \t error(val):84.4%\n",
      "epoch:1100 \t error(val):84.6%\n",
      "epoch:1200 \t error(val):84.7%\n",
      "epoch:1300 \t error(val):84.8%\n",
      "epoch:1400 \t error(val):84.7%\n",
      "epoch:0 \t error(val):48.2%\n",
      "epoch:100 \t error(val):73.3%\n",
      "epoch:200 \t error(val):77.5%\n",
      "epoch:300 \t error(val):80.0%\n",
      "epoch:400 \t error(val):81.7%\n",
      "epoch:500 \t error(val):82.7%\n",
      "epoch:600 \t error(val):83.5%\n",
      "epoch:700 \t error(val):83.9%\n",
      "epoch:800 \t error(val):84.2%\n",
      "epoch:900 \t error(val):84.4%\n",
      "epoch:1000 \t error(val):84.5%\n",
      "epoch:1100 \t error(val):84.8%\n",
      "epoch:1200 \t error(val):84.8%\n",
      "epoch:1300 \t error(val):85.1%\n",
      "epoch:1400 \t error(val):85.4%\n"
     ]
    }
   ],
   "source": [
    "test_error={}\n",
    "# typo!!\n",
    "# this dictionary stores the test accuracy\n",
    "\n",
    "for i in range(1000,15001,1000):\n",
    "    n_epoch = 1500\n",
    "    minibatch_size = 5 \n",
    "    N = i \n",
    "    img_indices = np.arange(N)\n",
    "    beta = np.copy(beta_init_bw)\n",
    "    learning_rate = 0.000000005\n",
    "    indices=random.sample(range(0,15000),i)\n",
    "    train_set=X_train_bw[indices]\n",
    "    train_res=Y_train[indices]\n",
    "    for epoch in range(n_epoch):\n",
    "        n_minibatch = N // minibatch_size + 1\n",
    "        np.random.shuffle(img_indices)\n",
    "        for k in range(n_minibatch):\n",
    "            batch_indices = np.arange(k*minibatch_size, (k+1)*minibatch_size) % N\n",
    "            batch_indices = img_indices[batch_indices]\n",
    "            X_minibatch = train_set[batch_indices]\n",
    "            Y_minibatch = train_res[batch_indices]\n",
    "\n",
    "            val, grad = loss_value_and_grad(beta, X_minibatch, Y_minibatch)\n",
    "\n",
    "            beta = beta - learning_rate*grad\n",
    "    \n",
    "        if epoch % 100 == 0:\n",
    "            err_val= 100*compute_error_rate(beta, X_test_bw, Y_test)\n",
    "            if i in test_error:\n",
    "                test_error[i].append(err_val)\n",
    "            else:\n",
    "                test_error[i]=[err_val]\n",
    "            print(f\"epoch:{epoch} \\t error(val):{err_val:2.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = [0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400] \n",
    "df = pd.DataFrame(test_error) #test accuracy\n",
    "df.index = values\n",
    "plt.plot(df, label=df.columns)\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t error(val):52.1%\n",
      "epoch:100 \t error(val):69.3%\n",
      "epoch:200 \t error(val):71.8%\n",
      "epoch:300 \t error(val):73.6%\n",
      "epoch:400 \t error(val):74.5%\n",
      "epoch:500 \t error(val):75.2%\n",
      "epoch:600 \t error(val):75.4%\n",
      "epoch:700 \t error(val):75.9%\n",
      "epoch:800 \t error(val):76.5%\n",
      "epoch:900 \t error(val):76.7%\n",
      "epoch:1000 \t error(val):77.3%\n",
      "epoch:1100 \t error(val):77.2%\n",
      "epoch:1200 \t error(val):77.6%\n",
      "epoch:1300 \t error(val):77.8%\n",
      "epoch:1400 \t error(val):77.8%\n",
      "epoch:0 \t error(val):54.6%\n",
      "epoch:100 \t error(val):72.4%\n",
      "epoch:200 \t error(val):75.1%\n",
      "epoch:300 \t error(val):76.9%\n",
      "epoch:400 \t error(val):77.9%\n",
      "epoch:500 \t error(val):78.7%\n",
      "epoch:600 \t error(val):79.3%\n",
      "epoch:700 \t error(val):79.9%\n",
      "epoch:800 \t error(val):80.1%\n",
      "epoch:900 \t error(val):80.4%\n",
      "epoch:1000 \t error(val):80.3%\n",
      "epoch:1100 \t error(val):80.7%\n",
      "epoch:1200 \t error(val):80.7%\n",
      "epoch:1300 \t error(val):81.0%\n",
      "epoch:1400 \t error(val):81.1%\n",
      "epoch:0 \t error(val):54.8%\n",
      "epoch:100 \t error(val):73.9%\n",
      "epoch:200 \t error(val):76.8%\n",
      "epoch:300 \t error(val):78.9%\n",
      "epoch:400 \t error(val):79.8%\n",
      "epoch:500 \t error(val):80.2%\n",
      "epoch:600 \t error(val):80.8%\n",
      "epoch:700 \t error(val):81.1%\n",
      "epoch:800 \t error(val):81.4%\n",
      "epoch:900 \t error(val):81.4%\n",
      "epoch:1000 \t error(val):81.8%\n",
      "epoch:1100 \t error(val):82.2%\n",
      "epoch:1200 \t error(val):82.3%\n",
      "epoch:1300 \t error(val):82.4%\n",
      "epoch:1400 \t error(val):82.6%\n",
      "epoch:0 \t error(val):55.4%\n",
      "epoch:100 \t error(val):75.0%\n",
      "epoch:200 \t error(val):78.5%\n",
      "epoch:300 \t error(val):80.5%\n",
      "epoch:400 \t error(val):81.2%\n",
      "epoch:500 \t error(val):82.0%\n",
      "epoch:600 \t error(val):82.9%\n",
      "epoch:700 \t error(val):83.2%\n",
      "epoch:800 \t error(val):83.4%\n",
      "epoch:900 \t error(val):83.8%\n",
      "epoch:1000 \t error(val):83.9%\n",
      "epoch:1100 \t error(val):84.1%\n",
      "epoch:1200 \t error(val):84.5%\n",
      "epoch:1300 \t error(val):84.4%\n",
      "epoch:1400 \t error(val):84.4%\n",
      "epoch:0 \t error(val):55.6%\n",
      "epoch:100 \t error(val):76.9%\n",
      "epoch:200 \t error(val):80.1%\n",
      "epoch:300 \t error(val):81.9%\n",
      "epoch:400 \t error(val):83.0%\n",
      "epoch:500 \t error(val):83.5%\n",
      "epoch:600 \t error(val):84.3%\n",
      "epoch:700 \t error(val):84.5%\n",
      "epoch:800 \t error(val):84.6%\n",
      "epoch:900 \t error(val):84.8%\n",
      "epoch:1000 \t error(val):85.1%\n",
      "epoch:1100 \t error(val):85.2%\n",
      "epoch:1200 \t error(val):85.4%\n",
      "epoch:1300 \t error(val):85.4%\n",
      "epoch:1400 \t error(val):85.4%\n",
      "epoch:0 \t error(val):55.4%\n",
      "epoch:100 \t error(val):77.9%\n",
      "epoch:200 \t error(val):80.6%\n",
      "epoch:300 \t error(val):82.3%\n",
      "epoch:400 \t error(val):83.2%\n",
      "epoch:500 \t error(val):83.9%\n",
      "epoch:600 \t error(val):84.5%\n",
      "epoch:700 \t error(val):84.8%\n",
      "epoch:800 \t error(val):85.0%\n",
      "epoch:900 \t error(val):85.3%\n",
      "epoch:1000 \t error(val):85.9%\n",
      "epoch:1100 \t error(val):85.7%\n",
      "epoch:1200 \t error(val):86.2%\n",
      "epoch:1300 \t error(val):86.4%\n",
      "epoch:1400 \t error(val):86.2%\n",
      "epoch:0 \t error(val):56.9%\n",
      "epoch:100 \t error(val):77.8%\n",
      "epoch:200 \t error(val):81.7%\n",
      "epoch:300 \t error(val):82.9%\n",
      "epoch:400 \t error(val):83.9%\n",
      "epoch:500 \t error(val):84.4%\n",
      "epoch:600 \t error(val):85.4%\n",
      "epoch:700 \t error(val):85.5%\n",
      "epoch:800 \t error(val):85.9%\n",
      "epoch:900 \t error(val):86.1%\n",
      "epoch:1000 \t error(val):86.3%\n",
      "epoch:1100 \t error(val):86.4%\n",
      "epoch:1200 \t error(val):86.5%\n",
      "epoch:1300 \t error(val):86.6%\n",
      "epoch:1400 \t error(val):86.7%\n",
      "epoch:0 \t error(val):57.2%\n",
      "epoch:100 \t error(val):78.8%\n",
      "epoch:200 \t error(val):82.1%\n",
      "epoch:300 \t error(val):83.5%\n",
      "epoch:400 \t error(val):84.2%\n",
      "epoch:500 \t error(val):85.1%\n",
      "epoch:600 \t error(val):85.6%\n",
      "epoch:700 \t error(val):86.0%\n",
      "epoch:800 \t error(val):86.2%\n",
      "epoch:900 \t error(val):86.3%\n",
      "epoch:1000 \t error(val):86.5%\n",
      "epoch:1100 \t error(val):86.7%\n",
      "epoch:1200 \t error(val):86.8%\n",
      "epoch:1300 \t error(val):87.1%\n",
      "epoch:1400 \t error(val):87.1%\n",
      "epoch:0 \t error(val):58.0%\n",
      "epoch:100 \t error(val):79.8%\n",
      "epoch:200 \t error(val):82.6%\n",
      "epoch:300 \t error(val):84.3%\n",
      "epoch:400 \t error(val):85.3%\n",
      "epoch:500 \t error(val):85.8%\n",
      "epoch:600 \t error(val):86.2%\n",
      "epoch:700 \t error(val):86.5%\n",
      "epoch:800 \t error(val):86.7%\n",
      "epoch:900 \t error(val):86.9%\n",
      "epoch:1000 \t error(val):87.1%\n",
      "epoch:1100 \t error(val):87.2%\n",
      "epoch:1200 \t error(val):87.3%\n",
      "epoch:1300 \t error(val):87.3%\n",
      "epoch:1400 \t error(val):87.5%\n",
      "epoch:0 \t error(val):58.3%\n",
      "epoch:100 \t error(val):80.6%\n",
      "epoch:200 \t error(val):83.4%\n",
      "epoch:300 \t error(val):84.4%\n",
      "epoch:400 \t error(val):85.4%\n",
      "epoch:500 \t error(val):86.0%\n",
      "epoch:600 \t error(val):86.7%\n",
      "epoch:700 \t error(val):86.7%\n",
      "epoch:800 \t error(val):87.0%\n",
      "epoch:900 \t error(val):87.3%\n",
      "epoch:1000 \t error(val):87.6%\n",
      "epoch:1100 \t error(val):87.7%\n",
      "epoch:1200 \t error(val):87.9%\n",
      "epoch:1300 \t error(val):87.8%\n",
      "epoch:1400 \t error(val):88.1%\n",
      "epoch:0 \t error(val):59.6%\n",
      "epoch:100 \t error(val):80.7%\n",
      "epoch:200 \t error(val):83.8%\n",
      "epoch:300 \t error(val):85.0%\n",
      "epoch:400 \t error(val):85.9%\n",
      "epoch:500 \t error(val):86.8%\n",
      "epoch:600 \t error(val):87.1%\n",
      "epoch:700 \t error(val):87.3%\n",
      "epoch:800 \t error(val):87.5%\n",
      "epoch:900 \t error(val):87.2%\n",
      "epoch:1000 \t error(val):87.8%\n",
      "epoch:1100 \t error(val):87.8%\n",
      "epoch:1200 \t error(val):87.9%\n",
      "epoch:1300 \t error(val):87.8%\n",
      "epoch:1400 \t error(val):87.8%\n",
      "epoch:0 \t error(val):60.0%\n",
      "epoch:100 \t error(val):81.3%\n",
      "epoch:200 \t error(val):84.2%\n",
      "epoch:300 \t error(val):85.7%\n",
      "epoch:400 \t error(val):86.6%\n",
      "epoch:500 \t error(val):86.9%\n",
      "epoch:600 \t error(val):87.5%\n",
      "epoch:700 \t error(val):87.8%\n",
      "epoch:800 \t error(val):87.9%\n",
      "epoch:900 \t error(val):88.1%\n",
      "epoch:1000 \t error(val):88.1%\n",
      "epoch:1100 \t error(val):88.2%\n",
      "epoch:1200 \t error(val):88.2%\n",
      "epoch:1300 \t error(val):88.1%\n",
      "epoch:1400 \t error(val):88.3%\n",
      "epoch:0 \t error(val):60.4%\n",
      "epoch:100 \t error(val):81.9%\n",
      "epoch:200 \t error(val):84.7%\n",
      "epoch:300 \t error(val):85.7%\n",
      "epoch:400 \t error(val):86.9%\n",
      "epoch:500 \t error(val):87.4%\n",
      "epoch:600 \t error(val):88.0%\n",
      "epoch:700 \t error(val):88.4%\n",
      "epoch:800 \t error(val):88.4%\n",
      "epoch:900 \t error(val):88.5%\n",
      "epoch:1000 \t error(val):88.7%\n",
      "epoch:1100 \t error(val):89.1%\n",
      "epoch:1200 \t error(val):89.0%\n",
      "epoch:1300 \t error(val):89.1%\n",
      "epoch:1400 \t error(val):89.1%\n",
      "epoch:0 \t error(val):61.1%\n",
      "epoch:100 \t error(val):82.2%\n",
      "epoch:200 \t error(val):84.8%\n",
      "epoch:300 \t error(val):85.9%\n",
      "epoch:400 \t error(val):87.2%\n",
      "epoch:500 \t error(val):87.6%\n",
      "epoch:600 \t error(val):88.2%\n",
      "epoch:700 \t error(val):88.4%\n",
      "epoch:800 \t error(val):88.3%\n",
      "epoch:900 \t error(val):88.6%\n",
      "epoch:1000 \t error(val):88.8%\n",
      "epoch:1100 \t error(val):88.8%\n",
      "epoch:1200 \t error(val):88.9%\n",
      "epoch:1300 \t error(val):88.5%\n",
      "epoch:1400 \t error(val):88.7%\n",
      "epoch:0 \t error(val):61.9%\n",
      "epoch:100 \t error(val):82.1%\n",
      "epoch:200 \t error(val):85.3%\n",
      "epoch:300 \t error(val):86.3%\n",
      "epoch:400 \t error(val):87.2%\n",
      "epoch:500 \t error(val):87.9%\n",
      "epoch:600 \t error(val):88.2%\n",
      "epoch:700 \t error(val):88.2%\n",
      "epoch:800 \t error(val):88.3%\n",
      "epoch:900 \t error(val):88.4%\n",
      "epoch:1000 \t error(val):88.8%\n",
      "epoch:1100 \t error(val):88.5%\n",
      "epoch:1200 \t error(val):89.0%\n",
      "epoch:1300 \t error(val):88.9%\n",
      "epoch:1400 \t error(val):88.8%\n"
     ]
    }
   ],
   "source": [
    "test_error={}\n",
    "# typo!!\n",
    "# this dictionary stores the test accuracy\n",
    "for i in range(1000,15001,1000):\n",
    "    n_epoch = 1500\n",
    "    minibatch_size = 5 \n",
    "    N = i  \n",
    "    img_indices = np.arange(N)\n",
    "    beta = np.copy(beta_init_rgb)\n",
    "    learning_rate = 0.000000005\n",
    "    indices=random.sample(range(0,15000),i)\n",
    "    train_set=X_train_rgb[indices]\n",
    "    train_res=Y_train[indices]\n",
    "    for epoch in range(n_epoch):\n",
    "        n_minibatch = N // minibatch_size + 1 \n",
    "        np.random.shuffle(img_indices)\n",
    "    \n",
    "        for k in range(n_minibatch):\n",
    "            batch_indices = np.arange(k*minibatch_size, (k+1)*minibatch_size) % N\n",
    "            batch_indices = img_indices[batch_indices]\n",
    "            X_minibatch = train_set[batch_indices]\n",
    "            Y_minibatch = train_res[batch_indices]\n",
    "\n",
    "            val, grad = loss_value_and_grad(beta, X_minibatch, Y_minibatch)\n",
    "\n",
    "            beta = beta - learning_rate*grad\n",
    "    \n",
    "        if epoch % 100 == 0:\n",
    "            err_val= 100*compute_error_rate(beta, X_test_rgb, Y_test)\n",
    "            \n",
    "            if i in test_error:\n",
    "                test_error[i].append(err_val)\n",
    "            else:\n",
    "                test_error[i]=[err_val]\n",
    "            print(f\"epoch:{epoch} \\t error(val):{err_val:2.1f}%\")\n",
    "            # error(val) should be accuracy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = [0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400] \n",
    "df = pd.DataFrame(test_error) #test accuracy\n",
    "df.index = values\n",
    "plt.plot(df, label=df.columns)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Task 4 : Using Specific Parts of the Face (Eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "side_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')\n",
    "eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/2415870123.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces_detected != ():\n",
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/2415870123.py:47: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if eyes_detected != ():\n",
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/2415870123.py:38: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces_detected != ():\n",
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/2415870123.py:29: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces_detected != ():\n"
     ]
    }
   ],
   "source": [
    "front_face = []\n",
    "side_face = []\n",
    "no_face = []\n",
    "\n",
    "is_male_front = []\n",
    "is_male_side = []\n",
    "is_male_no_face = []\n",
    "\n",
    "eyes = []\n",
    "no_eyes = []\n",
    "more_than_two_eyes = [] \n",
    "is_male_eye = []\n",
    "is_male_no_eye = []\n",
    "\n",
    "\n",
    "\n",
    "for k in range(15000): \n",
    "    img = imageio.imread(os.path.join(path, all_img[k])) \n",
    "    faces_detected = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5)\n",
    "    if faces_detected != ():\n",
    "        (x, y, w, h) = faces_detected[0]\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        eyes_detected = eyes_cascade.detectMultiScale(cropped_image)\n",
    "        front_face.append(cropped_image)\n",
    "        is_male_front.append(attribute[\"Male\"][k])\n",
    "\n",
    "    else:\n",
    "        faces_detected = side_face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5)\n",
    "        if faces_detected != ():\n",
    "            (x, y, w, h) = faces_detected[0]\n",
    "            cropped_image = img[y:y+h, x:x+w]\n",
    "            eyes_detected = eyes_cascade.detectMultiScale(cropped_image)\n",
    "            side_face.append(cropped_image)\n",
    "            is_male_side.append(attribute[\"Male\"][k])\n",
    "        else:\n",
    "            flip_img = cv2.flip(img, 1)\n",
    "            faces_detected = side_face_cascade.detectMultiScale(flip_img, scaleFactor=1.1, minNeighbors=5)\n",
    "            if faces_detected != ():\n",
    "                (x, y, w, h) = faces_detected[0]\n",
    "                cropped_image = flip_img[y:y+h, x:x+w]\n",
    "                eyes_detected = eyes_cascade.detectMultiScale(cropped_image)\n",
    "                side_face.append(cropped_image)\n",
    "                is_male_side.append(attribute[\"Male\"][k])\n",
    "            else:\n",
    "                no_face.append(img)\n",
    "                is_male_no_face.append(attribute[\"Male\"][k])\n",
    "    if eyes_detected != ():\n",
    "        if len(eyes_detected) <= 2:\n",
    "            for (ex, ey, ew, eh) in eyes_detected:\n",
    "                eyes.append(img[y+ey:y+ey+eh, x+ex:x+ex+ew])\n",
    "                is_male_eye.append(attribute[\"Male\"][k])\n",
    "        else:\n",
    "            more_than_two_eyes.append([img, k])\n",
    "    else:\n",
    "        no_eyes.append(img)\n",
    "        is_male_no_eye.append(attribute[\"Male\"][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/93825918.py:21: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces_detected != ():\n",
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/93825918.py:48: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if eyes_detected != ():\n",
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/93825918.py:30: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces_detected != ():\n",
      "/var/folders/cl/csfltj252gsbzqf6f1060pt00000gn/T/ipykernel_92306/93825918.py:39: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces_detected != ():\n"
     ]
    }
   ],
   "source": [
    "front_face_test = []\n",
    "side_face_test = []\n",
    "no_face_test = []\n",
    "\n",
    "is_male_front_test = []\n",
    "is_male_side_test = []\n",
    "is_male_no_face_test = []\n",
    "\n",
    "eyes_test = []\n",
    "no_eyes_test = []\n",
    "more_than_two_eyes_test = [] # Contains a list [img, index] of instances that has more than 2 eyes detected\n",
    "\n",
    "is_male_eye_test = []\n",
    "is_male_no_eye_test = []\n",
    "\n",
    "\n",
    "\n",
    "for k in range(15000,20000): ## CHANGE THIS TO NUMBER OF TRAINING!!!\n",
    "    img = imageio.imread(os.path.join(path, all_img[k])) \n",
    "    faces_detected = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5)\n",
    "    if faces_detected != ():\n",
    "        (x, y, w, h) = faces_detected[0]\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        eyes_detected = eyes_cascade.detectMultiScale(cropped_image)\n",
    "        front_face_test.append(cropped_image)\n",
    "        is_male_front_test.append(attribute[\"Male\"][k])\n",
    "\n",
    "    else:\n",
    "        faces_detected = side_face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5)\n",
    "        if faces_detected != ():\n",
    "            (x, y, w, h) = faces_detected[0]\n",
    "            cropped_image = img[y:y+h, x:x+w]\n",
    "            eyes_detected = eyes_cascade.detectMultiScale(cropped_image)\n",
    "            side_face_test.append(cropped_image)\n",
    "            is_male_side_test.append(attribute[\"Male\"][k])\n",
    "        else:\n",
    "            flip_img = cv2.flip(img, 1)\n",
    "            faces_detected = side_face_cascade.detectMultiScale(flip_img, scaleFactor=1.1, minNeighbors=5)\n",
    "            if faces_detected != ():\n",
    "                (x, y, w, h) = faces_detected[0]\n",
    "                cropped_image = flip_img[y:y+h, x:x+w]\n",
    "                eyes_detected = eyes_cascade.detectMultiScale(cropped_image)\n",
    "                side_face_test.append(cropped_image)\n",
    "                is_male_side_test.append(attribute[\"Male\"][k])\n",
    "            else:\n",
    "                no_face_test.append(img)\n",
    "                is_male_no_face_test.append(attribute[\"Male\"][k])\n",
    "    if eyes_detected != ():\n",
    "        if len(eyes_detected) <= 2:\n",
    "            for (ex, ey, ew, eh) in eyes_detected:\n",
    "                eyes_test.append(img[y+ey:y+ey+eh, x+ex:x+ex+ew])\n",
    "                is_male_eye_test.append(attribute[\"Male\"][k])\n",
    "        else:\n",
    "            more_than_two_eyes_test.append([img, k])\n",
    "    else:\n",
    "        no_eyes_test.append(img)\n",
    "        is_male_no_eye_test.append(attribute[\"Male\"][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21777"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7244"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eyes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(eyes)\n",
    "img_array = np.zeros((n_img, 100,100,3))\n",
    "for k in range(n_img):\n",
    "    im = eyes[k]\n",
    "    im = resize(im, (100,100,3) )\n",
    "    img_array[k,:,:,:] = im\n",
    "X_train_eye=img_array.reshape(len(eyes),100*100*3)\n",
    "Y_train_eye=np.asarray(is_male_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(eyes_test)\n",
    "img_array_test = np.zeros((n_img, 100,100,3))\n",
    "for k in range(n_img):\n",
    "    im = eyes_test[k]\n",
    "    im = resize(im, (100,100,3) )\n",
    "    img_array_test[k,:,:,:] = im\n",
    "X_test_eye=img_array_test.reshape(len(eyes_test),100*100*3)\n",
    "Y_test_eye=np.asarray(is_male_eye_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "beta_init_eye = np.random.normal(0,scale=1/np.sqrt(100*100*3),size=(100*100*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t Loss:0.658 \t error(train):61.9% \t error(val):61.5%\n",
      "epoch:100 \t Loss:0.494 \t error(train):79.2% \t error(val):79.1%\n",
      "epoch:200 \t Loss:0.457 \t error(train):80.9% \t error(val):81.3%\n",
      "epoch:300 \t Loss:0.437 \t error(train):81.7% \t error(val):82.3%\n",
      "epoch:400 \t Loss:0.425 \t error(train):82.2% \t error(val):82.6%\n",
      "epoch:500 \t Loss:0.417 \t error(train):82.5% \t error(val):83.2%\n",
      "epoch:600 \t Loss:0.410 \t error(train):82.7% \t error(val):83.3%\n",
      "epoch:700 \t Loss:0.406 \t error(train):82.9% \t error(val):83.5%\n",
      "epoch:800 \t Loss:0.402 \t error(train):83.1% \t error(val):83.6%\n",
      "epoch:900 \t Loss:0.398 \t error(train):83.3% \t error(val):83.8%\n",
      "epoch:1000 \t Loss:0.396 \t error(train):83.4% \t error(val):83.9%\n",
      "epoch:1100 \t Loss:0.393 \t error(train):83.6% \t error(val):84.1%\n",
      "epoch:1200 \t Loss:0.391 \t error(train):83.7% \t error(val):84.3%\n",
      "epoch:1300 \t Loss:0.390 \t error(train):83.7% \t error(val):84.4%\n",
      "epoch:1400 \t Loss:0.388 \t error(train):83.8% \t error(val):84.6%\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1500\n",
    "minibatch_size = 5 #size of the minibatchs\n",
    "N = len(X_train_eye)  \n",
    "img_indices = np.arange(N)\n",
    "\n",
    "loss_history = []\n",
    "loss_history_end_epoch = []\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "beta = np.copy(beta_init_eye)\n",
    "learning_rate = 0.0000005\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    n_minibatch = N // minibatch_size + 1 \n",
    "    np.random.shuffle(img_indices)\n",
    "    \n",
    "    all_loss_within_epoch = []\n",
    "    for k in range(n_minibatch):\n",
    "        batch_indices = np.arange(k*minibatch_size, (k+1)*minibatch_size) % N\n",
    "        batch_indices = img_indices[batch_indices]\n",
    "        X_minibatch = X_train_eye[batch_indices]\n",
    "        Y_minibatch = Y_train_eye[batch_indices]\n",
    "\n",
    "        val, grad = loss_value_and_grad(beta, X_minibatch, Y_minibatch)\n",
    "\n",
    "        beta = beta - learning_rate*grad\n",
    "\n",
    "        loss_history.append(val)\n",
    "        all_loss_within_epoch.append(val)\n",
    "    loss_history_end_epoch.append(np.mean(all_loss_within_epoch))\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        err_train = 100*compute_error_rate(beta, X_train_eye, Y_train_eye)\n",
    "        train_acc.append(err_train)\n",
    "        err_val= 100*compute_error_rate(beta, X_test_eye, Y_test_eye)\n",
    "        test_acc.append(err_val)\n",
    "        print(f\"epoch:{epoch} \\t Loss:{np.mean(all_loss_within_epoch):2.3f} \\t error(train):{err_train:2.1f}% \\t error(val):{err_val:2.1f}%\")\n",
    "        # typo!!\n",
    "        # error(train) should be accuracy(train)\n",
    "        # error(val) should be accuracy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(83.85378398, dtype=float64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_train_eye, Y_train_eye) #train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(84.70669427, dtype=float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_test_eye, Y_test_eye) #test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_end_epoch,\"-^\")\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.numpy.save(\"beta_eye_1500\",beta) #Saved beta for ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_eye=np.load('beta_eye_1500.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = prediction_batch(beta_eye,X_test_eye)\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test_eye, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(Y_test_eye, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Task 6 Best Model (Front Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Front Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14121"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(front_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4734"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(front_face_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black and White Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(front_face)\n",
    "img_array = np.zeros((n_img, 100,100))\n",
    "for k in range(n_img):\n",
    "    im = front_face[k]\n",
    "    im = resize(im, (100,100) )\n",
    "    im = jnp.mean(im, axis=2) \n",
    "    img_array[k,:,:] = im\n",
    "X_train_ff=img_array.reshape(len(front_face),100*100)\n",
    "Y_train_ff=np.asarray(is_male_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(front_face_test)\n",
    "img_array_test = np.zeros((n_img, 100,100))\n",
    "for k in range(len(front_face_test)):\n",
    "    im = front_face_test[k]\n",
    "    im = resize(im, (100,100) )\n",
    "    im = jnp.mean(im, axis=2) \n",
    "    img_array_test[k,:,:] = im\n",
    "X_test_ff=img_array_test.reshape(len(front_face_test),100*100)\n",
    "Y_test_ff=np.asarray(is_male_front_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t Loss:0.669 \t error(train):60.2% \t error(val):60.2%\n",
      "epoch:100 \t Loss:0.490 \t error(train):78.4% \t error(val):79.3%\n",
      "epoch:200 \t Loss:0.441 \t error(train):81.8% \t error(val):82.4%\n",
      "epoch:300 \t Loss:0.414 \t error(train):83.4% \t error(val):83.7%\n",
      "epoch:400 \t Loss:0.396 \t error(train):83.9% \t error(val):84.3%\n",
      "epoch:500 \t Loss:0.384 \t error(train):84.3% \t error(val):84.9%\n",
      "epoch:600 \t Loss:0.375 \t error(train):84.7% \t error(val):85.3%\n",
      "epoch:700 \t Loss:0.368 \t error(train):84.9% \t error(val):85.6%\n",
      "epoch:800 \t Loss:0.363 \t error(train):85.0% \t error(val):85.7%\n",
      "epoch:900 \t Loss:0.358 \t error(train):85.2% \t error(val):85.9%\n",
      "epoch:1000 \t Loss:0.354 \t error(train):85.3% \t error(val):86.0%\n",
      "epoch:1100 \t Loss:0.350 \t error(train):85.4% \t error(val):86.1%\n",
      "epoch:1200 \t Loss:0.348 \t error(train):85.6% \t error(val):86.3%\n",
      "epoch:1300 \t Loss:0.345 \t error(train):85.6% \t error(val):86.4%\n",
      "epoch:1400 \t Loss:0.343 \t error(train):85.7% \t error(val):86.5%\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1500\n",
    "minibatch_size = 5 #size of the minibatchs\n",
    "N = len(X_train_ff)  \n",
    "img_indices = np.arange(N)\n",
    "\n",
    "loss_history = []\n",
    "loss_history_end_epoch = []\n",
    "test_acc=[]\n",
    "train_acc=[]\n",
    "beta = np.copy(beta_init_bw)\n",
    "learning_rate = 0.000005\n",
    "for epoch in range(n_epoch):\n",
    "    # go through all the minibatches, sequetially\n",
    "    n_minibatch = N // minibatch_size + 1 # ensure that we're in the range [0,1]\n",
    "    # randomize the batches\n",
    "    np.random.shuffle(img_indices)\n",
    "    \n",
    "    all_loss_within_epoch = []\n",
    "    for k in range(n_minibatch):\n",
    "        # create the minibatch of examples\n",
    "        batch_indices = np.arange(k*minibatch_size, (k+1)*minibatch_size) % N\n",
    "        batch_indices = img_indices[batch_indices]\n",
    "        X_minibatch = X_train_ff[batch_indices]\n",
    "        Y_minibatch = Y_train_ff[batch_indices]\n",
    "\n",
    "        # compute the stochastic gradient\n",
    "        val, grad = loss_value_and_grad(beta, X_minibatch, Y_minibatch)\n",
    "\n",
    "        # do one step of SGD\n",
    "        beta = beta - learning_rate*grad\n",
    "\n",
    "        # book-keeping\n",
    "        loss_history.append(val)\n",
    "        all_loss_within_epoch.append(val)\n",
    "    loss_history_end_epoch.append(np.mean(all_loss_within_epoch))\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        err_train = 100*compute_error_rate(beta, X_train_ff, Y_train_ff)\n",
    "        train_acc.append(err_train)\n",
    "        err_val= 100*compute_error_rate(beta, X_test_ff, Y_test_ff)\n",
    "        test_acc.append(err_val)\n",
    "        print(f\"epoch:{epoch} \\t Loss:{np.mean(all_loss_within_epoch):2.3f} \\t error(train):{err_train:2.1f}% \\t error(val):{err_val:2.1f}%\")\n",
    "        # typo!!\n",
    "        # error(train) should be accuracy(train)\n",
    "        # error(val) should be accuracy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(85.91459528, dtype=float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_train_ff, Y_train_ff) #train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(86.58639628, dtype=float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_test_ff, Y_test_ff) #test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_end_epoch,\"-^\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = prediction_batch(beta,X_test_ff)\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test_ff, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(Y_test_ff, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(front_face)\n",
    "img_array = np.zeros((n_img, 100,100,3))\n",
    "for k in range(n_img):\n",
    "    im = front_face[k]\n",
    "    im = resize(im, (100,100) )\n",
    "    img_array[k,:,:,:] = im\n",
    "X_train_ff=img_array.reshape(len(front_face),100*100*3)\n",
    "Y_train_ff=np.asarray(is_male_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = len(front_face_test)\n",
    "img_array_test = np.zeros((n_img, 100,100,3))\n",
    "for k in range(len(front_face_test)):\n",
    "    im = front_face_test[k]\n",
    "    im = resize(im, (100,100) )\n",
    "    img_array_test[k,:,:,:] = im\n",
    "X_test_ff=img_array_test.reshape(len(front_face_test),100*100*3)\n",
    "Y_test_ff=np.asarray(is_male_front_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t Loss:0.666 \t error(train):61.4% \t error(val):61.8%\n",
      "epoch:100 \t Loss:0.374 \t error(train):85.5% \t error(val):85.9%\n",
      "epoch:200 \t Loss:0.330 \t error(train):87.4% \t error(val):87.7%\n",
      "epoch:300 \t Loss:0.308 \t error(train):88.4% \t error(val):88.3%\n",
      "epoch:400 \t Loss:0.294 \t error(train):89.0% \t error(val):88.7%\n",
      "epoch:500 \t Loss:0.285 \t error(train):89.2% \t error(val):89.1%\n",
      "epoch:600 \t Loss:0.277 \t error(train):89.4% \t error(val):89.4%\n",
      "epoch:700 \t Loss:0.271 \t error(train):89.6% \t error(val):89.5%\n",
      "epoch:800 \t Loss:0.266 \t error(train):89.9% \t error(val):89.7%\n",
      "epoch:900 \t Loss:0.261 \t error(train):89.9% \t error(val):89.6%\n",
      "epoch:1000 \t Loss:0.257 \t error(train):90.2% \t error(val):89.9%\n",
      "epoch:1100 \t Loss:0.254 \t error(train):90.3% \t error(val):89.9%\n",
      "epoch:1200 \t Loss:0.251 \t error(train):90.4% \t error(val):90.0%\n",
      "epoch:1300 \t Loss:0.248 \t error(train):90.3% \t error(val):90.1%\n",
      "epoch:1400 \t Loss:0.246 \t error(train):90.4% \t error(val):90.1%\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1500\n",
    "minibatch_size = 5 #size of the minibatchs\n",
    "N = len(X_train_ff)  \n",
    "img_indices = np.arange(N)\n",
    "\n",
    "loss_history = []\n",
    "loss_history_end_epoch = []\n",
    "test_acc=[]\n",
    "train_acc=[]\n",
    "beta = np.copy(beta_init_rgb)\n",
    "learning_rate = 0.000005\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    # go through all the minibatches, sequetially\n",
    "    n_minibatch = N // minibatch_size + 1 # ensure that we're in the range [0,1]\n",
    "    # randomize the batches\n",
    "    np.random.shuffle(img_indices)\n",
    "    \n",
    "    all_loss_within_epoch = []\n",
    "    for k in range(n_minibatch):\n",
    "        # create the minibatch of examples\n",
    "        batch_indices = np.arange(k*minibatch_size, (k+1)*minibatch_size) % N\n",
    "        batch_indices = img_indices[batch_indices]\n",
    "        X_minibatch = X_train_ff[batch_indices]\n",
    "        Y_minibatch = Y_train_ff[batch_indices]\n",
    "\n",
    "        # compute the stochastic gradient\n",
    "        val, grad = loss_value_and_grad(beta, X_minibatch, Y_minibatch)\n",
    "\n",
    "        # do one step of SGD\n",
    "        beta = beta - learning_rate*grad\n",
    "\n",
    "        # book-keeping\n",
    "        loss_history.append(val)\n",
    "        all_loss_within_epoch.append(val)\n",
    "    loss_history_end_epoch.append(np.mean(all_loss_within_epoch))\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        err_train = 100*compute_error_rate(beta, X_train_ff, Y_train_ff)\n",
    "        train_acc.append(err_train)\n",
    "        err_val= 100*compute_error_rate(beta, X_test_ff, Y_test_ff)\n",
    "        test_acc.append(err_val)\n",
    "        print(f\"epoch:{epoch} \\t Loss:{np.mean(all_loss_within_epoch):2.3f} \\t error(train):{err_train:2.1f}% \\t error(val):{err_val:2.1f}%\")\n",
    "        # typo!!\n",
    "        # error(train) should be accuracy(train)\n",
    "        # error(val) should be accuracy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(90.54599533, dtype=float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_train_ff, Y_train_ff) #train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(90.0295733, dtype=float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*compute_error_rate(beta, X_test_ff, Y_test_ff) #test accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_end_epoch,\"-^\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = prediction_batch(beta,X_test_ff)\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test_ff, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(Y_test_ff, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
